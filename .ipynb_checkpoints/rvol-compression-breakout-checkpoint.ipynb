{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35317593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the class from the Python file (module)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# from dotenv import load_dotenv\n",
    "# from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from BinanceClient import BinanceClient\n",
    "import numpy as np\n",
    "from typing import Final\n",
    "import joblib\n",
    "from BatchFeatures import BatchFeatures\n",
    "from datetime import datetime, timedelta\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eafd5c2",
   "metadata": {},
   "source": [
    "## Load pair df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca49b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "def interval_slug(s: str) -> str:\n",
    "    return s.strip().replace(\" \", \"\").replace(\"/\", \"\").lower()\n",
    "\n",
    "def make_db_name(pair: str, interval: str, weeks: int) -> str:\n",
    "    return f\"{pair}_{interval_slug(interval)}_{weeks}weeks.db\"\n",
    "\n",
    "def load_or_fetch_pair_df(pair: str, interval: str, weeks: int) -> tuple[str, \"pd.DataFrame\"]:\n",
    "    db_name = make_db_name(pair, interval, weeks)\n",
    "    db_path = \"./db/\" + db_name\n",
    "\n",
    "    print(f\"[{pair}] DB: {db_path}\")\n",
    "\n",
    "    binance_client = BinanceClient(db_path)\n",
    "    binance_client.set_interval(interval)\n",
    "\n",
    "    df = None\n",
    "\n",
    "    if os.path.exists(db_path):\n",
    "        df = binance_client.fetch_data_from_db(pair)\n",
    "        if df is not None and not df.empty:\n",
    "            print(f\"[{pair}] Loaded {len(df):,} rows from DB.\")\n",
    "        else:\n",
    "            df = None\n",
    "\n",
    "    if df is None:\n",
    "        print(f\"[{pair}] No usable DB data found -> fetching from Binance...\")\n",
    "\n",
    "        api_secret = os.getenv(\"BINANCE_SECRET_KEY\")\n",
    "        api_key = os.getenv(\"BINANCE_API_KEY\")\n",
    "        binance_client.make(api_key, api_secret)\n",
    "\n",
    "        server_time = binance_client.get_server_time()\n",
    "        end_dt = datetime.fromtimestamp(server_time[\"serverTime\"] / 1000, tz=timezone.utc)\n",
    "        start_dt = end_dt - timedelta(weeks=weeks)\n",
    "\n",
    "        start_ms = int(start_dt.timestamp() * 1000)\n",
    "        end_ms = int(end_dt.timestamp() * 1000)\n",
    "\n",
    "        data = binance_client.fetch_data(pair, start_ms, end_ms)\n",
    "        if data is None or data.empty:\n",
    "            raise RuntimeError(f\"[{pair}] No data returned from Binance for the requested range.\")\n",
    "\n",
    "        binance_client.store_data_to_db(pair, data)\n",
    "\n",
    "        df = binance_client.fetch_data_from_db(pair)\n",
    "        if df is None or df.empty:\n",
    "            raise RuntimeError(f\"[{pair}] Data fetched/stored but DB load returned empty.\")\n",
    "\n",
    "        print(f\"[{pair}] Fetched + stored + loaded {len(df):,} rows.\")\n",
    "\n",
    "    df = df.sort_index()\n",
    "    return db_path, df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b4bf11",
   "metadata": {},
   "source": [
    "## Load COINS, then align timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae31635-347b-4493-b505-85498e0b58ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def detect_volume_events(\n",
    "    df: pd.DataFrame,\n",
    "    symbol: str,\n",
    "    vol_win: int = 144,          # 12 hours on 5m\n",
    "    impulse_k: int = 12,         # 60 min impulse\n",
    "    rvol_thresh: float = 6.0,    # strict\n",
    "    impulse_thresh: float = 0.04,# +4% over impulse_k\n",
    "    lookahead: int = 24,         # 2 hours forward path\n",
    "    cooldown: int = 12,          # avoid logging same burst repeatedly (60 min)\n",
    "):\n",
    "    \"\"\"\n",
    "    Logs candidate 'flow shock' events:\n",
    "      - RVOL spike relative to rolling median\n",
    "      - Positive impulse over last impulse_k bars\n",
    "    Then measures forward path stats over lookahead bars.\n",
    "    \"\"\"\n",
    "    d = df.copy().sort_index()\n",
    "    d = d[[\"open\",\"high\",\"low\",\"close\",\"volume\"]].dropna()\n",
    "\n",
    "    vol_med = d[\"volume\"].rolling(vol_win).median()\n",
    "    rvol = d[\"volume\"] / vol_med\n",
    "    impulse = d[\"close\"] / d[\"close\"].shift(impulse_k) - 1.0\n",
    "\n",
    "    out = []\n",
    "    i = 0\n",
    "    n = len(d)\n",
    "\n",
    "    while i < n - lookahead:\n",
    "        if (rvol.iloc[i] >= rvol_thresh) and (impulse.iloc[i] >= impulse_thresh):\n",
    "            px0 = float(d[\"close\"].iloc[i])\n",
    "            ts0 = d.index[i]\n",
    "\n",
    "            future = d[\"close\"].iloc[i+1:i+1+lookahead]\n",
    "            fmax = float(future.max())\n",
    "            fmin = float(future.min())\n",
    "            max_fwd_return = fmax / px0 - 1.0\n",
    "            max_drawdown = fmin / px0 - 1.0\n",
    "\n",
    "            # retrace from the peak within the lookahead window\n",
    "            # find peak time then worst after that peak\n",
    "            peak_idx = future.values.argmax()\n",
    "            peak_px = float(future.iloc[peak_idx])\n",
    "            after_peak = future.iloc[peak_idx:]  # includes peak bar\n",
    "            trough_after_peak = float(after_peak.min())\n",
    "            max_retrace = trough_after_peak / peak_px - 1.0  # negative means retrace\n",
    "\n",
    "            # time to max retrace (bars after event)\n",
    "            trough_idx = after_peak.values.argmin()\n",
    "            time_to_max_retrace_bars = int(peak_idx + trough_idx + 1)\n",
    "\n",
    "            out.append({\n",
    "                \"symbol\": symbol,\n",
    "                \"event_ts\": ts0,\n",
    "                \"close_event\": px0,\n",
    "                \"rvol\": float(rvol.iloc[i]),\n",
    "                \"impulse\": float(impulse.iloc[i]),\n",
    "                \"max_fwd_return\": max_fwd_return,\n",
    "                \"max_drawdown\": max_drawdown,\n",
    "                \"max_retrace\": max_retrace,\n",
    "                \"time_to_max_retrace_bars\": time_to_max_retrace_bars,\n",
    "            })\n",
    "\n",
    "            i += cooldown  # skip ahead so we don't log every bar of the same burst\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return pd.DataFrame(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6963fc3-8a04-4230-ba38-a92c9803b0af",
   "metadata": {},
   "source": [
    "## Get all Binance coin pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebb5e124-1a4e-46e7-ab7e-d1e16949b323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "BINANCE_REST = \"https://api.binance.com\"\n",
    "\n",
    "def get_spot_usdt_symbols():\n",
    "    \"\"\"All Spot symbols that trade against USDT and are currently TRADING.\"\"\"\n",
    "    info = requests.get(f\"{BINANCE_REST}/api/v3/exchangeInfo\", timeout=20).json()\n",
    "    syms = []\n",
    "    for s in info[\"symbols\"]:\n",
    "        if s.get(\"status\") != \"TRADING\":\n",
    "            continue\n",
    "        if s.get(\"isSpotTradingAllowed\") is not True:\n",
    "            continue\n",
    "        if s.get(\"quoteAsset\") != \"USDT\":\n",
    "            continue\n",
    "\n",
    "        sym = s[\"symbol\"]\n",
    "\n",
    "        # Exclude leveraged tokens & some common non-spot-like tickers\n",
    "        bad_substrings = [\"UPUSDT\", \"DOWNUSDT\", \"BULLUSDT\", \"BEARUSDT\", \"3LUSDT\", \"3SUSDT\", \"5LUSDT\", \"5SUSDT\"]\n",
    "        if any(sym.endswith(x) for x in bad_substrings):\n",
    "            continue\n",
    "\n",
    "        syms.append(sym)\n",
    "    return sorted(set(syms))\n",
    "\n",
    "def rank_symbols_by_quote_volume(symbols):\n",
    "    \"\"\"Return DataFrame of symbols with 24h quoteVolume (USDT) sorted desc.\"\"\"\n",
    "    tickers = requests.get(f\"{BINANCE_REST}/api/v3/ticker/24hr\", timeout=20).json()\n",
    "    # Build a map for fast lookup\n",
    "    wanted = set(symbols)\n",
    "\n",
    "    rows = []\n",
    "    for t in tickers:\n",
    "        sym = t.get(\"symbol\")\n",
    "        if sym not in wanted:\n",
    "            continue\n",
    "        # quoteVolume is in quoteAsset units, here USDT\n",
    "        qv = float(t.get(\"quoteVolume\", 0.0))\n",
    "        rows.append({\n",
    "            \"symbol\": sym,\n",
    "            \"quoteVolumeUSDT_24h\": qv,\n",
    "            \"lastPrice\": float(t.get(\"lastPrice\", 0.0)),\n",
    "            \"priceChangePercent\": float(t.get(\"priceChangePercent\", 0.0)),\n",
    "            \"count\": int(t.get(\"count\", 0)),  # trade count 24h\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.sort_values(\"quoteVolumeUSDT_24h\", ascending=False).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def get_top_usdt_pairs(n=100, min_quote_vol_usdt=None):\n",
    "    \"\"\"Top-N by 24h quote volume; optionally filter by minimum quote volume.\"\"\"\n",
    "    syms = get_spot_usdt_symbols()\n",
    "    ranked = rank_symbols_by_quote_volume(syms)\n",
    "\n",
    "    if min_quote_vol_usdt is not None:\n",
    "        ranked = ranked[ranked[\"quoteVolumeUSDT_24h\"] >= float(min_quote_vol_usdt)].copy()\n",
    "\n",
    "    top = ranked.head(n).copy()\n",
    "    return top, ranked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a39df23b-a2f4-413e-b913-d138d3712d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top100, ranked_all = get_top_usdt_pairs(n=100)\n",
    "pairs = top100[\"symbol\"].tolist()\n",
    "\n",
    "len(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51bee877-e504-4a5c-94a7-68298b36bea4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[USDCUSDT] DB: ./db/USDCUSDT_5m_52weeks.db\n",
      "[USDCUSDT] Loaded 104,832 rows from DB.\n",
      "[BTCUSDT] DB: ./db/BTCUSDT_5m_52weeks.db\n",
      "[BTCUSDT] Loaded 104,832 rows from DB.\n",
      "[ETHUSDT] DB: ./db/ETHUSDT_5m_52weeks.db\n",
      "[ETHUSDT] Loaded 104,832 rows from DB.\n",
      "[FOGOUSDT] DB: ./db/FOGOUSDT_5m_52weeks.db\n",
      "[FOGOUSDT] Loaded 2,907 rows from DB.\n",
      "[SOLUSDT] DB: ./db/SOLUSDT_5m_52weeks.db\n",
      "[SOLUSDT] Loaded 104,832 rows from DB.\n",
      "[PAXGUSDT] DB: ./db/PAXGUSDT_5m_52weeks.db\n",
      "[PAXGUSDT] Loaded 104,832 rows from DB.\n",
      "[USD1USDT] DB: ./db/USD1USDT_5m_52weeks.db\n",
      "[USD1USDT] Loaded 71,475 rows from DB.\n",
      "[FDUSDUSDT] DB: ./db/FDUSDUSDT_5m_52weeks.db\n",
      "[FDUSDUSDT] Loaded 104,832 rows from DB.\n",
      "[XRPUSDT] DB: ./db/XRPUSDT_5m_52weeks.db\n",
      "[XRPUSDT] Loaded 104,832 rows from DB.\n",
      "[ZECUSDT] DB: ./db/ZECUSDT_5m_52weeks.db\n",
      "[ZECUSDT] Loaded 104,832 rows from DB.\n",
      "[BNBUSDT] DB: ./db/BNBUSDT_5m_52weeks.db\n",
      "[BNBUSDT] Loaded 104,832 rows from DB.\n",
      "[DOGEUSDT] DB: ./db/DOGEUSDT_5m_52weeks.db\n",
      "[DOGEUSDT] Loaded 104,832 rows from DB.\n",
      "[SUIUSDT] DB: ./db/SUIUSDT_5m_52weeks.db\n",
      "[SUIUSDT] Loaded 104,832 rows from DB.\n",
      "[PUMPUSDT] DB: ./db/PUMPUSDT_5m_52weeks.db\n",
      "[PUMPUSDT] Loaded 39,215 rows from DB.\n",
      "[ASTERUSDT] DB: ./db/ASTERUSDT_5m_52weeks.db\n",
      "[ASTERUSDT] Loaded 32,185 rows from DB.\n",
      "[TRXUSDT] DB: ./db/TRXUSDT_5m_52weeks.db\n",
      "[TRXUSDT] Loaded 104,832 rows from DB.\n",
      "[ADAUSDT] DB: ./db/ADAUSDT_5m_52weeks.db\n",
      "[ADAUSDT] Loaded 104,832 rows from DB.\n",
      "[SOMIUSDT] DB: ./db/SOMIUSDT_5m_52weeks.db\n",
      "[SOMIUSDT] Loaded 41,782 rows from DB.\n",
      "[XPLUSDT] DB: ./db/XPLUSDT_5m_52weeks.db\n",
      "[XPLUSDT] Loaded 35,344 rows from DB.\n",
      "[PEPEUSDT] DB: ./db/PEPEUSDT_5m_52weeks.db\n",
      "[PEPEUSDT] Loaded 104,832 rows from DB.\n",
      "[AXSUSDT] DB: ./db/AXSUSDT_5m_52weeks.db\n",
      "[AXSUSDT] Loaded 104,832 rows from DB.\n",
      "[LINKUSDT] DB: ./db/LINKUSDT_5m_52weeks.db\n",
      "[LINKUSDT] Loaded 104,832 rows from DB.\n",
      "[JTOUSDT] DB: ./db/JTOUSDT_5m_52weeks.db\n",
      "[JTOUSDT] Loaded 104,832 rows from DB.\n",
      "[AVAXUSDT] DB: ./db/AVAXUSDT_5m_52weeks.db\n",
      "[AVAXUSDT] Loaded 104,832 rows from DB.\n",
      "[EURUSDT] DB: ./db/EURUSDT_5m_52weeks.db\n",
      "[EURUSDT] Loaded 104,832 rows from DB.\n",
      "[DASHUSDT] DB: ./db/DASHUSDT_5m_52weeks.db\n",
      "[DASHUSDT] Loaded 104,832 rows from DB.\n",
      "[LTCUSDT] DB: ./db/LTCUSDT_5m_52weeks.db\n",
      "[LTCUSDT] Loaded 104,832 rows from DB.\n",
      "[ZROUSDT] DB: ./db/ZROUSDT_5m_52weeks.db\n",
      "[ZROUSDT] Loaded 104,832 rows from DB.\n",
      "[SENTUSDT] DB: ./db/SENTUSDT_5m_52weeks.db\n",
      "[SENTUSDT] Loaded 904 rows from DB.\n",
      "[KITEUSDT] DB: ./db/KITEUSDT_5m_52weeks.db\n",
      "[KITEUSDT] Loaded 24,811 rows from DB.\n",
      "[ENAUSDT] DB: ./db/ENAUSDT_5m_52weeks.db\n",
      "[ENAUSDT] Loaded 104,832 rows from DB.\n",
      "[PENGUUSDT] DB: ./db/PENGUUSDT_5m_52weeks.db\n",
      "[PENGUUSDT] Loaded 104,832 rows from DB.\n",
      "[AAVEUSDT] DB: ./db/AAVEUSDT_5m_52weeks.db\n",
      "[AAVEUSDT] Loaded 104,832 rows from DB.\n",
      "[ROSEUSDT] DB: ./db/ROSEUSDT_5m_52weeks.db\n",
      "[ROSEUSDT] Loaded 104,832 rows from DB.\n",
      "[TAOUSDT] DB: ./db/TAOUSDT_5m_52weeks.db\n",
      "[TAOUSDT] Loaded 104,832 rows from DB.\n",
      "[WLFIUSDT] DB: ./db/WLFIUSDT_5m_52weeks.db\n",
      "[WLFIUSDT] Loaded 42,252 rows from DB.\n",
      "[WIFUSDT] DB: ./db/WIFUSDT_5m_52weeks.db\n",
      "[WIFUSDT] Loaded 104,832 rows from DB.\n",
      "[NEARUSDT] DB: ./db/NEARUSDT_5m_52weeks.db\n",
      "[NEARUSDT] Loaded 104,832 rows from DB.\n",
      "[BCHUSDT] DB: ./db/BCHUSDT_5m_52weeks.db\n",
      "[BCHUSDT] Loaded 104,832 rows from DB.\n",
      "[HBARUSDT] DB: ./db/HBARUSDT_5m_52weeks.db\n",
      "[HBARUSDT] Loaded 104,832 rows from DB.\n",
      "[VIRTUALUSDT] DB: ./db/VIRTUALUSDT_5m_52weeks.db\n",
      "[VIRTUALUSDT] Loaded 83,432 rows from DB.\n",
      "[DOTUSDT] DB: ./db/DOTUSDT_5m_52weeks.db\n",
      "[DOTUSDT] Loaded 104,832 rows from DB.\n",
      "[RENDERUSDT] DB: ./db/RENDERUSDT_5m_52weeks.db\n",
      "[RENDERUSDT] Loaded 104,832 rows from DB.\n",
      "[NOMUSDT] DB: ./db/NOMUSDT_5m_52weeks.db\n",
      "[NOMUSDT] Loaded 33,508 rows from DB.\n",
      "[币安人生USDT] DB: ./db/币安人生USDT_5m_52weeks.db\n",
      "[币安人生USDT] Loaded 5,377 rows from DB.\n",
      "[FRAXUSDT] DB: ./db/FRAXUSDT_5m_52weeks.db\n",
      "[FRAXUSDT] Loaded 3,847 rows from DB.\n",
      "[FILUSDT] DB: ./db/FILUSDT_5m_52weeks.db\n",
      "[FILUSDT] Loaded 104,832 rows from DB.\n",
      "[ZENUSDT] DB: ./db/ZENUSDT_5m_52weeks.db\n",
      "[ZENUSDT] Loaded 104,832 rows from DB.\n",
      "[UNIUSDT] DB: ./db/UNIUSDT_5m_52weeks.db\n",
      "[UNIUSDT] Loaded 104,832 rows from DB.\n",
      "[XUSDUSDT] DB: ./db/XUSDUSDT_5m_52weeks.db\n",
      "[XUSDUSDT] Loaded 90,132 rows from DB.\n",
      "[APTUSDT] DB: ./db/APTUSDT_5m_52weeks.db\n",
      "[APTUSDT] Loaded 104,832 rows from DB.\n",
      "[ENSOUSDT] DB: ./db/ENSOUSDT_5m_52weeks.db\n",
      "[ENSOUSDT] Loaded 29,751 rows from DB.\n",
      "[ICPUSDT] DB: ./db/ICPUSDT_5m_52weeks.db\n",
      "[ICPUSDT] Loaded 104,832 rows from DB.\n",
      "[ONDOUSDT] DB: ./db/ONDOUSDT_5m_52weeks.db\n",
      "[ONDOUSDT] Loaded 84,127 rows from DB.\n",
      "[ARBUSDT] DB: ./db/ARBUSDT_5m_52weeks.db\n",
      "[ARBUSDT] Loaded 104,832 rows from DB.\n",
      "[BONKUSDT] DB: ./db/BONKUSDT_5m_52weeks.db\n",
      "[BONKUSDT] Loaded 104,832 rows from DB.\n",
      "[POLUSDT] DB: ./db/POLUSDT_5m_52weeks.db\n",
      "[POLUSDT] Loaded 104,832 rows from DB.\n",
      "[TURTLEUSDT] DB: ./db/TURTLEUSDT_5m_52weeks.db\n",
      "[TURTLEUSDT] Loaded 27,547 rows from DB.\n",
      "[1INCHUSDT] DB: ./db/1INCHUSDT_5m_52weeks.db\n",
      "[1INCHUSDT] Loaded 104,832 rows from DB.\n",
      "[BFUSDUSDT] DB: ./db/BFUSDUSDT_5m_52weeks.db\n",
      "[BFUSDUSDT] Loaded 47,718 rows from DB.\n",
      "[FETUSDT] DB: ./db/FETUSDT_5m_52weeks.db\n",
      "[FETUSDT] Loaded 104,832 rows from DB.\n",
      "[LINEAUSDT] DB: ./db/LINEAUSDT_5m_52weeks.db\n",
      "[LINEAUSDT] Loaded 39,633 rows from DB.\n",
      "[GIGGLEUSDT] DB: ./db/GIGGLEUSDT_5m_52weeks.db\n",
      "[GIGGLEUSDT] Loaded 26,793 rows from DB.\n",
      "[CHZUSDT] DB: ./db/CHZUSDT_5m_52weeks.db\n",
      "[CHZUSDT] Loaded 104,832 rows from DB.\n",
      "[PYTHUSDT] DB: ./db/PYTHUSDT_5m_52weeks.db\n",
      "[PYTHUSDT] Loaded 104,832 rows from DB.\n",
      "[CITYUSDT] DB: ./db/CITYUSDT_5m_52weeks.db\n",
      "[CITYUSDT] Loaded 104,832 rows from DB.\n",
      "[SHIBUSDT] DB: ./db/SHIBUSDT_5m_52weeks.db\n",
      "[SHIBUSDT] Loaded 104,832 rows from DB.\n",
      "[AVNTUSDT] DB: ./db/AVNTUSDT_5m_52weeks.db\n",
      "[AVNTUSDT] Loaded 38,318 rows from DB.\n",
      "[WLDUSDT] DB: ./db/WLDUSDT_5m_52weeks.db\n",
      "[WLDUSDT] Loaded 104,832 rows from DB.\n",
      "[TRUMPUSDT] DB: ./db/TRUMPUSDT_5m_52weeks.db\n",
      "[TRUMPUSDT] Loaded 104,832 rows from DB.\n",
      "[AXLUSDT] DB: ./db/AXLUSDT_5m_52weeks.db\n",
      "[AXLUSDT] Loaded 104,832 rows from DB.\n",
      "[XLMUSDT] DB: ./db/XLMUSDT_5m_52weeks.db\n",
      "[XLMUSDT] Loaded 104,832 rows from DB.\n",
      "[ZKCUSDT] DB: ./db/ZKCUSDT_5m_52weeks.db\n",
      "[ZKCUSDT] Loaded 38,044 rows from DB.\n",
      "[PENDLEUSDT] DB: ./db/PENDLEUSDT_5m_52weeks.db\n",
      "[PENDLEUSDT] Loaded 104,832 rows from DB.\n",
      "[ETHFIUSDT] DB: ./db/ETHFIUSDT_5m_52weeks.db\n",
      "[ETHFIUSDT] Loaded 104,832 rows from DB.\n",
      "[CRVUSDT] DB: ./db/CRVUSDT_5m_52weeks.db\n",
      "[CRVUSDT] Loaded 104,832 rows from DB.\n",
      "[AUCTIONUSDT] DB: ./db/AUCTIONUSDT_5m_52weeks.db\n",
      "[AUCTIONUSDT] Loaded 104,832 rows from DB.\n",
      "[JSTUSDT] DB: ./db/JSTUSDT_5m_52weeks.db\n",
      "[JSTUSDT] Loaded 104,832 rows from DB.\n",
      "[METUSDT] DB: ./db/METUSDT_5m_52weeks.db\n",
      "[METUSDT] Loaded 21,920 rows from DB.\n",
      "[OPUSDT] DB: ./db/OPUSDT_5m_52weeks.db\n",
      "[OPUSDT] Loaded 104,832 rows from DB.\n",
      "[WBTCUSDT] DB: ./db/WBTCUSDT_5m_52weeks.db\n",
      "[WBTCUSDT] Loaded 104,832 rows from DB.\n",
      "[DUSKUSDT] DB: ./db/DUSKUSDT_5m_52weeks.db\n",
      "[DUSKUSDT] Loaded 104,832 rows from DB.\n",
      "[USDEUSDT] DB: ./db/USDEUSDT_5m_52weeks.db\n",
      "[USDEUSDT] Loaded 39,963 rows from DB.\n",
      "[STGUSDT] DB: ./db/STGUSDT_5m_52weeks.db\n",
      "[STGUSDT] Loaded 104,832 rows from DB.\n",
      "[EIGENUSDT] DB: ./db/EIGENUSDT_5m_52weeks.db\n",
      "[EIGENUSDT] Loaded 104,832 rows from DB.\n",
      "[TIAUSDT] DB: ./db/TIAUSDT_5m_52weeks.db\n",
      "[TIAUSDT] Loaded 104,832 rows from DB.\n",
      "[STRKUSDT] DB: ./db/STRKUSDT_5m_52weeks.db\n",
      "[STRKUSDT] Loaded 104,832 rows from DB.\n",
      "[BIOUSDT] DB: ./db/BIOUSDT_5m_52weeks.db\n",
      "[BIOUSDT] Loaded 104,832 rows from DB.\n",
      "[TONUSDT] DB: ./db/TONUSDT_5m_52weeks.db\n",
      "[TONUSDT] Loaded 104,832 rows from DB.\n",
      "[DUSDT] DB: ./db/DUSDT_5m_52weeks.db\n",
      "[DUSDT] Loaded 104,832 rows from DB.\n",
      "[RESOLVUSDT] DB: ./db/RESOLVUSDT_5m_52weeks.db\n",
      "[RESOLVUSDT] Loaded 65,908 rows from DB.\n",
      "[KAIAUSDT] DB: ./db/KAIAUSDT_5m_52weeks.db\n",
      "[KAIAUSDT] Loaded 104,832 rows from DB.\n",
      "[0GUSDT] DB: ./db/0GUSDT_5m_52weeks.db\n",
      "[0GUSDT] Loaded 36,249 rows from DB.\n",
      "[RLUSDUSDT] DB: ./db/RLUSDUSDT_5m_52weeks.db\n",
      "[RLUSDUSDT] Loaded 1,832 rows from DB.\n",
      "[SUNUSDT] DB: ./db/SUNUSDT_5m_52weeks.db\n",
      "[SUNUSDT] No usable DB data found -> fetching from Binance...\n",
      "Fetching data from Binance API...\n",
      "[SUNUSDT] Fetched + stored + loaded 104,832 rows.\n",
      "[ZKPUSDT] DB: ./db/ZKPUSDT_5m_52weeks.db\n",
      "[ZKPUSDT] Loaded 5,212 rows from DB.\n",
      "[SEIUSDT] DB: ./db/SEIUSDT_5m_52weeks.db\n",
      "[SEIUSDT] Loaded 104,832 rows from DB.\n",
      "[XVSUSDT] DB: ./db/XVSUSDT_5m_52weeks.db\n",
      "[XVSUSDT] No usable DB data found -> fetching from Binance...\n",
      "Fetching data from Binance API...\n",
      "[XVSUSDT] Fetched + stored + loaded 104,832 rows.\n",
      "[QNTUSDT] DB: ./db/QNTUSDT_5m_52weeks.db\n",
      "[QNTUSDT] No usable DB data found -> fetching from Binance...\n",
      "Fetching data from Binance API...\n",
      "[QNTUSDT] Fetched + stored + loaded 104,832 rows.\n",
      "[BEAMXUSDT] DB: ./db/BEAMXUSDT_5m_52weeks.db\n",
      "[BEAMXUSDT] Loaded 104,832 rows from DB.\n"
     ]
    }
   ],
   "source": [
    "interval = \"5m\"\n",
    "weeks = 52\n",
    "\n",
    "paths = {}\n",
    "dfs = {}\n",
    "\n",
    "for sym in pairs:\n",
    "    db_path, df = load_or_fetch_pair_df(sym, interval, weeks)\n",
    "    paths[sym] = db_path\n",
    "    dfs[sym] = df\n",
    "    dfs[sym] = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924c6504-33ce-400e-9a64-1755e81db007",
   "metadata": {},
   "source": [
    "## Detect Comporession state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10154eca-6f14-4289-a5a9-bcbbe19bd944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def detect_compression_state(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    atr_short: int = 20,          # ~100 min on 5m\n",
    "    atr_long: int = 100,          # ~8 hours on 5m\n",
    "    vol_win: int = 144,           # volume median window (12 hours)\n",
    "    vol_ratio_thresh: float = 0.6,\n",
    "    rvol_thresh: float = 0.6,\n",
    "    min_duration: int = 12        # bars of sustained compression (60 min)\n",
    "):\n",
    "    \"\"\"\n",
    "    Detects pre-shock compression state.\n",
    "\n",
    "    Returns df with added columns:\n",
    "      - atr\n",
    "      - atr_med\n",
    "      - vol_compression\n",
    "      - rvol\n",
    "      - volu_compression\n",
    "      - compression_raw\n",
    "      - compression_duration\n",
    "      - is_compressed\n",
    "    \"\"\"\n",
    "\n",
    "    d = df.copy().sort_index()\n",
    "    d = d[[\"open\",\"high\",\"low\",\"close\",\"volume\"]].dropna()\n",
    "\n",
    "    # -----------------------\n",
    "    # 1) Volatility (ATR)\n",
    "    # -----------------------\n",
    "    high = d[\"high\"]\n",
    "    low  = d[\"low\"]\n",
    "    close = d[\"close\"]\n",
    "\n",
    "    tr = pd.concat([\n",
    "        high - low,\n",
    "        (high - close.shift()).abs(),\n",
    "        (low - close.shift()).abs()\n",
    "    ], axis=1).max(axis=1)\n",
    "\n",
    "    d[\"atr\"] = tr.rolling(atr_short).mean()\n",
    "    d[\"atr_med\"] = d[\"atr\"].rolling(atr_long).median()\n",
    "\n",
    "    d[\"vol_compression\"] = d[\"atr\"] / d[\"atr_med\"]\n",
    "    d[\"is_vol_compressed\"] = d[\"vol_compression\"] <= vol_ratio_thresh\n",
    "\n",
    "    # -----------------------\n",
    "    # 2) Volume compression\n",
    "    # -----------------------\n",
    "    vol_med = d[\"volume\"].rolling(vol_win).median()\n",
    "    d[\"rvol\"] = d[\"volume\"] / vol_med\n",
    "    d[\"is_volume_compressed\"] = d[\"rvol\"] <= rvol_thresh\n",
    "\n",
    "    # -----------------------\n",
    "    # 3) Raw compression flag\n",
    "    # -----------------------\n",
    "    d[\"compression_raw\"] = (\n",
    "        d[\"is_vol_compressed\"] &\n",
    "        d[\"is_volume_compressed\"]\n",
    "    )\n",
    "\n",
    "    # -----------------------\n",
    "    # 4) Duration counter\n",
    "    # -----------------------\n",
    "    duration = np.zeros(len(d), dtype=int)\n",
    "\n",
    "    for i in range(1, len(d)):\n",
    "        if d[\"compression_raw\"].iloc[i]:\n",
    "            duration[i] = duration[i-1] + 1\n",
    "        else:\n",
    "            duration[i] = 0\n",
    "\n",
    "    d[\"compression_duration\"] = duration\n",
    "\n",
    "    # -----------------------\n",
    "    # 5) Final state\n",
    "    # -----------------------\n",
    "    d[\"is_compressed\"] = d[\"compression_duration\"] >= min_duration\n",
    "\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c252a734-b5fb-4551-b6ac-8cb04e97daab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vol_compression</th>\n",
       "      <th>rvol</th>\n",
       "      <th>compression_duration</th>\n",
       "      <th>is_compressed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2026-01-24 12:50:00</th>\n",
       "      <td>0.868259</td>\n",
       "      <td>1.387158</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 12:55:00</th>\n",
       "      <td>0.837331</td>\n",
       "      <td>1.140229</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:00:00</th>\n",
       "      <td>0.797691</td>\n",
       "      <td>0.936581</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:05:00</th>\n",
       "      <td>0.779997</td>\n",
       "      <td>0.651361</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:10:00</th>\n",
       "      <td>0.775064</td>\n",
       "      <td>0.883699</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:15:00</th>\n",
       "      <td>0.786500</td>\n",
       "      <td>2.852841</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:20:00</th>\n",
       "      <td>0.698898</td>\n",
       "      <td>1.816785</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:25:00</th>\n",
       "      <td>0.675804</td>\n",
       "      <td>0.651221</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:30:00</th>\n",
       "      <td>0.657340</td>\n",
       "      <td>0.881418</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:35:00</th>\n",
       "      <td>0.694816</td>\n",
       "      <td>0.812190</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:40:00</th>\n",
       "      <td>0.640644</td>\n",
       "      <td>0.313170</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:45:00</th>\n",
       "      <td>0.582687</td>\n",
       "      <td>0.327921</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:50:00</th>\n",
       "      <td>0.545234</td>\n",
       "      <td>0.371703</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:55:00</th>\n",
       "      <td>0.916004</td>\n",
       "      <td>5.158043</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:00:00</th>\n",
       "      <td>1.439484</td>\n",
       "      <td>12.129071</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:05:00</th>\n",
       "      <td>1.814154</td>\n",
       "      <td>3.734550</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:10:00</th>\n",
       "      <td>1.900884</td>\n",
       "      <td>3.335517</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:15:00</th>\n",
       "      <td>1.900022</td>\n",
       "      <td>1.663950</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:20:00</th>\n",
       "      <td>1.900465</td>\n",
       "      <td>0.887099</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:25:00</th>\n",
       "      <td>1.923170</td>\n",
       "      <td>1.418124</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:30:00</th>\n",
       "      <td>2.016597</td>\n",
       "      <td>0.886594</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:35:00</th>\n",
       "      <td>2.056416</td>\n",
       "      <td>1.348959</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:40:00</th>\n",
       "      <td>2.088773</td>\n",
       "      <td>2.653494</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:45:00</th>\n",
       "      <td>2.185846</td>\n",
       "      <td>2.761525</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:50:00</th>\n",
       "      <td>2.207220</td>\n",
       "      <td>1.929704</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:55:00</th>\n",
       "      <td>2.195277</td>\n",
       "      <td>1.422006</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 15:00:00</th>\n",
       "      <td>2.279987</td>\n",
       "      <td>3.426879</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 15:05:00</th>\n",
       "      <td>2.369031</td>\n",
       "      <td>4.032178</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 15:10:00</th>\n",
       "      <td>2.435445</td>\n",
       "      <td>7.094364</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 15:15:00</th>\n",
       "      <td>2.511463</td>\n",
       "      <td>3.552484</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     vol_compression       rvol  compression_duration  \\\n",
       "timestamp                                                               \n",
       "2026-01-24 12:50:00         0.868259   1.387158                     0   \n",
       "2026-01-24 12:55:00         0.837331   1.140229                     0   \n",
       "2026-01-24 13:00:00         0.797691   0.936581                     0   \n",
       "2026-01-24 13:05:00         0.779997   0.651361                     0   \n",
       "2026-01-24 13:10:00         0.775064   0.883699                     0   \n",
       "2026-01-24 13:15:00         0.786500   2.852841                     0   \n",
       "2026-01-24 13:20:00         0.698898   1.816785                     0   \n",
       "2026-01-24 13:25:00         0.675804   0.651221                     0   \n",
       "2026-01-24 13:30:00         0.657340   0.881418                     0   \n",
       "2026-01-24 13:35:00         0.694816   0.812190                     0   \n",
       "2026-01-24 13:40:00         0.640644   0.313170                     0   \n",
       "2026-01-24 13:45:00         0.582687   0.327921                     1   \n",
       "2026-01-24 13:50:00         0.545234   0.371703                     2   \n",
       "2026-01-24 13:55:00         0.916004   5.158043                     0   \n",
       "2026-01-24 14:00:00         1.439484  12.129071                     0   \n",
       "2026-01-24 14:05:00         1.814154   3.734550                     0   \n",
       "2026-01-24 14:10:00         1.900884   3.335517                     0   \n",
       "2026-01-24 14:15:00         1.900022   1.663950                     0   \n",
       "2026-01-24 14:20:00         1.900465   0.887099                     0   \n",
       "2026-01-24 14:25:00         1.923170   1.418124                     0   \n",
       "2026-01-24 14:30:00         2.016597   0.886594                     0   \n",
       "2026-01-24 14:35:00         2.056416   1.348959                     0   \n",
       "2026-01-24 14:40:00         2.088773   2.653494                     0   \n",
       "2026-01-24 14:45:00         2.185846   2.761525                     0   \n",
       "2026-01-24 14:50:00         2.207220   1.929704                     0   \n",
       "2026-01-24 14:55:00         2.195277   1.422006                     0   \n",
       "2026-01-24 15:00:00         2.279987   3.426879                     0   \n",
       "2026-01-24 15:05:00         2.369031   4.032178                     0   \n",
       "2026-01-24 15:10:00         2.435445   7.094364                     0   \n",
       "2026-01-24 15:15:00         2.511463   3.552484                     0   \n",
       "\n",
       "                     is_compressed  \n",
       "timestamp                           \n",
       "2026-01-24 12:50:00          False  \n",
       "2026-01-24 12:55:00          False  \n",
       "2026-01-24 13:00:00          False  \n",
       "2026-01-24 13:05:00          False  \n",
       "2026-01-24 13:10:00          False  \n",
       "2026-01-24 13:15:00          False  \n",
       "2026-01-24 13:20:00          False  \n",
       "2026-01-24 13:25:00          False  \n",
       "2026-01-24 13:30:00          False  \n",
       "2026-01-24 13:35:00          False  \n",
       "2026-01-24 13:40:00          False  \n",
       "2026-01-24 13:45:00          False  \n",
       "2026-01-24 13:50:00          False  \n",
       "2026-01-24 13:55:00          False  \n",
       "2026-01-24 14:00:00          False  \n",
       "2026-01-24 14:05:00          False  \n",
       "2026-01-24 14:10:00          False  \n",
       "2026-01-24 14:15:00          False  \n",
       "2026-01-24 14:20:00          False  \n",
       "2026-01-24 14:25:00          False  \n",
       "2026-01-24 14:30:00          False  \n",
       "2026-01-24 14:35:00          False  \n",
       "2026-01-24 14:40:00          False  \n",
       "2026-01-24 14:45:00          False  \n",
       "2026-01-24 14:50:00          False  \n",
       "2026-01-24 14:55:00          False  \n",
       "2026-01-24 15:00:00          False  \n",
       "2026-01-24 15:05:00          False  \n",
       "2026-01-24 15:10:00          False  \n",
       "2026-01-24 15:15:00          False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dfs[\"BTCUSDT\"]\n",
    "df_c = detect_compression_state(df)\n",
    "\n",
    "df_c[[\"vol_compression\",\"rvol\",\"compression_duration\",\"is_compressed\"]].tail(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "973e7c80-ac75-4944-9da3-55846269a8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0025660103785103785)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c[\"is_compressed\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b9efd3d-f172-4940-9bfe-c07dc9ad987a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_compression_times(df_c):\n",
    "    \"\"\"\n",
    "    df_c = output of detect_compression_state(df)\n",
    "    Returns DatetimeIndex of bars where compression starts\n",
    "    (we take the FIRST bar of each compression block)\n",
    "    \"\"\"\n",
    "    comp = df_c[\"is_compressed\"]\n",
    "\n",
    "    # compression start = is_compressed == True AND previous == False\n",
    "    comp_start = comp & (~comp.shift(1).fillna(False))\n",
    "\n",
    "    return df_c.index[comp_start]\n",
    "\n",
    "def get_shock_times(events_sym):\n",
    "    \"\"\"\n",
    "    events_sym = events filtered to one symbol\n",
    "    Returns DatetimeIndex of shock timestamps\n",
    "    \"\"\"\n",
    "    return pd.to_datetime(events_sym[\"event_ts\"]).sort_values()\n",
    "\n",
    "def compression_leads_shock(\n",
    "    compression_times,\n",
    "    shock_times,\n",
    "    *,\n",
    "    max_lead_minutes=120\n",
    "):\n",
    "    \"\"\"\n",
    "    For each compression start time, check whether\n",
    "    a shock occurs within max_lead_minutes AFTER it.\n",
    "    \"\"\"\n",
    "    lead_td = pd.Timedelta(minutes=max_lead_minutes)\n",
    "\n",
    "    hits = 0\n",
    "    for t in compression_times:\n",
    "        if ((shock_times > t) & (shock_times <= t + lead_td)).any():\n",
    "            hits += 1\n",
    "\n",
    "    total = len(compression_times)\n",
    "\n",
    "    return {\n",
    "        \"compression_events\": total,\n",
    "        \"hits\": hits,\n",
    "        \"hit_rate\": hits / total if total > 0 else np.nan\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eb3d43e-03d7-47f3-ad66-52e45d696ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame,\n",
       "     symbol            event_ts  close_event       rvol   impulse  \\\n",
       " 0  BTCUSDT 2025-03-02 16:15:00     89370.23  35.169505  0.049267   \n",
       " 1  BTCUSDT 2025-03-02 17:20:00     92623.03  24.089593  0.040878   \n",
       " 2  BTCUSDT 2025-04-07 14:15:00     80243.10  12.829945  0.040335   \n",
       " 3  BTCUSDT 2025-04-09 17:20:00     80744.00  27.602926  0.040441   \n",
       " 4  BTCUSDT 2025-10-10 22:15:00    113213.78   6.726021  0.088853   \n",
       " \n",
       "    max_fwd_return  max_drawdown  max_retrace  time_to_max_retrace_bars  \n",
       " 0        0.058518     -0.004590    -0.012570                        23  \n",
       " 1        0.021344     -0.001134    -0.022009                        18  \n",
       " 2       -0.010208     -0.030371    -0.020371                        11  \n",
       " 3        0.026891      0.000949    -0.013591                        19  \n",
       " 4        0.012397     -0.012771    -0.024860                        24  )"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = []\n",
    "\n",
    "for sym, df in dfs.items():\n",
    "    ev = detect_volume_events(df, sym)\n",
    "    events.append(ev)\n",
    "\n",
    "# Convert list of DataFrames into a single DataFrame\n",
    "events = pd.concat(events, ignore_index=True)\n",
    "\n",
    "type(events), events.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9f2aa29-43d2-43ba-840c-26f71e270c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers: ATR + linear slope\n",
    "# -----------------------------\n",
    "def _atr14(series_df: pd.DataFrame, n: int = 14) -> pd.Series:\n",
    "    h = series_df[\"high\"]\n",
    "    l = series_df[\"low\"]\n",
    "    c = series_df[\"close\"]\n",
    "    tr = pd.concat(\n",
    "        [(h - l), (h - c.shift()).abs(), (l - c.shift()).abs()],\n",
    "        axis=1\n",
    "    ).max(axis=1)\n",
    "    return tr.rolling(n).mean()\n",
    "\n",
    "def _lin_slope(y: np.ndarray) -> float:\n",
    "    \"\"\"Slope of y versus index (0..n-1). Returns 0 if too short or constant.\"\"\"\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    n = len(y)\n",
    "    if n < 3 or np.all(~np.isfinite(y)):\n",
    "        return np.nan\n",
    "    x = np.arange(n, dtype=float)\n",
    "    y = y - np.nanmean(y)\n",
    "    x = x - x.mean()\n",
    "    denom = np.nansum(x * x)\n",
    "    return float(np.nansum(x * y) / denom) if denom > 0 else 0.0\n",
    "\n",
    "# -----------------------------\n",
    "# Candle overlap + wick/body\n",
    "# -----------------------------\n",
    "def _overlap_ratio(window: pd.DataFrame) -> float:\n",
    "    \"\"\"Mean normalized overlap between consecutive candles (0..1-ish).\"\"\"\n",
    "    if len(window) < 2:\n",
    "        return np.nan\n",
    "    h = window[\"high\"].to_numpy(dtype=float)\n",
    "    l = window[\"low\"].to_numpy(dtype=float)\n",
    "    rng = (h - l)\n",
    "    rng[rng == 0] = np.nan\n",
    "\n",
    "    # overlap between t and t-1\n",
    "    ov = np.minimum(h[1:], h[:-1]) - np.maximum(l[1:], l[:-1])\n",
    "    ov = np.maximum(ov, 0.0)\n",
    "    # normalize by current candle range\n",
    "    ov_norm = ov / rng[1:]\n",
    "    return float(np.nanmean(ov_norm))\n",
    "\n",
    "def _wick_to_body_ratio(window: pd.DataFrame) -> float:\n",
    "    \"\"\"(upper+lower wick)/body averaged over window.\"\"\"\n",
    "    o = window[\"open\"].to_numpy(dtype=float)\n",
    "    c = window[\"close\"].to_numpy(dtype=float)\n",
    "    h = window[\"high\"].to_numpy(dtype=float)\n",
    "    l = window[\"low\"].to_numpy(dtype=float)\n",
    "\n",
    "    body = np.abs(c - o)\n",
    "    body[body == 0] = np.nan\n",
    "\n",
    "    upper = h - np.maximum(o, c)\n",
    "    lower = np.minimum(o, c) - l\n",
    "    wick = upper + lower\n",
    "    return float(np.nanmean(wick / body))\n",
    "\n",
    "# -----------------------------\n",
    "# Feature extraction for one window\n",
    "# -----------------------------\n",
    "def extract_window_features(\n",
    "    d: pd.DataFrame,\n",
    "    t0: pd.Timestamp,\n",
    "    *,\n",
    "    pre_bars: int = 36,        # 180 min\n",
    "    gap_bars: int = 2,         # exclude last 10 min\n",
    "    atr_long_med_win: int = 144 # 12h baseline for median\n",
    ") -> dict | None:\n",
    "    \"\"\"\n",
    "    Compute pre-shock window features for a single event time t0.\n",
    "\n",
    "    Window is: [t0 - pre_bars, t0 - gap_bars]\n",
    "    Assumes d is indexed by datetime and has open/high/low/close/volume.\n",
    "    \"\"\"\n",
    "    if not isinstance(d.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"df must have a DatetimeIndex\")\n",
    "\n",
    "    # Ensure sorted\n",
    "    d = d.sort_index()\n",
    "\n",
    "    # Need baseline columns\n",
    "    if \"atr14\" not in d.columns:\n",
    "        d[\"atr14\"] = _atr14(d, 14)\n",
    "    if \"vol_med_12h\" not in d.columns:\n",
    "        d[\"vol_med_12h\"] = d[\"volume\"].rolling(atr_long_med_win).median()\n",
    "    if \"rvol_12h\" not in d.columns:\n",
    "        d[\"rvol_12h\"] = d[\"volume\"] / d[\"vol_med_12h\"]\n",
    "    if \"atr14_med_12h\" not in d.columns:\n",
    "        d[\"atr14_med_12h\"] = d[\"atr14\"].rolling(atr_long_med_win).median()\n",
    "\n",
    "    # Locate t0\n",
    "    if t0 not in d.index:\n",
    "        # if exact timestamp missing, align to nearest previous bar\n",
    "        loc = d.index.searchsorted(t0, side=\"right\") - 1\n",
    "        if loc < 0:\n",
    "            return None\n",
    "        t0 = d.index[loc]\n",
    "\n",
    "    end_loc = d.index.get_loc(t0) - gap_bars\n",
    "    start_loc = end_loc - pre_bars + 1\n",
    "\n",
    "    if start_loc < 0 or end_loc <= start_loc:\n",
    "        return None\n",
    "\n",
    "    w = d.iloc[start_loc:end_loc+1].copy()\n",
    "    if len(w) < max(10, pre_bars // 2):\n",
    "        return None\n",
    "\n",
    "    # Baselines at window end (most relevant \"current regime\")\n",
    "    atr_med = d[\"atr14_med_12h\"].iloc[end_loc]\n",
    "    if not np.isfinite(atr_med) or atr_med <= 0:\n",
    "        return None\n",
    "\n",
    "    # Features\n",
    "    atr_mean = float(np.nanmean(w[\"atr14\"].to_numpy(dtype=float)))\n",
    "    atr_mean_ratio = atr_mean / float(atr_med)\n",
    "\n",
    "    atr_slope = _lin_slope(w[\"atr14\"].to_numpy(dtype=float))\n",
    "    rvol_mean = float(np.nanmean(w[\"rvol_12h\"].to_numpy(dtype=float)))\n",
    "    rvol_slope = _lin_slope(w[\"rvol_12h\"].to_numpy(dtype=float))\n",
    "\n",
    "    window_high = float(np.nanmax(w[\"high\"]))\n",
    "    window_low  = float(np.nanmin(w[\"low\"]))\n",
    "    window_close = float(w[\"close\"].iloc[-1])\n",
    "    range_pct = (window_high - window_low) / window_close if window_close != 0 else np.nan\n",
    "\n",
    "    overlap_ratio = _overlap_ratio(w)\n",
    "    wick_to_body = _wick_to_body_ratio(w)\n",
    "\n",
    "    return {\n",
    "        \"t0\": t0,\n",
    "        \"win_start\": w.index[0],\n",
    "        \"win_end\": w.index[-1],\n",
    "        \"atr_mean_ratio\": atr_mean_ratio,\n",
    "        \"atr_slope\": atr_slope,\n",
    "        \"rvol_mean\": rvol_mean,\n",
    "        \"rvol_slope\": rvol_slope,\n",
    "        \"range_pct\": range_pct,\n",
    "        \"overlap_ratio\": overlap_ratio,\n",
    "        \"wick_to_body_ratio\": wick_to_body,\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# Build dataset: shock vs control\n",
    "# -----------------------------\n",
    "def build_preshock_dataset(\n",
    "    dfs: dict[str, pd.DataFrame],\n",
    "    events: pd.DataFrame,\n",
    "    *,\n",
    "    pre_bars: int = 36,\n",
    "    gap_bars: int = 2,\n",
    "    control_per_event: int = 1,\n",
    "    control_lookahead_bars: int = 36,   # control must have NO shock in next 3h\n",
    "    seed: int = 42,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a labeled dataset with:\n",
    "      label=1 for pre-shock windows\n",
    "      label=0 for matched control windows (same symbol, same window length)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    ev = events.copy()\n",
    "    ev[\"event_ts\"] = pd.to_datetime(ev[\"event_ts\"])\n",
    "    ev = ev.sort_values([\"symbol\", \"event_ts\"])\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # Precompute shock times per symbol for fast control selection\n",
    "    shock_times_by_sym = {\n",
    "        sym: pd.to_datetime(g[\"event_ts\"]).sort_values().to_numpy(dtype=\"datetime64[ns]\")\n",
    "        for sym, g in ev.groupby(\"symbol\")\n",
    "    }\n",
    "\n",
    "    for sym, g in ev.groupby(\"symbol\"):\n",
    "        if sym not in dfs or dfs[sym].empty:\n",
    "            continue\n",
    "\n",
    "        d = dfs[sym].copy().sort_index()\n",
    "        d = d[[\"open\",\"high\",\"low\",\"close\",\"volume\"]].dropna()\n",
    "        if len(d) < (pre_bars + gap_bars + 200):\n",
    "            continue\n",
    "\n",
    "        # Make sure index is datetime\n",
    "        if not isinstance(d.index, pd.DatetimeIndex):\n",
    "            raise ValueError(f\"{sym} df index must be DatetimeIndex\")\n",
    "\n",
    "        # Precompute baseline columns once per symbol\n",
    "        d[\"atr14\"] = _atr14(d, 14)\n",
    "        d[\"vol_med_12h\"] = d[\"volume\"].rolling(144).median()\n",
    "        d[\"rvol_12h\"] = d[\"volume\"] / d[\"vol_med_12h\"]\n",
    "        d[\"atr14_med_12h\"] = d[\"atr14\"].rolling(144).median()\n",
    "\n",
    "        shock_times = shock_times_by_sym.get(sym, np.array([], dtype=\"datetime64[ns]\"))\n",
    "\n",
    "        for t0 in pd.to_datetime(g[\"event_ts\"]):\n",
    "            # --- Positive (pre-shock) ---\n",
    "            feat = extract_window_features(\n",
    "                d, t0, pre_bars=pre_bars, gap_bars=gap_bars\n",
    "            )\n",
    "            if feat is None:\n",
    "                continue\n",
    "\n",
    "            feat.update({\"symbol\": sym, \"label\": 1})\n",
    "            rows.append(feat)\n",
    "\n",
    "            # --- Controls (non-shock) ---\n",
    "            # We sample control windows that are NOT too close to any shock:\n",
    "            # specifically: no shock in [t_ctrl, t_ctrl + control_lookahead_bars]\n",
    "            # and the control window itself must exist.\n",
    "            if control_per_event <= 0:\n",
    "                continue\n",
    "\n",
    "            # Candidate range: pick end_loc such that start_loc >= 0 and end_loc within df\n",
    "            end_min = pre_bars + gap_bars  # minimal index for t0 location\n",
    "            end_max = len(d) - control_lookahead_bars - 1\n",
    "            if end_max <= end_min:\n",
    "                continue\n",
    "\n",
    "            # Convert shock_times to pandas index positions for quick exclusion\n",
    "            # We'll just exclude by time comparisons (simpler, good enough)\n",
    "            attempts = 0\n",
    "            got = 0\n",
    "            while got < control_per_event and attempts < 200:\n",
    "                attempts += 1\n",
    "                end_loc = int(rng.integers(end_min, end_max))\n",
    "                t_ctrl = d.index[end_loc]  # treat as \"event time\"\n",
    "\n",
    "                # Exclude if within pre_bars of start or near this shock t0 to avoid leakage\n",
    "                if abs((t_ctrl - feat[\"t0\"]).total_seconds()) < 6 * 3600:\n",
    "                    continue\n",
    "\n",
    "                # Check: no shock in next lookahead window\n",
    "                t1 = t_ctrl\n",
    "                t2 = t_ctrl + pd.Timedelta(minutes=5 * control_lookahead_bars)\n",
    "\n",
    "                if shock_times.size > 0:\n",
    "                    # numpy datetime64 compare\n",
    "                    t1n = np.datetime64(t1.to_datetime64())\n",
    "                    t2n = np.datetime64(t2.to_datetime64())\n",
    "                    has_future_shock = np.any((shock_times > t1n) & (shock_times <= t2n))\n",
    "                    if has_future_shock:\n",
    "                        continue\n",
    "\n",
    "                feat_c = extract_window_features(\n",
    "                    d, t_ctrl, pre_bars=pre_bars, gap_bars=gap_bars\n",
    "                )\n",
    "                if feat_c is None:\n",
    "                    continue\n",
    "\n",
    "                feat_c.update({\"symbol\": sym, \"label\": 0})\n",
    "                rows.append(feat_c)\n",
    "                got += 1\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b361129a-2f7b-44be-8437-ff465d3cdbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10076, 12),\n",
       " label\n",
       " 1    5038\n",
       " 0    5038\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build dataset\n",
    "ds = build_preshock_dataset(\n",
    "    dfs=dfs,\n",
    "    events=events,\n",
    "    pre_bars=36,            # 180 min\n",
    "    gap_bars=2,             # exclude last 10 min\n",
    "    control_per_event=1,    # start with 1:1 matching\n",
    "    control_lookahead_bars=36,  # control has no shock in next 3h\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "ds.shape, ds[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdfb843d-92fd-4dbc-bd60-6d9f1a2b5fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>atr_mean_ratio</th>\n",
       "      <td>1.005180e+00</td>\n",
       "      <td>1.209002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atr_slope</th>\n",
       "      <td>-8.918000e-08</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rvol_mean</th>\n",
       "      <td>1.457157e+00</td>\n",
       "      <td>2.520168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rvol_slope</th>\n",
       "      <td>-1.365018e-03</td>\n",
       "      <td>0.054635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>range_pct</th>\n",
       "      <td>2.537937e-02</td>\n",
       "      <td>0.054166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overlap_ratio</th>\n",
       "      <td>5.745321e-01</td>\n",
       "      <td>0.579448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wick_to_body_ratio</th>\n",
       "      <td>1.448094e+00</td>\n",
       "      <td>1.871671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label                          0         1\n",
       "atr_mean_ratio      1.005180e+00  1.209002\n",
       "atr_slope          -8.918000e-08  0.000017\n",
       "rvol_mean           1.457157e+00  2.520168\n",
       "rvol_slope         -1.365018e-03  0.054635\n",
       "range_pct           2.537937e-02  0.054166\n",
       "overlap_ratio       5.745321e-01  0.579448\n",
       "wick_to_body_ratio  1.448094e+00  1.871671"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Any NaNs?\n",
    "ds.isna().mean().sort_values(ascending=False).head(10)\n",
    "\n",
    "# Compare distributions quickly (shock vs control)\n",
    "cols = [\"atr_mean_ratio\",\"atr_slope\",\"rvol_mean\",\"rvol_slope\",\"range_pct\",\"overlap_ratio\",\"wick_to_body_ratio\"]\n",
    "ds.groupby(\"label\")[cols].median().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dd4e9f5-7dce-4d57-a986-b01669e4f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_instability_features_over_window(\n",
    "    d: pd.DataFrame,\n",
    "    *,\n",
    "    pre_bars: int = 36,\n",
    "    gap_bars: int = 2,\n",
    "    vol_med_win: int = 144\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds rolling-window (per bar) pre-shock features aligned to each bar t0,\n",
    "    computed from [t0-pre_bars, t0-gap_bars].\n",
    "    Output columns are same as dataset: atr_mean_ratio, atr_slope, rvol_mean, rvol_slope,\n",
    "    range_pct, wick_to_body_ratio.\n",
    "    \"\"\"\n",
    "    df = d.copy().sort_index()\n",
    "    df = df[[\"open\",\"high\",\"low\",\"close\",\"volume\"]].dropna()\n",
    "\n",
    "    # precompute base series\n",
    "    df[\"atr14\"] = _atr14(df, 14)\n",
    "    df[\"atr14_med_12h\"] = df[\"atr14\"].rolling(vol_med_win).median()\n",
    "    df[\"vol_med_12h\"] = df[\"volume\"].rolling(vol_med_win).median()\n",
    "    df[\"rvol_12h\"] = df[\"volume\"] / df[\"vol_med_12h\"]\n",
    "\n",
    "    # container columns\n",
    "    cols = [\"atr_mean_ratio\",\"atr_slope\",\"rvol_mean\",\"rvol_slope\",\"range_pct\",\"wick_to_body_ratio\"]\n",
    "    for c in cols:\n",
    "        df[c] = np.nan\n",
    "\n",
    "    # iterate bars (vectorizing slopes/wicks is possible later; keep correct first)\n",
    "    for end_loc in range(pre_bars + gap_bars, len(df)):\n",
    "        t0 = df.index[end_loc]\n",
    "        # window ends at end_loc-gap_bars\n",
    "        w_end = end_loc - gap_bars\n",
    "        w_start = w_end - pre_bars + 1\n",
    "        w = df.iloc[w_start:w_end+1]\n",
    "\n",
    "        atr_med = df[\"atr14_med_12h\"].iloc[w_end]\n",
    "        if not np.isfinite(atr_med) or atr_med <= 0:\n",
    "            continue\n",
    "\n",
    "        atr_mean = float(np.nanmean(w[\"atr14\"].to_numpy(dtype=float)))\n",
    "        df.at[t0, \"atr_mean_ratio\"] = atr_mean / float(atr_med)\n",
    "\n",
    "        df.at[t0, \"atr_slope\"] = _lin_slope(w[\"atr14\"].to_numpy(dtype=float))\n",
    "\n",
    "        df.at[t0, \"rvol_mean\"] = float(np.nanmean(w[\"rvol_12h\"].to_numpy(dtype=float)))\n",
    "        df.at[t0, \"rvol_slope\"] = _lin_slope(w[\"rvol_12h\"].to_numpy(dtype=float))\n",
    "\n",
    "        window_high = float(np.nanmax(w[\"high\"]))\n",
    "        window_low  = float(np.nanmin(w[\"low\"]))\n",
    "        window_close = float(w[\"close\"].iloc[-1])\n",
    "        df.at[t0, \"range_pct\"] = (window_high - window_low) / window_close if window_close else np.nan\n",
    "\n",
    "        df.at[t0, \"wick_to_body_ratio\"] = _wick_to_body_ratio(w)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def classify_instability(df_feat: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Returns boolean Series indexed like df_feat: True when in pre-shock instability state.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        (df_feat[\"rvol_mean\"] >= 2.0) &\n",
    "        (df_feat[\"rvol_slope\"] > 0.0) &\n",
    "        (df_feat[\"atr_mean_ratio\"] >= 1.10) &\n",
    "        (df_feat[\"wick_to_body_ratio\"] >= 1.60) &\n",
    "        (df_feat[\"range_pct\"] >= 0.035)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60fb632d-3f4a-4193-9898-96086a26c603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.007659874847374847),\n",
       " timestamp\n",
       " 2026-01-24 11:10:00    False\n",
       " 2026-01-24 11:15:00    False\n",
       " 2026-01-24 11:20:00    False\n",
       " 2026-01-24 11:25:00    False\n",
       " 2026-01-24 11:30:00    False\n",
       " 2026-01-24 11:35:00    False\n",
       " 2026-01-24 11:40:00    False\n",
       " 2026-01-24 11:45:00    False\n",
       " 2026-01-24 11:50:00    False\n",
       " 2026-01-24 11:55:00    False\n",
       " 2026-01-24 12:00:00    False\n",
       " 2026-01-24 12:05:00    False\n",
       " 2026-01-24 12:10:00    False\n",
       " 2026-01-24 12:15:00    False\n",
       " 2026-01-24 12:20:00    False\n",
       " 2026-01-24 12:25:00    False\n",
       " 2026-01-24 12:30:00    False\n",
       " 2026-01-24 12:35:00    False\n",
       " 2026-01-24 12:40:00    False\n",
       " 2026-01-24 12:45:00    False\n",
       " 2026-01-24 12:50:00    False\n",
       " 2026-01-24 12:55:00    False\n",
       " 2026-01-24 13:00:00    False\n",
       " 2026-01-24 13:05:00    False\n",
       " 2026-01-24 13:10:00    False\n",
       " 2026-01-24 13:15:00    False\n",
       " 2026-01-24 13:20:00    False\n",
       " 2026-01-24 13:25:00    False\n",
       " 2026-01-24 13:30:00    False\n",
       " 2026-01-24 13:35:00    False\n",
       " 2026-01-24 13:40:00    False\n",
       " 2026-01-24 13:45:00    False\n",
       " 2026-01-24 13:50:00    False\n",
       " 2026-01-24 13:55:00    False\n",
       " 2026-01-24 14:00:00    False\n",
       " 2026-01-24 14:05:00    False\n",
       " 2026-01-24 14:10:00    False\n",
       " 2026-01-24 14:15:00    False\n",
       " 2026-01-24 14:20:00    False\n",
       " 2026-01-24 14:25:00    False\n",
       " 2026-01-24 14:30:00    False\n",
       " 2026-01-24 14:35:00    False\n",
       " 2026-01-24 14:40:00    False\n",
       " 2026-01-24 14:45:00    False\n",
       " 2026-01-24 14:50:00    False\n",
       " 2026-01-24 14:55:00    False\n",
       " 2026-01-24 15:00:00    False\n",
       " 2026-01-24 15:05:00    False\n",
       " 2026-01-24 15:10:00    False\n",
       " 2026-01-24 15:15:00    False\n",
       " Name: is_instability, dtype: bool)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym = \"BTCUSDT\"\n",
    "df_feat = compute_instability_features_over_window(dfs[sym])\n",
    "df_feat[\"is_instability\"] = classify_instability(df_feat)\n",
    "\n",
    "df_feat[\"is_instability\"].mean(), df_feat[\"is_instability\"].tail(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f7dab9a-78bb-46bc-a645-6bb7bfa31abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>thr</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>range_pct</td>\n",
       "      <td>0.036742</td>\n",
       "      <td>0.829297</td>\n",
       "      <td>0.270742</td>\n",
       "      <td>0.558555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rvol_slope</td>\n",
       "      <td>0.032369</td>\n",
       "      <td>0.607185</td>\n",
       "      <td>0.212783</td>\n",
       "      <td>0.394403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rvol_mean</td>\n",
       "      <td>2.099454</td>\n",
       "      <td>0.602422</td>\n",
       "      <td>0.257642</td>\n",
       "      <td>0.344780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atr_mean_ratio</td>\n",
       "      <td>1.116728</td>\n",
       "      <td>0.613934</td>\n",
       "      <td>0.306074</td>\n",
       "      <td>0.307860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wick_to_body_ratio</td>\n",
       "      <td>1.341384</td>\n",
       "      <td>0.751687</td>\n",
       "      <td>0.548233</td>\n",
       "      <td>0.203454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature       thr       TPR       FPR         J\n",
       "4           range_pct  0.036742  0.829297  0.270742  0.558555\n",
       "1          rvol_slope  0.032369  0.607185  0.212783  0.394403\n",
       "0           rvol_mean  2.099454  0.602422  0.257642  0.344780\n",
       "2      atr_mean_ratio  1.116728  0.613934  0.306074  0.307860\n",
       "3  wick_to_body_ratio  1.341384  0.751687  0.548233  0.203454"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def best_threshold_youden(ds: pd.DataFrame, feature: str, higher_is_more_shock: bool = True):\n",
    "    x = ds[feature].to_numpy(dtype=float)\n",
    "    y = ds[\"label\"].to_numpy(dtype=int)\n",
    "\n",
    "    # candidate thresholds = percentiles (fast, robust)\n",
    "    qs = np.linspace(5, 95, 91)\n",
    "    thrs = np.percentile(x[np.isfinite(x)], qs)\n",
    "\n",
    "    best = None\n",
    "    for thr in thrs:\n",
    "        pred = (x >= thr) if higher_is_more_shock else (x <= thr)\n",
    "        pred = pred & np.isfinite(x)\n",
    "\n",
    "        tp = np.sum((pred == 1) & (y == 1))\n",
    "        fp = np.sum((pred == 1) & (y == 0))\n",
    "        tn = np.sum((pred == 0) & (y == 0))\n",
    "        fn = np.sum((pred == 0) & (y == 1))\n",
    "\n",
    "        tpr = tp / (tp + fn) if (tp + fn) else 0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) else 0\n",
    "        j = tpr - fpr\n",
    "\n",
    "        if best is None or j > best[\"J\"]:\n",
    "            best = {\"feature\": feature, \"thr\": float(thr), \"TPR\": tpr, \"FPR\": fpr, \"J\": j}\n",
    "\n",
    "    return best\n",
    "\n",
    "features = [\"rvol_mean\",\"rvol_slope\",\"atr_mean_ratio\",\"wick_to_body_ratio\",\"range_pct\"]\n",
    "best_list = [best_threshold_youden(ds, f, higher_is_more_shock=True) for f in features]\n",
    "pd.DataFrame(best_list).sort_values(\"J\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13b3e124-dbff-4c17-941f-709febf29130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_future_shock(df_feat: pd.DataFrame, events: pd.DataFrame, horizon_bars: int):\n",
    "    \"\"\"\n",
    "    For each bar in df_feat, mark whether a shock occurs within the next horizon_bars.\n",
    "    \"\"\"\n",
    "    shock_times = pd.to_datetime(events[\"event_ts\"]).values\n",
    "\n",
    "    df = df_feat.copy()\n",
    "    df[\"future_shock\"] = False\n",
    "\n",
    "    idx = df.index.values\n",
    "    for i in range(len(idx)):\n",
    "        t0 = idx[i]\n",
    "        t1 = idx[min(i + horizon_bars, len(idx) - 1)]\n",
    "        # any shock in (t0, t1]?\n",
    "        df.iloc[i, df.columns.get_loc(\"future_shock\")] = np.any(\n",
    "            (shock_times > t0) & (shock_times <= t1)\n",
    "        )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcf3022f-7485-42b5-a7ac-21b21aea482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_pre_shock_instability_v1(df_feat: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Rule-based pre-shock instability classifier.\n",
    "    Calibrated via Youden J on your dataset.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        (df_feat[\"range_pct\"] >= 0.037) &\n",
    "        (df_feat[\"rvol_slope\"] >= 0.032) &\n",
    "        (df_feat[\"rvol_mean\"] >= 2.10)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98790414-e6aa-4cbb-8c1f-7a130f23af86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.0010397588522588523),\n",
       " np.float64(0.04932735426008968),\n",
       " np.float64(47.44114864030937))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym = \"BTCUSDT\"\n",
    "\n",
    "df_feat = compute_instability_features_over_window(dfs[sym])\n",
    "df_feat[\"is_instability\"] = classify_pre_shock_instability_v1(df_feat)\n",
    "\n",
    "ev = events.query(\"symbol == @sym\")\n",
    "df_feat = mark_future_shock(df_feat, ev, horizon_bars=24)  # 120 min\n",
    "\n",
    "p_base = df_feat[\"future_shock\"].mean()\n",
    "p_cond = df_feat.loc[df_feat[\"is_instability\"], \"future_shock\"].mean()\n",
    "\n",
    "p_base, p_cond, p_cond / p_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3e5a7fe-3228-4c99-b90f-dbc888983e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Helpers: ATR and simple linear slope\n",
    "# ------------------------------------------------------------\n",
    "def _atr(series_df: pd.DataFrame, n: int = 14) -> pd.Series:\n",
    "    h = series_df[\"high\"]\n",
    "    l = series_df[\"low\"]\n",
    "    c = series_df[\"close\"]\n",
    "    tr = pd.concat([(h - l), (h - c.shift()).abs(), (l - c.shift()).abs()], axis=1).max(axis=1)\n",
    "    return tr.rolling(n).mean()\n",
    "\n",
    "def _lin_slope(y: np.ndarray) -> float:\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    n = len(y)\n",
    "    if n < 3 or np.all(~np.isfinite(y)):\n",
    "        return np.nan\n",
    "    x = np.arange(n, dtype=float)\n",
    "    ym = np.nanmean(y)\n",
    "    y = y - ym\n",
    "    x = x - x.mean()\n",
    "    denom = np.nansum(x * x)\n",
    "    return float(np.nansum(x * y) / denom) if denom > 0 else 0.0\n",
    "\n",
    "def _wick_to_body_ratio(window: pd.DataFrame) -> float:\n",
    "    o = window[\"open\"].to_numpy(dtype=float)\n",
    "    c = window[\"close\"].to_numpy(dtype=float)\n",
    "    h = window[\"high\"].to_numpy(dtype=float)\n",
    "    l = window[\"low\"].to_numpy(dtype=float)\n",
    "\n",
    "    body = np.abs(c - o)\n",
    "    body[body == 0] = np.nan\n",
    "\n",
    "    upper = h - np.maximum(o, c)\n",
    "    lower = np.minimum(o, c) - l\n",
    "    wick = upper + lower\n",
    "\n",
    "    x = wick / body\n",
    "    x = x[np.isfinite(x)]\n",
    "    return float(np.mean(x)) if x.size else np.nan\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Compute rolling/window features aligned to each bar t0\n",
    "# NOTE: This is still the expensive step. We cache its output.\n",
    "# ------------------------------------------------------------\n",
    "def compute_instability_features_over_window(\n",
    "    d: pd.DataFrame,\n",
    "    *,\n",
    "    pre_bars: int = 36,\n",
    "    gap_bars: int = 2,\n",
    "    vol_med_win: int = 144,   # 12h baseline\n",
    "    atr_n: int = 14\n",
    ") -> pd.DataFrame:\n",
    "    df = d.copy().sort_index()\n",
    "    df = df[[\"open\",\"high\",\"low\",\"close\",\"volume\"]].dropna()\n",
    "\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"df index must be DatetimeIndex\")\n",
    "\n",
    "    # base series (computed once)\n",
    "    df[\"atr14\"] = _atr(df, atr_n)\n",
    "    df[\"atr14_med_12h\"] = df[\"atr14\"].rolling(vol_med_win).median()\n",
    "    df[\"vol_med_12h\"] = df[\"volume\"].rolling(vol_med_win).median()\n",
    "    df[\"rvol_12h\"] = df[\"volume\"] / df[\"vol_med_12h\"]\n",
    "\n",
    "    # features to fill\n",
    "    cols = [\"atr_mean_ratio\",\"atr_slope\",\"rvol_mean\",\"rvol_slope\",\"range_pct\",\"wick_to_body_ratio\"]\n",
    "    for c in cols:\n",
    "        df[c] = np.nan\n",
    "\n",
    "    # Python loop (heavy). Keep correct first; optimize later if needed.\n",
    "    for end_loc in range(pre_bars + gap_bars, len(df)):\n",
    "        t0 = df.index[end_loc]\n",
    "        w_end = end_loc - gap_bars\n",
    "        w_start = w_end - pre_bars + 1\n",
    "\n",
    "        w = df.iloc[w_start:w_end+1]\n",
    "        atr_med = df[\"atr14_med_12h\"].iloc[w_end]\n",
    "        if not np.isfinite(atr_med) or atr_med <= 0:\n",
    "            continue\n",
    "\n",
    "        atr_mean = float(np.nanmean(w[\"atr14\"].to_numpy(dtype=float)))\n",
    "        df.at[t0, \"atr_mean_ratio\"] = atr_mean / float(atr_med)\n",
    "        df.at[t0, \"atr_slope\"] = _lin_slope(w[\"atr14\"].to_numpy(dtype=float))\n",
    "\n",
    "        rvol_arr = w[\"rvol_12h\"].to_numpy(dtype=float)\n",
    "        df.at[t0, \"rvol_mean\"] = float(np.nanmean(rvol_arr))\n",
    "        df.at[t0, \"rvol_slope\"] = _lin_slope(rvol_arr)\n",
    "\n",
    "        window_high = float(np.nanmax(w[\"high\"]))\n",
    "        window_low  = float(np.nanmin(w[\"low\"]))\n",
    "        window_close = float(w[\"close\"].iloc[-1])\n",
    "        df.at[t0, \"range_pct\"] = (window_high - window_low) / window_close if window_close else np.nan\n",
    "\n",
    "        df.at[t0, \"wick_to_body_ratio\"] = _wick_to_body_ratio(w)\n",
    "\n",
    "    return df\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Instability classifier (your v1, based on Youden J results)\n",
    "# ------------------------------------------------------------\n",
    "def classify_pre_shock_instability_v1(df_feat: pd.DataFrame) -> pd.Series:\n",
    "    return (\n",
    "        (df_feat[\"range_pct\"] >= 0.037) &\n",
    "        (df_feat[\"rvol_slope\"] >= 0.032) &\n",
    "        (df_feat[\"rvol_mean\"] >= 2.10)\n",
    "    )\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# FIX #2: Fast \"future shock within horizon\" flag (vectorized)\n",
    "# ------------------------------------------------------------\n",
    "def mark_future_shock_fast(df_feat: pd.DataFrame, events_sym: pd.DataFrame, horizon_bars: int) -> pd.DataFrame:\n",
    "    df = df_feat.copy()\n",
    "    df[\"future_shock\"] = False\n",
    "\n",
    "    if events_sym.empty:\n",
    "        return df\n",
    "\n",
    "    # Convert shock times -> indices in df.index\n",
    "    shock_times = pd.to_datetime(events_sym[\"event_ts\"])\n",
    "    shock_pos = df.index.searchsorted(shock_times)\n",
    "\n",
    "    # Keep only valid positions\n",
    "    shock_pos = shock_pos[(shock_pos >= 0) & (shock_pos < len(df))]\n",
    "    if len(shock_pos) == 0:\n",
    "        return df\n",
    "\n",
    "    shock_flag = np.zeros(len(df), dtype=int)\n",
    "    shock_flag[shock_pos] = 1\n",
    "\n",
    "    # any shock in the next horizon_bars?\n",
    "    # We shift \"backwards\" by -horizon to align \"future window starting now\"\n",
    "    future_any = (\n",
    "        pd.Series(shock_flag, index=df.index)\n",
    "        .rolling(horizon_bars, min_periods=1)\n",
    "        .sum()\n",
    "        .shift(-horizon_bars)\n",
    "        .fillna(0)\n",
    "        .gt(0)\n",
    "    )\n",
    "\n",
    "    df[\"future_shock\"] = future_any\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30678dcf-f274-40aa-a997-887b7230b216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb01c582c05e4981bbe3dfef1868a2a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing instability per symbol:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1243553/1206333118.py:38: RuntimeWarning: Mean of empty slice\n",
      "  return float(np.nanmean(wick / body))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m df_feat \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_instability_features_over_window\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m df_feat[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_instability\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m classify_pre_shock_instability_v1(df_feat)\n\u001b[1;32m     22\u001b[0m instability_cache[sym] \u001b[38;5;241m=\u001b[39m df_feat[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_instability\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[19], line 82\u001b[0m, in \u001b[0;36mcompute_instability_features_over_window\u001b[0;34m(d, pre_bars, gap_bars, vol_med_win, atr_n)\u001b[0m\n\u001b[1;32m     80\u001b[0m atr_mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mnanmean(w[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124matr14\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)))\n\u001b[1;32m     81\u001b[0m df\u001b[38;5;241m.\u001b[39mat[t0, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124matr_mean_ratio\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m atr_mean \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(atr_med)\n\u001b[0;32m---> 82\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43matr_slope\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m _lin_slope(w[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124matr14\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m))\n\u001b[1;32m     84\u001b[0m rvol_arr \u001b[38;5;241m=\u001b[39m w[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrvol_12h\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m     85\u001b[0m df\u001b[38;5;241m.\u001b[39mat[t0, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrvol_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mnanmean(rvol_arr))\n",
      "File \u001b[0;32m~/miniconda3/envs/binbot/lib/python3.10/site-packages/pandas/core/indexing.py:2603\u001b[0m, in \u001b[0;36m_AtIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2600\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mloc[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m   2601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 2603\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/binbot/lib/python3.10/site-packages/pandas/core/indexing.py:2543\u001b[0m, in \u001b[0;36m_ScalarAccessIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m   2541\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough indexers for scalar access (setting)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2543\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/binbot/lib/python3.10/site-packages/pandas/core/frame.py:4573\u001b[0m, in \u001b[0;36mDataFrame._set_value\u001b[0;34m(self, index, col, value, takeable)\u001b[0m\n\u001b[1;32m   4571\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4572\u001b[0m     icol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(col)\n\u001b[0;32m-> 4573\u001b[0m     iindex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4574\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mcolumn_setitem(icol, iindex, value, inplace_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   4575\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/miniconda3/envs/binbot/lib/python3.10/site-packages/pandas/core/indexes/datetimes.py:630\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(orig_key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/binbot/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m casted_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_indexer(key)\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "# ============================================================\n",
    "# FIX #1: Cache instability once per symbol (WITH PROGRESS)\n",
    "# ============================================================\n",
    "instability_cache = {}\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for sym in tqdm(pairs, desc=\"Computing instability per symbol\"):\n",
    "    if sym not in dfs:\n",
    "        continue\n",
    "\n",
    "    df = dfs[sym]\n",
    "    if df is None or df.empty:\n",
    "        continue\n",
    "\n",
    "    df_feat = compute_instability_features_over_window(df)\n",
    "    df_feat[\"is_instability\"] = classify_pre_shock_instability_v1(df_feat)\n",
    "\n",
    "    instability_cache[sym] = df_feat[[\"is_instability\"]]\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"Instability cache built in {(t1 - t0)/60:.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fab7a5-0d30-49e0-a675-3433eef53c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ---- Worker must be TOP-LEVEL for multiprocessing (do not nest it) ----\n",
    "def _worker_compute_instability(sym: str, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Returns (sym, is_instability_df) where is_instability_df has one column: ['is_instability']\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return sym, None\n",
    "\n",
    "    df_feat = compute_instability_features_over_window(df)\n",
    "    df_feat[\"is_instability\"] = classify_pre_shock_instability_v1(df_feat)\n",
    "\n",
    "    # Return only the small piece to reduce inter-process overhead\n",
    "    out = df_feat[[\"is_instability\"]].copy()\n",
    "    return sym, out\n",
    "\n",
    "\n",
    "def build_instability_cache_parallel(dfs: dict, pairs: list, n_workers: int = 12):\n",
    "    tasks = [(sym, dfs[sym]) for sym in pairs if sym in dfs and dfs[sym] is not None and not dfs[sym].empty]\n",
    "\n",
    "    instability_cache = {}\n",
    "    t0 = time.time()\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=n_workers) as ex:\n",
    "        futures = {ex.submit(_worker_compute_instability, sym, df): sym for sym, df in tasks}\n",
    "\n",
    "        for fut in tqdm(as_completed(futures), total=len(futures), desc=f\"Instability x{n_workers}\"):\n",
    "            sym = futures[fut]\n",
    "            try:\n",
    "                sym2, out = fut.result()\n",
    "                if out is not None:\n",
    "                    instability_cache[sym2] = out\n",
    "            except Exception as e:\n",
    "                print(f\"[{sym}] failed: {e}\")\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(f\"Instability cache built for {len(instability_cache)}/{len(tasks)} symbols in {(t1-t0)/60:.2f} min\")\n",
    "    return instability_cache\n",
    "\n",
    "\n",
    "# Choose how many cores to use\n",
    "N_WORKERS = 4  # you said 10–12 is fine\n",
    "instability_cache = build_instability_cache_parallel(dfs, pairs, n_workers=N_WORKERS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7504be74-7b30-4816-8664-7c404b75bdbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11149cc7-02b2-4e39-8657-ad9c05e92384",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1243553/1576788080.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;31m# Compute features ONCE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mdf_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_instability_features_over_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;31m# Compute instability flag once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0mdf_feat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"is_instability\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_pre_shock_instability_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1243553/1576788080.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(d, pre_bars, gap_bars, vol_med_win, atr_n)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mwindow_high\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"high\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mwindow_low\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"low\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mwindow_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"close\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"range_pct\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwindow_high\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwindow_low\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mwindow_close\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwindow_close\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wick_to_body_ratio\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wick_to_body_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/binbot/lib/python3.10/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2600\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2601\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2603\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/binbot/lib/python3.10/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2539\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2541\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not enough indexers for scalar access (setting)!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2543\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/binbot/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, index, col, value, takeable)\u001b[0m\n\u001b[1;32m   4585\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4586\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4587\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4589\u001b[0;31m         \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mii_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4590\u001b[0m             \u001b[0;31m# GH48729: Seems like you are trying to assign a value to a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4591\u001b[0m             \u001b[0;31m# row when only scalar options are permitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4592\u001b[0m             raise InvalidIndexError(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FIX #3: Conditional shock probability (FAST, WITH PROGRESS)\n",
    "# ============================================================\n",
    "rows = []\n",
    "horizon_bars = 24\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for sym in tqdm(pairs, desc=\"Computing conditional shock probability\"):\n",
    "    if sym not in instability_cache:\n",
    "        continue\n",
    "\n",
    "    ev = events.query(\"symbol == @sym\")\n",
    "    if ev.empty:\n",
    "        continue\n",
    "\n",
    "    df_feat = instability_cache[sym]\n",
    "    df_feat = mark_future_shock_fast(df_feat, ev, horizon_bars=horizon_bars)\n",
    "\n",
    "    n_inst = int(df_feat[\"is_instability\"].sum())\n",
    "    if n_inst < 10:\n",
    "        continue\n",
    "\n",
    "    p_base = float(df_feat[\"future_shock\"].mean())\n",
    "    p_cond = float(df_feat.loc[df_feat[\"is_instability\"], \"future_shock\"].mean())\n",
    "\n",
    "    rows.append({\n",
    "        \"symbol\": sym,\n",
    "        \"base_prob\": p_base,\n",
    "        \"cond_prob\": p_cond,\n",
    "        \"lift\": (p_cond / p_base) if p_base > 0 else np.nan,\n",
    "        \"instability_rate\": float(df_feat[\"is_instability\"].mean()),\n",
    "        \"n_instability\": n_inst,\n",
    "        \"n_shocks\": len(ev),\n",
    "    })\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"Conditional probability pass in {(t1 - t0):.2f} seconds\")\n",
    "\n",
    "prob_df = pd.DataFrame(rows).sort_values(\"lift\", ascending=False)\n",
    "prob_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13cba060-8853-41d5-be4b-c1d33807c831",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prob_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprob_df\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[1;32m      2\u001b[0m prob_df[prob_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlift\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2.0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prob_df' is not defined"
     ]
    }
   ],
   "source": [
    "prob_df.describe()\n",
    "prob_df[prob_df[\"lift\"] > 2.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c0a3abb-8de9-49a1-9750-d059d731556c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prob_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprob_df\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstability_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prob_df' is not defined"
     ]
    }
   ],
   "source": [
    "prob_df.sort_values(\"instability_rate\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (binbot)",
   "language": "python",
   "name": "binbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
