{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ata/miniconda3/envs/ml-2/bin/python\n",
      "/home/ata/miniconda3/envs/ml-2/bin/jupyter\n"
     ]
    }
   ],
   "source": [
    "# Verify that we are using the correct Python (/home/ata/miniconda3/envs/ml/bin/)\n",
    "!which python\n",
    "!which jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 15:41:08.416174: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-08 15:41:08.419008: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-08 15:41:08.425742: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736332868.440260 1538158 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736332868.444153 1538158 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-08 15:41:08.457924: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from packaging import version\n",
    "import tensorflow as tf\n",
    "\n",
    "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the class from the Python file (module)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from BinanceClient import BinanceClient\n",
    "import numpy as np\n",
    "from typing import Final\n",
    "import joblib\n",
    "from BatchFeatures import BatchFeatures\n",
    "from datetime import datetime, timedelta\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch pair data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Binance client with your API credentials\n",
    "# dotenv_path = Path('.env-secret')\n",
    "# load_dotenv(dotenv_path=dotenv_path)\n",
    "api_secret = os.getenv(\"BINANCE_SECRET_KEY\")\n",
    "api_key = os.getenv(\"BINANCE_API_KEY\")\n",
    "\n",
    "# Create Binance client & initialize it\n",
    "pair = \"BTCUSDT\"\n",
    "time_delta = 12\n",
    "db_name = pair + \"_1min_\" + str(time_delta) + \"weeks.db\"\n",
    "db_name = \"BTCUSDT_1min_dry_run.db\"             # For dry run testing\n",
    "binance_client = BinanceClient(db_name)\n",
    "binance_client.set_interval(\"1m\")\n",
    "batch_feature = BatchFeatures()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fecth Data from Binance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from Binance API...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create connection to fetch data\n",
    "binance_client.make(api_key, api_secret)\n",
    "\n",
    "# Get current server time\n",
    "server_time = binance_client.get_server_time()\n",
    "\n",
    "# Compute start and end time for the last x hours\n",
    "server_time_dt = datetime.fromtimestamp(server_time['serverTime'] / 1000, tz=datetime.timezone.utc if hasattr(datetime, 'timezone') else None)\n",
    "end_date = server_time_dt\n",
    "# start_date = server_time_dt - timedelta(hours=10)\n",
    "start_date = server_time_dt - timedelta(weeks=time_delta)\n",
    "start_date_str = int(start_date.timestamp() * 1000)  # Convert to milliseconds\n",
    "end_date_str = int(end_date.timestamp() * 1000)      # Convert to milliseconds\n",
    "\n",
    "# Fetch data\n",
    "data = binance_client.fetch_data(pair, start_date_str, end_date_str)\n",
    "binance_client.store_data_to_db(pair, data)\n",
    "\n",
    "# Check if data is fetched\n",
    "if not data.empty:\n",
    "    df = data\n",
    "else:\n",
    "    print(\"No data found!!!.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch data from db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch data from db\n",
    "df = binance_client.fetch_data_from_db(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering (mind the order since some features are dependent on others)\n",
    "bf = BatchFeatures()\n",
    "\n",
    "# Must-have features\n",
    "\n",
    "# EMA: Compute for short-term and long-term spans\n",
    "bf.calculate_ema(df, spans=[10, 50])  # Short-term (10), Long-term (50)\n",
    "\n",
    "# MACD: Standard MACD (12-26-9) and Fast MACD (6-13-5)\n",
    "bf.calculate_macd(df, spans={'standard': (12, 26, 9), 'fast': (6, 13, 5)})\n",
    "\n",
    "# RSI: Compute for default (14) and shorter-term (7) windows\n",
    "bf.calculate_rsi(df, windows=[7, 14])\n",
    "\n",
    "# Bollinger Bands: Compute for default 20-period with 2 standard deviations\n",
    "bf.calculate_bollinger_bands(df, window=20, num_std_dev=2)\n",
    "\n",
    "# Volume Features: Compute for default 20-period\n",
    "bf.calculate_volume_features(df, windows=[20])  # Include backward-compatible volume_ratio\n",
    "\n",
    "# Candle Features: Include optional 'candle_range' based on compatibility\n",
    "bf.calculate_candle_features(df, legacy_compatibility=True)  # Default behavior for backward compatibility\n",
    "\n",
    "\n",
    "# # Optionals\n",
    "# bf.calculate_sma(df)\n",
    "# bf.calculate_atr(df)\n",
    "# bf.calculate_moving_average_crossover(df)\n",
    "# bf.calculate_historical_volatility(df)\n",
    "# bf.calculate_money_flow_index(df)\n",
    "# bf.calculate_roc(df)\n",
    "# bf.calculate_stochastic_oscillator(df)\n",
    "# bf.calculate_williams_r(df)\n",
    "\n",
    "# # Low value fatures\n",
    "# bf.calculate_lagged_features(df)\n",
    "# bf.calculate_on_balance_volume(df)\n",
    "# bf.calculate_croc(df)\n",
    "\n",
    "# drop NaNs\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of candles to look ahead for predictions\n",
    "nn = 10\n",
    "\n",
    "# Predict future EMA values\n",
    "df['target_ema_10'] = df['ema_10'].shift(-nn)\n",
    "df['target_ema_50'] = df['ema_50'].shift(-nn)\n",
    "\n",
    "# Predict future MACD line and MACD signal\n",
    "df['target_macd'] = df['macd'].shift(-nn)\n",
    "df['target_macd_signal'] = df['macd_signal'].shift(-nn)\n",
    "\n",
    "# Predict future RSI values\n",
    "df['target_rsi_14'] = df['rsi_14'].shift(-nn)\n",
    "\n",
    "# Predict future Bollinger Bands\n",
    "df['target_bollinger_upper'] = df['bollinger_upper_20'].shift(-nn)\n",
    "df['target_bollinger_lower'] = df['bollinger_lower_20'].shift(-nn)\n",
    "\n",
    "# Drop rows with NaN values due to shifting\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test/Train Splot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the df into three parts, train, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lstm_scaler_derived_features.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "# Use only the last 3 hours of data for training, validation, and testing\n",
    "df_recent = df.copy().iloc[-1920*4:]  # Adjust slice as needed\n",
    "\n",
    "# Calculate split indices\n",
    "n = len(df_recent)\n",
    "train_end = int(train_ratio * n)\n",
    "val_end = train_end + int(val_ratio * n)\n",
    "\n",
    "# Perform the splits\n",
    "train_data = df_recent.iloc[:train_end]\n",
    "val_data = df_recent.iloc[train_end:val_end]\n",
    "test_data = df_recent.iloc[val_end:]\n",
    "\n",
    "# Identify target columns (derived targets for the model)\n",
    "target_columns = [\n",
    "    'target_ema_10',\n",
    "    'target_ema_50',\n",
    "    'target_macd',\n",
    "    'target_macd_signal',\n",
    "    'target_rsi_14',\n",
    "    'target_bollinger_upper',\n",
    "    'target_bollinger_lower',\n",
    "]\n",
    "\n",
    "# Separate features (X_*) and targets (y_*)\n",
    "X_train = train_data.drop(columns=target_columns)\n",
    "y_train = train_data[target_columns] / 1e5 # normalize\n",
    "\n",
    "X_valid = val_data.drop(columns=target_columns)\n",
    "y_valid = val_data[target_columns] / 1e5 # normalize\n",
    "\n",
    "X_test = test_data.drop(columns=target_columns)\n",
    "y_test = test_data[target_columns] / 1e5 # normalize\n",
    "\n",
    "# Initialize the scaler and scale only the X_* components\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training features and transform\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "\n",
    "# Transform validation and test features\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_valid_scaled = pd.DataFrame(X_valid_scaled, columns=X_valid.columns, index=X_valid.index)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# Save the scaler for later use\n",
    "joblib.dump(scaler, 'lstm_scaler_derived_features.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomize the time sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence length (5 hours = 300 instances for 1-minute resolution)\n",
    "seq_length = 60\n",
    "batch_size = 32 * 4\n",
    "\n",
    "# Create time series datasets\n",
    "tf.random.set_seed(42)  # Ensures reproducibility\n",
    "\n",
    "# Training dataset\n",
    "train_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    data=X_train_scaled.iloc[:-seq_length].to_numpy(),  # Exclude the last 'seq_length' rows for input\n",
    "    targets=y_train.iloc[seq_length:].to_numpy(),  # Shift target by 'seq_length'\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Validation dataset\n",
    "valid_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    data=X_valid_scaled.iloc[:-seq_length].to_numpy(),\n",
    "    targets=y_valid.iloc[seq_length:].to_numpy(),  # Ensure alignment with shifted targets\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_per_target(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate MAE for each target individually and return the mean (scalar).\n",
    "    \"\"\"\n",
    "    # Ensure consistent data types\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    # Compute absolute error per target\n",
    "    abs_error = tf.abs(y_true - y_pred)\n",
    "\n",
    "    # Calculate mean error per target\n",
    "    per_target_mae = tf.reduce_mean(abs_error, axis=0)\n",
    "\n",
    "    # Return the aggregated mean for compatibility with Keras\n",
    "    return tf.reduce_mean(per_target_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mvar_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom loss function for MVAR: Computes MAE per target and averages them.\n",
    "    \"\"\"\n",
    "    # Ensure both y_true and y_pred are the same data type\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    # Compute absolute errors for all targets\n",
    "    abs_error = tf.abs(y_true - y_pred)\n",
    "\n",
    "    # Take mean across the batch dimension for each target\n",
    "    mae_per_target = tf.reduce_mean(abs_error, axis=0)\n",
    "\n",
    "    # Aggregate by averaging across targets\n",
    "    loss = tf.reduce_mean(mae_per_target)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_evaluate_mvar(model, train_set, valid_set, learning_rate, epochs=500):\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=50, restore_best_weights=True\n",
    "    )\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(\n",
    "        loss=custom_mvar_loss,\n",
    "        optimizer=opt,\n",
    "        metrics=[mae_per_target],  # Collective MAE across all targets\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_set, validation_data=valid_set, epochs=epochs, callbacks=[early_stopping_cb]\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    results = model.evaluate(valid_set, return_dict=True)\n",
    "\n",
    "    # Extract predictions and calculate per-target MAE manually\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for x_batch, y_batch in valid_set:\n",
    "        y_true.append(y_batch.numpy())\n",
    "        y_pred.append(model.predict(x_batch))\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    per_target_mae = np.mean(np.abs(y_true - y_pred), axis=0)\n",
    "    per_target_metrics = {f\"target_{i}_mae\": mae for i, mae in enumerate(per_target_mae)}\n",
    "\n",
    "    return per_target_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivar LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ata/miniconda3/envs/ml-2/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(64, activation=\"relu\", return_sequences=True, input_shape=[None, X_train_scaled.shape[1]]),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.LSTM(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(len(target_columns))  # Number of output neurons matches the number of target variables\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - loss: 15865.4707 - mae_per_target: 15858.1055 - val_loss: 1011.1753 - val_mae_per_target: 1076.2124\n",
      "Epoch 2/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 553.8893 - mae_per_target: 553.5843 - val_loss: 287.3329 - val_mae_per_target: 301.6217\n",
      "Epoch 3/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 1653.8323 - mae_per_target: 1652.7106 - val_loss: 1204.1383 - val_mae_per_target: 1239.8429\n",
      "Epoch 4/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 1732.1566 - mae_per_target: 1730.9668 - val_loss: 536.7826 - val_mae_per_target: 572.3749\n",
      "Epoch 5/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 9234.9287 - mae_per_target: 9219.1045 - val_loss: 755.4918 - val_mae_per_target: 798.2376\n",
      "Epoch 6/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 2508.2471 - mae_per_target: 2506.7146 - val_loss: 4.2547 - val_mae_per_target: 4.2547\n",
      "Epoch 7/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 269.0499 - mae_per_target: 269.1399 - val_loss: 4.2459 - val_mae_per_target: 4.2459\n",
      "Epoch 8/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 327.1854 - mae_per_target: 326.8964 - val_loss: 4.2350 - val_mae_per_target: 4.2350\n",
      "Epoch 9/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 211.7581 - mae_per_target: 212.1112 - val_loss: 4.2222 - val_mae_per_target: 4.2223\n",
      "Epoch 10/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 232.4159 - mae_per_target: 232.3453 - val_loss: 4.2080 - val_mae_per_target: 4.2081\n",
      "Epoch 11/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 151.5258 - mae_per_target: 151.6734 - val_loss: 4.1941 - val_mae_per_target: 4.1942\n",
      "Epoch 12/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 228.7072 - mae_per_target: 228.4523 - val_loss: 4.1790 - val_mae_per_target: 4.1791\n",
      "Epoch 13/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 113.7517 - mae_per_target: 113.7574 - val_loss: 4.1641 - val_mae_per_target: 4.1641\n",
      "Epoch 14/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 105.0589 - mae_per_target: 105.0492 - val_loss: 4.1497 - val_mae_per_target: 4.1498\n",
      "Epoch 15/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 92.6751 - mae_per_target: 92.5371 - val_loss: 4.1340 - val_mae_per_target: 4.1341\n",
      "Epoch 16/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 88.4482 - mae_per_target: 88.6060 - val_loss: 4.1166 - val_mae_per_target: 4.1167\n",
      "Epoch 17/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 90.8294 - mae_per_target: 90.7905 - val_loss: 4.0992 - val_mae_per_target: 4.0992\n",
      "Epoch 18/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 71.7388 - mae_per_target: 71.7105 - val_loss: 4.0820 - val_mae_per_target: 4.0821\n",
      "Epoch 19/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 60.5272 - mae_per_target: 60.5616 - val_loss: 4.0643 - val_mae_per_target: 4.0644\n",
      "Epoch 20/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 90.6663 - mae_per_target: 90.5637 - val_loss: 4.0464 - val_mae_per_target: 4.0464\n",
      "Epoch 21/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 58.9513 - mae_per_target: 58.9168 - val_loss: 4.0298 - val_mae_per_target: 4.0299\n",
      "Epoch 22/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 52.5276 - mae_per_target: 52.5055 - val_loss: 4.0160 - val_mae_per_target: 4.0161\n",
      "Epoch 23/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 52.7763 - mae_per_target: 52.7689 - val_loss: 4.0023 - val_mae_per_target: 4.0024\n",
      "Epoch 24/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 57.7246 - mae_per_target: 57.7542 - val_loss: 3.9876 - val_mae_per_target: 3.9877\n",
      "Epoch 25/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 77.3796 - mae_per_target: 77.3998 - val_loss: 3.9740 - val_mae_per_target: 3.9740\n",
      "Epoch 26/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 60.6968 - mae_per_target: 60.6501 - val_loss: 3.9616 - val_mae_per_target: 3.9616\n",
      "Epoch 27/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 39.6809 - mae_per_target: 39.6682 - val_loss: 3.9460 - val_mae_per_target: 3.9461\n",
      "Epoch 28/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 39.6418 - mae_per_target: 39.6515 - val_loss: 3.9311 - val_mae_per_target: 3.9313\n",
      "Epoch 29/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 37.9655 - mae_per_target: 38.0419 - val_loss: 3.9153 - val_mae_per_target: 3.9154\n",
      "Epoch 30/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 88.0643 - mae_per_target: 87.9843 - val_loss: 3.8967 - val_mae_per_target: 3.8968\n",
      "Epoch 31/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 33.7248 - mae_per_target: 33.7012 - val_loss: 3.8770 - val_mae_per_target: 3.8771\n",
      "Epoch 32/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 24.4807 - mae_per_target: 24.4834 - val_loss: 3.8565 - val_mae_per_target: 3.8566\n",
      "Epoch 33/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 32.8520 - mae_per_target: 32.8246 - val_loss: 3.8383 - val_mae_per_target: 3.8384\n",
      "Epoch 34/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 23.8937 - mae_per_target: 23.9104 - val_loss: 3.8165 - val_mae_per_target: 3.8167\n",
      "Epoch 35/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 47.3708 - mae_per_target: 47.3361 - val_loss: 3.7950 - val_mae_per_target: 3.7952\n",
      "Epoch 36/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 27.4180 - mae_per_target: 27.5106 - val_loss: 3.7715 - val_mae_per_target: 3.7716\n",
      "Epoch 37/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 65.2957 - mae_per_target: 65.2549 - val_loss: 3.7484 - val_mae_per_target: 3.7485\n",
      "Epoch 38/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 27.2094 - mae_per_target: 27.1998 - val_loss: 3.7243 - val_mae_per_target: 3.7244\n",
      "Epoch 39/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 21.2661 - mae_per_target: 21.2600 - val_loss: 3.7001 - val_mae_per_target: 3.7002\n",
      "Epoch 40/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 19.8767 - mae_per_target: 19.8683 - val_loss: 3.6759 - val_mae_per_target: 3.6761\n",
      "Epoch 41/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 20.9405 - mae_per_target: 20.9261 - val_loss: 3.6525 - val_mae_per_target: 3.6526\n",
      "Epoch 42/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 20.0637 - mae_per_target: 20.0754 - val_loss: 3.6263 - val_mae_per_target: 3.6265\n",
      "Epoch 43/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 31.2441 - mae_per_target: 31.2440 - val_loss: 3.6013 - val_mae_per_target: 3.6015\n",
      "Epoch 44/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 20.1674 - mae_per_target: 20.1533 - val_loss: 3.5736 - val_mae_per_target: 3.5738\n",
      "Epoch 45/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 18.7867 - mae_per_target: 18.7716 - val_loss: 3.5472 - val_mae_per_target: 3.5474\n",
      "Epoch 46/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 17.4554 - mae_per_target: 17.4536 - val_loss: 3.5205 - val_mae_per_target: 3.5207\n",
      "Epoch 47/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 22.6853 - mae_per_target: 22.6651 - val_loss: 3.4930 - val_mae_per_target: 3.4932\n",
      "Epoch 48/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 15.2499 - mae_per_target: 15.2551 - val_loss: 3.4634 - val_mae_per_target: 3.4637\n",
      "Epoch 49/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 21.9171 - mae_per_target: 21.8999 - val_loss: 3.4322 - val_mae_per_target: 3.4329\n",
      "Epoch 50/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 17.8175 - mae_per_target: 17.7983 - val_loss: 3.3587 - val_mae_per_target: 3.3596\n",
      "Epoch 51/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 20.1245 - mae_per_target: 20.0626 - val_loss: 39196.0078 - val_mae_per_target: 36159.5820\n",
      "Epoch 52/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 28421.3105 - mae_per_target: 28403.6758 - val_loss: 4.9704 - val_mae_per_target: 4.8536\n",
      "Epoch 53/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 414.9996 - mae_per_target: 414.7374 - val_loss: 3.4191 - val_mae_per_target: 3.4235\n",
      "Epoch 54/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 245.6393 - mae_per_target: 245.4601 - val_loss: 3.4258 - val_mae_per_target: 3.4312\n",
      "Epoch 55/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 58.5956 - mae_per_target: 58.6015 - val_loss: 3.4003 - val_mae_per_target: 3.4058\n",
      "Epoch 56/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 64.2743 - mae_per_target: 64.3852 - val_loss: 3.3935 - val_mae_per_target: 3.3992\n",
      "Epoch 57/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 104.7131 - mae_per_target: 104.6479 - val_loss: 3.3709 - val_mae_per_target: 3.3764\n",
      "Epoch 58/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 49.7937 - mae_per_target: 49.7476 - val_loss: 3.3383 - val_mae_per_target: 3.3430\n",
      "Epoch 59/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 34.4442 - mae_per_target: 34.4704 - val_loss: 3.3490 - val_mae_per_target: 3.3547\n",
      "Epoch 60/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 49.4680 - mae_per_target: 49.4178 - val_loss: 3.3232 - val_mae_per_target: 3.3287\n",
      "Epoch 61/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 32.0983 - mae_per_target: 32.0616 - val_loss: 3.3063 - val_mae_per_target: 3.3117\n",
      "Epoch 62/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 25.0677 - mae_per_target: 25.0639 - val_loss: 3.2802 - val_mae_per_target: 3.2852\n",
      "Epoch 63/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 28.6765 - mae_per_target: 28.6827 - val_loss: 3.2588 - val_mae_per_target: 3.2638\n",
      "Epoch 64/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 26.6065 - mae_per_target: 26.5980 - val_loss: 3.2414 - val_mae_per_target: 3.2464\n",
      "Epoch 65/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 23.5029 - mae_per_target: 23.4828 - val_loss: 3.2249 - val_mae_per_target: 3.2300\n",
      "Epoch 66/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 22.6490 - mae_per_target: 22.6661 - val_loss: 3.2091 - val_mae_per_target: 3.2145\n",
      "Epoch 67/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 31.2081 - mae_per_target: 31.1907 - val_loss: 3.1778 - val_mae_per_target: 3.1828\n",
      "Epoch 68/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 29.0843 - mae_per_target: 29.0744 - val_loss: 3.1531 - val_mae_per_target: 3.1579\n",
      "Epoch 69/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 27.1771 - mae_per_target: 27.1597 - val_loss: 3.1215 - val_mae_per_target: 3.1253\n",
      "Epoch 70/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 27.5049 - mae_per_target: 27.4774 - val_loss: 3.1004 - val_mae_per_target: 3.1043\n",
      "Epoch 71/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 38.1995 - mae_per_target: 38.1537 - val_loss: 3.0786 - val_mae_per_target: 3.0825\n",
      "Epoch 72/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 56.0425 - mae_per_target: 55.9986 - val_loss: 3.0578 - val_mae_per_target: 3.0618\n",
      "Epoch 73/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 33.9990 - mae_per_target: 33.9852 - val_loss: 3.0400 - val_mae_per_target: 3.0442\n",
      "Epoch 74/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 36.4482 - mae_per_target: 36.4387 - val_loss: 3.0156 - val_mae_per_target: 3.0198\n",
      "Epoch 75/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 34.1425 - mae_per_target: 34.1088 - val_loss: 3.0026 - val_mae_per_target: 3.0073\n",
      "Epoch 76/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 23.5221 - mae_per_target: 23.5614 - val_loss: 2.9891 - val_mae_per_target: 2.9943\n",
      "Epoch 77/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 80.8740 - mae_per_target: 80.8223 - val_loss: 2.9654 - val_mae_per_target: 2.9701\n",
      "Epoch 78/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 45.9633 - mae_per_target: 45.9410 - val_loss: 2.9464 - val_mae_per_target: 2.9516\n",
      "Epoch 79/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 29.7727 - mae_per_target: 29.8372 - val_loss: 2.9236 - val_mae_per_target: 2.9289\n",
      "Epoch 80/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 107.7211 - mae_per_target: 107.6483 - val_loss: 2.8941 - val_mae_per_target: 2.8993\n",
      "Epoch 81/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 21.3668 - mae_per_target: 21.3542 - val_loss: 2.8651 - val_mae_per_target: 2.8700\n",
      "Epoch 82/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 15.9148 - mae_per_target: 15.9336 - val_loss: 2.8388 - val_mae_per_target: 2.8436\n",
      "Epoch 83/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 28.9707 - mae_per_target: 28.9748 - val_loss: 2.8169 - val_mae_per_target: 2.8217\n",
      "Epoch 84/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 12.5354 - mae_per_target: 12.5400 - val_loss: 2.7881 - val_mae_per_target: 2.7928\n",
      "Epoch 85/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 14.7304 - mae_per_target: 14.7308 - val_loss: 2.7624 - val_mae_per_target: 2.7670\n",
      "Epoch 86/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 14.5716 - mae_per_target: 14.5726 - val_loss: 2.7410 - val_mae_per_target: 2.7457\n",
      "Epoch 87/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 18.3896 - mae_per_target: 18.3921 - val_loss: 2.7189 - val_mae_per_target: 2.7237\n",
      "Epoch 88/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 11.4952 - mae_per_target: 11.5037 - val_loss: 2.6965 - val_mae_per_target: 2.7012\n",
      "Epoch 89/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 38.2557 - mae_per_target: 38.2218 - val_loss: 2.6693 - val_mae_per_target: 2.6741\n",
      "Epoch 90/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 13.0358 - mae_per_target: 13.1552 - val_loss: 2.6597 - val_mae_per_target: 2.6650\n",
      "Epoch 91/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 10.4358 - mae_per_target: 10.4246 - val_loss: 2.7805 - val_mae_per_target: 2.7938\n",
      "Epoch 92/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 13.8310 - mae_per_target: 13.8406 - val_loss: 2.7813 - val_mae_per_target: 2.7980\n",
      "Epoch 93/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 28.7064 - mae_per_target: 28.6833 - val_loss: 2.9190 - val_mae_per_target: 2.9492\n",
      "Epoch 94/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 2565962.5000 - mae_per_target: 2561660.5000 - val_loss: 3.2353 - val_mae_per_target: 3.1943\n",
      "Epoch 95/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 765.9377 - mae_per_target: 765.5622 - val_loss: 2.8423 - val_mae_per_target: 2.8305\n",
      "Epoch 96/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 211.3230 - mae_per_target: 211.1715 - val_loss: 2.8198 - val_mae_per_target: 2.8092\n",
      "Epoch 97/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 199.2468 - mae_per_target: 199.0954 - val_loss: 2.8147 - val_mae_per_target: 2.8041\n",
      "Epoch 98/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 186.2527 - mae_per_target: 186.0809 - val_loss: 2.8195 - val_mae_per_target: 2.8082\n",
      "Epoch 99/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 187.0835 - mae_per_target: 187.1899 - val_loss: 2.8210 - val_mae_per_target: 2.8095\n",
      "Epoch 100/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 195.4984 - mae_per_target: 195.5050 - val_loss: 2.8262 - val_mae_per_target: 2.8144\n",
      "Epoch 101/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 184.6949 - mae_per_target: 184.6292 - val_loss: 2.8324 - val_mae_per_target: 2.8202\n",
      "Epoch 102/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 179.6920 - mae_per_target: 179.9566 - val_loss: 2.8383 - val_mae_per_target: 2.8251\n",
      "Epoch 103/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 174.7612 - mae_per_target: 174.6071 - val_loss: 8.1416 - val_mae_per_target: 8.3050\n",
      "Epoch 104/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 149.2805 - mae_per_target: 149.4962 - val_loss: 5.7421 - val_mae_per_target: 5.8765\n",
      "Epoch 105/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 140.1587 - mae_per_target: 140.3463 - val_loss: 40.9905 - val_mae_per_target: 42.2556\n",
      "Epoch 106/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 133.1520 - mae_per_target: 133.4403 - val_loss: 97.7514 - val_mae_per_target: 100.8180\n",
      "Epoch 107/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 145.8278 - mae_per_target: 145.7194 - val_loss: 68.4985 - val_mae_per_target: 70.6441\n",
      "Epoch 108/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 114.8486 - mae_per_target: 114.7791 - val_loss: 69.8137 - val_mae_per_target: 72.0270\n",
      "Epoch 109/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 110.0315 - mae_per_target: 110.0320 - val_loss: 83.5629 - val_mae_per_target: 86.2731\n",
      "Epoch 110/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 99.6864 - mae_per_target: 99.7480 - val_loss: 64.5940 - val_mae_per_target: 66.7374\n",
      "Epoch 111/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 87.8975 - mae_per_target: 87.8837 - val_loss: 56.3879 - val_mae_per_target: 58.1760\n",
      "Epoch 112/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 62.6427 - mae_per_target: 62.6095 - val_loss: 46.8891 - val_mae_per_target: 48.3876\n",
      "Epoch 113/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 58.5539 - mae_per_target: 58.5484 - val_loss: 63.6051 - val_mae_per_target: 65.6218\n",
      "Epoch 114/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 50.6559 - mae_per_target: 50.6284 - val_loss: 43.9754 - val_mae_per_target: 45.3342\n",
      "Epoch 115/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 46.7380 - mae_per_target: 46.7095 - val_loss: 32.6123 - val_mae_per_target: 33.7018\n",
      "Epoch 116/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 46.5930 - mae_per_target: 46.5812 - val_loss: 27.1940 - val_mae_per_target: 28.0672\n",
      "Epoch 117/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 41.6547 - mae_per_target: 41.6491 - val_loss: 33.8736 - val_mae_per_target: 34.9564\n",
      "Epoch 118/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 37.3644 - mae_per_target: 37.3597 - val_loss: 35.3721 - val_mae_per_target: 36.5069\n",
      "Epoch 119/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 32.9776 - mae_per_target: 32.9878 - val_loss: 68.2271 - val_mae_per_target: 70.4051\n",
      "Epoch 120/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 51.0467 - mae_per_target: 51.0379 - val_loss: 24.8530 - val_mae_per_target: 25.6466\n",
      "Epoch 121/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 28.7585 - mae_per_target: 28.7476 - val_loss: 38.9009 - val_mae_per_target: 40.1647\n",
      "Epoch 122/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 36.1690 - mae_per_target: 36.1631 - val_loss: 31.1191 - val_mae_per_target: 32.0614\n",
      "Epoch 123/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 31.9848 - mae_per_target: 31.9733 - val_loss: 23.4396 - val_mae_per_target: 24.1598\n",
      "Epoch 124/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 33.2097 - mae_per_target: 33.2078 - val_loss: 43.3697 - val_mae_per_target: 44.7490\n",
      "Epoch 125/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 36.6129 - mae_per_target: 36.6357 - val_loss: 30.7240 - val_mae_per_target: 31.7290\n",
      "Epoch 126/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 30.8198 - mae_per_target: 30.8313 - val_loss: 44.3739 - val_mae_per_target: 45.8157\n",
      "Epoch 127/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 33.0491 - mae_per_target: 33.0696 - val_loss: 24.8622 - val_mae_per_target: 25.6747\n",
      "Epoch 128/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 26.3788 - mae_per_target: 26.3709 - val_loss: 14.0979 - val_mae_per_target: 14.5081\n",
      "Epoch 129/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 26.3442 - mae_per_target: 26.3570 - val_loss: 27.0960 - val_mae_per_target: 27.9644\n",
      "Epoch 130/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 28.9616 - mae_per_target: 28.9556 - val_loss: 35.4717 - val_mae_per_target: 36.5936\n",
      "Epoch 131/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 26.2868 - mae_per_target: 26.2745 - val_loss: 24.0591 - val_mae_per_target: 24.7959\n",
      "Epoch 132/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 25.4590 - mae_per_target: 25.4540 - val_loss: 28.0275 - val_mae_per_target: 28.9854\n",
      "Epoch 133/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 23.7514 - mae_per_target: 23.7521 - val_loss: 31.8614 - val_mae_per_target: 32.9249\n",
      "Epoch 134/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 23.8031 - mae_per_target: 23.7964 - val_loss: 34.3745 - val_mae_per_target: 35.4657\n",
      "Epoch 135/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 27.2728 - mae_per_target: 27.2781 - val_loss: 25.5339 - val_mae_per_target: 26.3524\n",
      "Epoch 136/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 30.8593 - mae_per_target: 30.8362 - val_loss: 20.2748 - val_mae_per_target: 20.9563\n",
      "Epoch 137/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 21.1607 - mae_per_target: 21.1489 - val_loss: 33.2418 - val_mae_per_target: 34.2669\n",
      "Epoch 138/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 22.3157 - mae_per_target: 22.3102 - val_loss: 13.7556 - val_mae_per_target: 14.1744\n",
      "Epoch 139/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 18.3772 - mae_per_target: 18.4039 - val_loss: 20.2402 - val_mae_per_target: 20.9279\n",
      "Epoch 140/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 23.9035 - mae_per_target: 23.9008 - val_loss: 17.5958 - val_mae_per_target: 18.1939\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6333 - mae_per_target: 2.6341\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
      "target_0_mae: 4.1643\n",
      "target_1_mae: 4.6614\n",
      "target_2_mae: 0.0148\n",
      "target_3_mae: 0.1292\n",
      "target_4_mae: 0.7091\n",
      "target_5_mae: 4.5446\n",
      "target_6_mae: 4.3946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 16:01:26.217885: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate the model\n",
    "metrics = fit_and_evaluate_mvar(model, train_ds, valid_ds, learning_rate=0.001, epochs=500)\n",
    "\n",
    "# Display per-target MAE\n",
    "for target, mae in metrics.items():\n",
    "    print(f\"{target}: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trtained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lstm_10candles_1min.joblib']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "joblib.dump(model, 'lstm_multivar_10candles_1min.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load previously trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model\n",
    "model = joblib.load('lstm_multivar_10candles_1min.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for target_ema_10:\n",
      "  Absolute Mean: 0.9504\n",
      "  Standard Deviation: 0.0151\n",
      "  Minimum Value: 0.9182\n",
      "  Maximum Value: 0.9719\n",
      "----------------------------------------\n",
      "Statistics for target_ema_50:\n",
      "  Absolute Mean: 0.9502\n",
      "  Standard Deviation: 0.0147\n",
      "  Minimum Value: 0.9223\n",
      "  Maximum Value: 0.9710\n",
      "----------------------------------------\n",
      "Statistics for target_macd:\n",
      "  Absolute Mean: 0.0006\n",
      "  Standard Deviation: 0.0015\n",
      "  Minimum Value: -0.0021\n",
      "  Maximum Value: 0.0132\n",
      "----------------------------------------\n",
      "Statistics for target_macd_signal:\n",
      "  Absolute Mean: 0.0006\n",
      "  Standard Deviation: 0.0014\n",
      "  Minimum Value: -0.0018\n",
      "  Maximum Value: 0.0116\n",
      "----------------------------------------\n",
      "Statistics for target_rsi_14:\n",
      "  Absolute Mean: 0.0005\n",
      "  Standard Deviation: 0.0002\n",
      "  Minimum Value: 0.0000\n",
      "  Maximum Value: 0.0010\n",
      "----------------------------------------\n",
      "Statistics for target_bollinger_upper:\n",
      "  Absolute Mean: 0.9526\n",
      "  Standard Deviation: 0.0156\n",
      "  Minimum Value: 0.9229\n",
      "  Maximum Value: 1.0018\n",
      "----------------------------------------\n",
      "Statistics for target_bollinger_lower:\n",
      "  Absolute Mean: 0.9482\n",
      "  Standard Deviation: 0.0160\n",
      "  Minimum Value: 0.8868\n",
      "  Maximum Value: 0.9704\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each target column in y_test\n",
    "for target in y_test.columns:\n",
    "    print(f\"Statistics for {target}:\")\n",
    "    print(f\"  Absolute Mean: {y_test[target].abs().mean():.4f}\")\n",
    "    print(f\"  Standard Deviation: {y_test[target].std():.4f}\")\n",
    "    print(f\"  Minimum Value: {y_test[target].min():.4f}\")\n",
    "    print(f\"  Maximum Value: {y_test[target].max():.4f}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_BALANCE=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "                         open      high       low     close   volume  \\\n",
      "timestamp                                                              \n",
      "2024-12-30 03:20:00  93970.01  94023.30  93966.66  94023.30  4.86591   \n",
      "2024-12-30 03:21:00  94023.30  94023.30  93964.42  93964.42  4.72563   \n",
      "2024-12-30 03:22:00  93964.43  93964.43  93896.58  93952.52  5.19245   \n",
      "2024-12-30 03:23:00  93952.51  93955.32  93860.62  93860.63  4.21085   \n",
      "2024-12-30 03:24:00  93860.62  93860.63  93824.61  93851.09  3.45070   \n",
      "\n",
      "                           ema_10        ema_50       macd  macd_signal  \\\n",
      "timestamp                                                                 \n",
      "2024-12-30 03:20:00  94002.906588  93858.902875  56.272919    69.077061   \n",
      "2024-12-30 03:21:00  93995.909026  93863.040802  49.398179    65.141284   \n",
      "2024-12-30 03:22:00  93988.020112  93866.549790  42.499757    60.612979   \n",
      "2024-12-30 03:23:00  93964.858274  93866.317641  29.280425    54.346468   \n",
      "2024-12-30 03:24:00  93944.173133  93865.720479  17.828694    47.042913   \n",
      "\n",
      "                     macd_hist  ...  Predicted target_macd  \\\n",
      "timestamp                       ...                          \n",
      "2024-12-30 03:20:00 -12.804142  ...           -1185.868164   \n",
      "2024-12-30 03:21:00 -15.743105  ...           -2044.829224   \n",
      "2024-12-30 03:22:00 -18.113222  ...           -2993.131592   \n",
      "2024-12-30 03:23:00 -25.066043  ...           -3367.000732   \n",
      "2024-12-30 03:24:00 -29.214219  ...           -3719.925049   \n",
      "\n",
      "                     Actual target_macd  Predicted target_macd_signal  \\\n",
      "timestamp                                                               \n",
      "2024-12-30 03:20:00           -6.440139                  19311.162109   \n",
      "2024-12-30 03:21:00          -14.898270                  23598.570312   \n",
      "2024-12-30 03:22:00          -19.526854                  27080.296875   \n",
      "2024-12-30 03:23:00          -19.419940                  29469.281250   \n",
      "2024-12-30 03:24:00          -21.746547                  29569.533203   \n",
      "\n",
      "                     Actual target_macd_signal  Predicted target_rsi_14  \\\n",
      "timestamp                                                                 \n",
      "2024-12-30 03:20:00                  12.808346             78522.882812   \n",
      "2024-12-30 03:21:00                   7.267023             80610.789062   \n",
      "2024-12-30 03:22:00                   1.908247             82144.953125   \n",
      "2024-12-30 03:23:00                  -2.357390             82610.867188   \n",
      "2024-12-30 03:24:00                  -6.235222             83491.414062   \n",
      "\n",
      "                     Actual target_rsi_14  Predicted target_bollinger_upper  \\\n",
      "timestamp                                                                     \n",
      "2024-12-30 03:20:00             35.376492                       548809.5000   \n",
      "2024-12-30 03:21:00             29.721585                       549092.1250   \n",
      "2024-12-30 03:22:00             32.089392                       549394.4375   \n",
      "2024-12-30 03:23:00             40.420763                       549350.0625   \n",
      "2024-12-30 03:24:00             31.960523                       549403.3125   \n",
      "\n",
      "                     Actual target_bollinger_upper  \\\n",
      "timestamp                                            \n",
      "2024-12-30 03:20:00                   94080.615646   \n",
      "2024-12-30 03:21:00                   94081.703243   \n",
      "2024-12-30 03:22:00                   94083.368569   \n",
      "2024-12-30 03:23:00                   94075.780919   \n",
      "2024-12-30 03:24:00                   94066.225754   \n",
      "\n",
      "                     Predicted target_bollinger_lower  \\\n",
      "timestamp                                               \n",
      "2024-12-30 03:20:00                       539668.9375   \n",
      "2024-12-30 03:21:00                       540088.0625   \n",
      "2024-12-30 03:22:00                       540127.9375   \n",
      "2024-12-30 03:23:00                       541260.8125   \n",
      "2024-12-30 03:24:00                       541756.1250   \n",
      "\n",
      "                     Actual target_bollinger_lower  \n",
      "timestamp                                           \n",
      "2024-12-30 03:20:00                   93822.874354  \n",
      "2024-12-30 03:21:00                   93799.020757  \n",
      "2024-12-30 03:22:00                   93782.507431  \n",
      "2024-12-30 03:23:00                   93776.290081  \n",
      "2024-12-30 03:24:00                   93767.473246  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "# Generate sequences for LSTM input\n",
    "X_test_copy = X_test_scaled.copy()\n",
    "y_test_copy = y_test.copy()\n",
    "X_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "# Create sequences for test data\n",
    "for i in range(seq_length, len(X_test_copy)):\n",
    "    X_test_list.append(X_test_copy.iloc[i - seq_length:i].to_numpy())  # Create sequence\n",
    "    y_test_list.append(y_test_copy.iloc[i])\n",
    "\n",
    "X_test_list = np.array(X_test_list)\n",
    "y_test_list = np.array(y_test_list)\n",
    "\n",
    "# Generate predictions\n",
    "predictions_scaled = model.predict(X_test_list)  # Predictions are in scaled space\n",
    "\n",
    "# Unscale predictions and actual values\n",
    "X_test_reversed = scaler.inverse_transform(X_test_scaled)  # Reverse scale inputs if needed\n",
    "predictions_unscaled = predictions_scaled * 1e5  # Assuming y_* scaling was 1e5\n",
    "actuals = y_test_list * 1e5\n",
    "\n",
    "# Ensure lengths match\n",
    "results_length = len(X_test_copy) - seq_length\n",
    "predictions = predictions[:results_length]  # Adjust predictions to match available rows\n",
    "actuals = actuals[:results_length]  # Adjust actuals similarly\n",
    "\n",
    "# Convert predictions and actuals to a DataFrame for analysis\n",
    "results_df = X_test.iloc[seq_length:seq_length + results_length].copy()  # Align indices with available rows\n",
    "for i, target_name in enumerate(y_test.columns):\n",
    "    results_df[f\"Predicted {target_name}\"] = predictions[:, i]\n",
    "    results_df[f\"Actual {target_name}\"] = actuals[:, i]\n",
    "\n",
    "# Display or save the results\n",
    "print(results_df.head())\n",
    "\n",
    "# Optional: Save the results to a CSV file for detailed analysis\n",
    "results_df.to_csv(\"predictions_vs_actuals.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('results_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df['Actual Future Price'] = results_df['close']  # Actual future close price\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(12, 7))\n",
    "# results_df['Predicted Price'].plot()\n",
    "# results_df['close'].plot()\n",
    "results_df['Predicted Change'].plot()\n",
    "results_df['Actual Change'].plot()\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Change: -0.5142806172370911\n",
      "Max Change: 0.9654271602630615\n"
     ]
    }
   ],
   "source": [
    "predict_ch_min = results_df[\"Predicted Change\"].min()\n",
    "predict_ch_max = results_df[\"Predicted Change\"].max()\n",
    "print(f'Min Change: {predict_ch_min}')\n",
    "print(f'Max Change: {predict_ch_max}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_trades(signals, prices, initial_balance=1000):\n",
    "    \"\"\"\n",
    "    Simulates trades based on signals and actual price changes.\n",
    "\n",
    "    Args:\n",
    "        actual_changes (list or pd.Series): Actual percentage changes (not predicted).\n",
    "        signals (list): List of trading signals (\"Buy\", \"Sell\", \"Hold\").\n",
    "        prices (list or pd.Series): Actual price values for the asset.\n",
    "        initial_balance (float): Starting balance of the trading account.\n",
    "\n",
    "    Returns:\n",
    "        float: Final balance or cumulative profit.\n",
    "    \"\"\"\n",
    "    balance = INITIAL_BALANCE\n",
    "    position = 0  # Tracks the number of stocks held\n",
    "    entry_price = None  # Store the price when a \"Buy\" was executed\n",
    "\n",
    "    for i, signal in enumerate(signals):\n",
    "        if signal == 1 and balance > 0:\n",
    "            # Execute a buy\n",
    "            entry_price = prices.iloc[i]  # Use .iloc for positional indexing\n",
    "            position = balance / entry_price  # Buy with all available balance\n",
    "            balance = 0  # All balance used to buy\n",
    "        elif signal == -1 and position > 0:\n",
    "            # Execute a sell\n",
    "            exit_price = prices.iloc[i]  # Use .iloc for positional indexing\n",
    "            balance = position * exit_price  # Convert position to cash\n",
    "            position = 0  # Clear position\n",
    "            entry_price = None  # Reset entry price after selling\n",
    "\n",
    "    # If there's a remaining position at the end, calculate its value\n",
    "    if position > 0 and entry_price is not None:\n",
    "        balance += position * prices.iloc[-1]  # Use .iloc for positional indexing\n",
    "\n",
    "    return balance - INITIAL_BALANCE  # Return cumulative profit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "results_df[\"Predicted Change\"].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Buy Threshold: 0.3051, Best Sell Threshold: -0.054280617237090656\n",
      "Best Performance: 11.989245237638102\n"
     ]
    }
   ],
   "source": [
    "# Define buy and sell thresholds (e.g., absolute differences in predicted vs. actual price)\n",
    "sell_thresholds = np.arange(predict_ch_min, -0.0001, 0.005)  # Thresholds for when to \"Sell\"; Sell when price is predicted to go down\n",
    "buy_thresholds = np.arange(0.0001, predict_ch_max, 0.005)   # Thresholds for when to \"Buy\"; buy when price is predicted to go up\n",
    "\n",
    "best_buy_threshold = None\n",
    "best_sell_threshold = None\n",
    "best_performance = -np.inf\n",
    "\n",
    "ii = 0\n",
    "jj = 0\n",
    "performance = np.zeros((len(buy_thresholds), len(sell_thresholds)))\n",
    "# -1 = Sell\n",
    "# 0 = Hold\n",
    "# 1 = Buy\n",
    "for buy_th in buy_thresholds:\n",
    "    for sell_th in sell_thresholds:\n",
    "        # Generate signals\n",
    "        trading_signals = [\n",
    "            -1 if pred < sell_th else 1 if pred > buy_th else 0\n",
    "            for pred in results_df['Predicted Change']\n",
    "        ]\n",
    "\n",
    "        # Simulate trades and calculate performance\n",
    "        performance[ii, jj] = simulate_trades(\n",
    "            signals=trading_signals,\n",
    "            prices=results_df['close'],  # Use the computed predicted prices\n",
    "            initial_balance=INITIAL_BALANCE\n",
    "        )\n",
    "        # Update best thresholds if current performance is better\n",
    "        if performance[ii, jj] > best_performance:\n",
    "            best_performance = performance[ii, jj]\n",
    "            best_buy_threshold = buy_th\n",
    "            best_sell_threshold = sell_th\n",
    "        jj += 1\n",
    "    ii += 1\n",
    "    jj = 0\n",
    "print(f\"Best Buy Threshold: {best_buy_threshold}, Best Sell Threshold: {best_sell_threshold}\")\n",
    "print(f\"Best Performance: {best_performance}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beck Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Balance: $1016.15\n",
      "Net Profit: $16.15\n"
     ]
    }
   ],
   "source": [
    "# Define buy & sell thrsholds\n",
    "buy_threshold = best_buy_threshold\n",
    "sell_threshold = best_sell_threshold\n",
    "# Generate signals with reversed logic\n",
    "trading_signals = [\n",
    "    -1 if pred < sell_threshold else 1 if pred > buy_threshold else 0\n",
    "    for pred in results_df['Predicted Change']\n",
    "]\n",
    "\n",
    "balance = INITIAL_BALANCE\n",
    "position = 0  # No stock initially\n",
    "trading_log = []  # To store completed trades\n",
    "\n",
    "\n",
    "\n",
    "results_df['Signal'] = trading_signals\n",
    "\n",
    "# Add 'open' and 'close' prices from the original DataFrame to results DataFrame\n",
    "# results_df['open'] = df.loc[results_df.index, 'open']\n",
    "# results_df['close'] = df.loc[results_df.index, 'close']\n",
    "\n",
    "results_df.dropna(inplace=True)\n",
    "\n",
    "# Variables to track ongoing trades\n",
    "buy_price = None\n",
    "buy_date = None\n",
    "buy_volume = None\n",
    "\n",
    "# Iterate over results_df for backtesting\n",
    "for index, row in results_df.iterrows():\n",
    "    signal = row['Signal']\n",
    "    price = row['close']  # Use 'open' price for Buy\n",
    "\n",
    "    if signal == 1 and balance > 0:\n",
    "        # Record Buy details\n",
    "        buy_price = price\n",
    "        buy_date = index\n",
    "        buy_volume = balance / price\n",
    "        position = buy_volume  # Update position\n",
    "        balance = 0  # All money is invested\n",
    "\n",
    "    elif signal == -1 and position > 0:\n",
    "        # Calculate profit/loss for the completed trade\n",
    "        sell_price = price  # Use 'close' price for Sell\n",
    "        profit_loss = (sell_price - buy_price) * buy_volume\n",
    "        balance = sell_price * buy_volume  # Update balance after selling\n",
    "        position = 0  # No stock left\n",
    "\n",
    "        # Record the completed trade in the log\n",
    "        trading_log.append({\n",
    "            \"Buy Date\": buy_date,\n",
    "            \"Buy Price\": buy_price,\n",
    "            \"Buy Volume\": buy_volume,\n",
    "            \"Sell Date\": index,\n",
    "            \"Sell Price\": sell_price,\n",
    "            \"Profit/Loss\": profit_loss\n",
    "        })\n",
    "\n",
    "        # Reset Buy details\n",
    "        buy_price = None\n",
    "        buy_date = None\n",
    "        buy_volume = None\n",
    "\n",
    "# Final portfolio value\n",
    "if position > 0:\n",
    "    final_price = results_df.iloc[-1]['Predicted Price']\n",
    "    final_profit_loss = (final_price - buy_price) * buy_volume\n",
    "    balance = final_price * buy_volume  # Update balance with remaining shares\n",
    "    trading_log.append({\n",
    "        \"Buy Date\": buy_date,\n",
    "        \"Buy Price\": buy_price,\n",
    "        \"Buy Volume\": buy_volume,\n",
    "        \"Sell Date\": results_df.index[-1],\n",
    "        \"Sell Price\": final_price,\n",
    "        \"Profit/Loss\": final_profit_loss\n",
    "    })\n",
    "\n",
    "# Convert trading log to a DataFrame for better analysis\n",
    "trading_log_df = pd.DataFrame(trading_log)\n",
    "\n",
    "# Print the final results\n",
    "print(f\"Final Balance: ${balance:.2f}\")\n",
    "print(f\"Net Profit: ${balance - INITIAL_BALANCE:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predicted prices\n",
    "plt.clf()\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(results_df.index, results_df['Predicted Change'], label='Predicted Change', color='blue', alpha=0.7)\n",
    "plt.plot(results_df.index, y_test/100, label='Actual Change', color='red', alpha=0.7)\n",
    "\n",
    "\n",
    "# Use trading_log_df for Buy and Sell points\n",
    "buy_signals = trading_log_df.dropna(subset=['Buy Date'])\n",
    "sell_signals = trading_log_df.dropna(subset=['Sell Date'])\n",
    "\n",
    "# Map Buy/Sell signals to values from results_df['close']\n",
    "buy_close_prices = [results_df.loc[row['Buy Date'], 'Predicted Change'] for _, row in buy_signals.iterrows()]\n",
    "sell_close_prices = [results_df.loc[row['Sell Date'], 'Predicted Change'] for _, row in sell_signals.iterrows()]\n",
    "\n",
    "# Plot Buy signals as green squares at actual 'close' prices\n",
    "plt.scatter(\n",
    "    buy_signals['Buy Date'],\n",
    "    buy_close_prices,\n",
    "    label='Buy Signal',\n",
    "    color='green',\n",
    "    marker='s',\n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "# Plot Sell signals as red circles at actual 'close' prices\n",
    "plt.scatter(\n",
    "    sell_signals['Sell Date'],\n",
    "    sell_close_prices,\n",
    "    label='Sell Signal',\n",
    "    color='red',\n",
    "    marker='o',\n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "# Add labels, title, legend, and grid\n",
    "plt.title(\"Trading Signals Over Predicted Prices (Using Actual Close Prices)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model_10candles_1min.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "joblib.dump(best_model, 'best_model_10candles_1min.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
