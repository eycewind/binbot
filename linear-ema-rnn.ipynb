{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ata/miniconda3/envs/ml-2/bin/python\n",
      "/home/ata/miniconda3/envs/ml-2/bin/jupyter\n"
     ]
    }
   ],
   "source": [
    "# Verify that we are using the correct Python (/home/ata/miniconda3/envs/ml/bin/)\n",
    "!which python\n",
    "!which jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 7)\n",
    "from packaging import version\n",
    "import tensorflow as tf\n",
    "\n",
    "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")\n",
    "# Import the class from the Python file (module)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from BinanceClient import BinanceClient\n",
    "import numpy as np\n",
    "from typing import Final\n",
    "import joblib\n",
    "from BatchFeatures import BatchFeatures\n",
    "from datetime import datetime, timedelta\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch pair data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Binance client with your API credentials\n",
    "# dotenv_path = Path('.env-secret')\n",
    "# load_dotenv(dotenv_path=dotenv_path)\n",
    "api_secret = os.getenv(\"BINANCE_SECRET_KEY\")\n",
    "api_key = os.getenv(\"BINANCE_API_KEY\")\n",
    "\n",
    "# Create Binance client & initialize it\n",
    "pair = \"BTCUSDT\"\n",
    "time_delta = 12\n",
    "db_name = pair + \"_1min_\" + str(time_delta) + \"weeks.db\"\n",
    "db_name = \"BTCUSDT_1min_dry_run.db\"             # For dry run testing\n",
    "binance_client = BinanceClient(db_name)\n",
    "binance_client.set_interval(\"1m\")\n",
    "batch_feature = BatchFeatures()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "12*7*24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fecth Data from Binance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create connection to fetch data\n",
    "binance_client.make(api_key, api_secret)\n",
    "\n",
    "# Get current server time\n",
    "server_time = binance_client.get_server_time()\n",
    "\n",
    "# Compute start and end time for the last x hours\n",
    "server_time_dt = datetime.fromtimestamp(server_time['serverTime'] / 1000, tz=datetime.timezone.utc if hasattr(datetime, 'timezone') else None)\n",
    "end_date = server_time_dt\n",
    "start_date = server_time_dt - timedelta(weeks=time_delta)\n",
    "start_date_str = int(start_date.timestamp() * 1000)  # Convert to milliseconds\n",
    "end_date_str = int(end_date.timestamp() * 1000)      # Convert to milliseconds\n",
    "\n",
    "# Fetch data\n",
    "data = binance_client.fetch_data(pair, start_date_str, end_date_str)\n",
    "binance_client.store_data_to_db(pair, data)\n",
    "\n",
    "# Check if data is fetched\n",
    "if not data.empty:\n",
    "    df = data\n",
    "else:\n",
    "    print(\"No data found!!!.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch data from db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch data from db\n",
    "df = binance_client.fetch_data_from_db(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering (mind the order since some features are dependent on others)\n",
    "bf = BatchFeatures()\n",
    "\n",
    "# Must-have features\n",
    "\n",
    "# EMA: Compute for short-term and long-term spans\n",
    "bf.calculate_ema(df, spans=[5, 10, 50])  # Short-term (10), Long-term (50)\n",
    "\n",
    "# MACD: Standard MACD (12-26-9) and Fast MACD (6-13-5)\n",
    "bf.calculate_macd(df, spans={'standard': (12, 26, 9), 'fast': (6, 13, 5)})\n",
    "\n",
    "# RSI: Compute for default (14) and shorter-term (7) windows\n",
    "bf.calculate_rsi(df, windows=[7, 14])\n",
    "\n",
    "# Bollinger Bands: Compute for default 20-period with 2 standard deviations\n",
    "bf.calculate_bollinger_bands(df, window=20, num_std_dev=2)\n",
    "\n",
    "# Volume Features: Compute for default 20-period\n",
    "bf.calculate_volume_features(df, windows=[20])  # Include backward-compatible volume_ratio\n",
    "\n",
    "# Candle Features: Include optional 'candle_range' based on compatibility\n",
    "bf.calculate_candle_features(df, legacy_compatibility=True)  # Default behavior for backward compatibility\n",
    "\n",
    "\n",
    "# Optionals\n",
    "bf.calculate_sma(df)\n",
    "bf.calculate_atr(df)\n",
    "bf.calculate_moving_average_crossover(df)\n",
    "bf.calculate_historical_volatility(df)\n",
    "bf.calculate_money_flow_index(df)\n",
    "bf.calculate_roc(df)\n",
    "bf.calculate_stochastic_oscillator(df)\n",
    "bf.calculate_williams_r(df)\n",
    "\n",
    "# Low value fatures\n",
    "bf.calculate_lagged_features(df)\n",
    "bf.calculate_on_balance_volume(df)\n",
    "bf.calculate_croc(df)\n",
    "\n",
    "# drop NaNs\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Define the prediction window and smoothing factor\n",
    "nn = 10  # Number of candles ahead to predict\n",
    "alpha = 0.8  # Weight for the EMA-based target vs raw percentage change\n",
    "\n",
    "# Ensure EMAs (or other features) are already computed\n",
    "# Example: df['ema_5'], df['ema_10'], df['ema_50']\n",
    "\n",
    "# Calculate the EMA-based target\n",
    "ema_target = (df['ema_5'].shift(-nn) - df['ema_10']) / df['ema_10'] * 100\n",
    "\n",
    "# Calculate the raw percentage change target\n",
    "raw_target = (df['close'].shift(-nn) - df['close']) / df['close'] * 100\n",
    "\n",
    "# Combine the two targets with weights\n",
    "df['target'] = alpha * ema_target + (1 - alpha) * raw_target\n",
    "\n",
    "#\n",
    "instant_change = (df['close'].shift(-nn) - df['close']) / df['close'] * 100\n",
    "\n",
    "# Drop NaN values caused by shifting\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# # Verify the resulting target\n",
    "# print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.figure(figsize=[12, 6])\n",
    "df['target'].plot(alpha=0.6)\n",
    "instant_change.plot(alpha=0.6)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test/Train Splot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the df into three parts, train, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lstm_ema_scaler.pkl']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "# Use only the last 3 hours of data for training, validation, and testing\n",
    "df_recent = df.copy()  # Adjust slice as needed\n",
    "\n",
    "# Calculate split indices\n",
    "n = len(df_recent)\n",
    "train_end = int(train_ratio * n)\n",
    "val_end = train_end + int(val_ratio * n)\n",
    "\n",
    "# Perform the splits\n",
    "train_data = df_recent.iloc[:train_end]\n",
    "val_data = df_recent.iloc[train_end:val_end]\n",
    "test_data = df_recent.iloc[val_end:]\n",
    "\n",
    "# Separate features (X_*) and targets (y_*)\n",
    "X_train = train_data.drop(columns=['target'])\n",
    "y_train = train_data['target']\n",
    "\n",
    "X_valid = val_data.drop(columns=['target'])\n",
    "y_valid = val_data['target']\n",
    "\n",
    "X_test = test_data.drop(columns=['target'])\n",
    "y_test = test_data['target']\n",
    "\n",
    "# Initialize the scaler and scale only the X_* components\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training features and transform\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "\n",
    "# Transform validation and test features\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_valid_scaled = pd.DataFrame(X_valid_scaled, columns=X_valid.columns, index=X_valid.index)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# Save the scaler for later use\n",
    "joblib.dump(scaler, 'lstm_ema_scaler.pkl')\n",
    "\n",
    "# Combine scaled features (X_*) and unscaled targets (y_*) back into final datasets\n",
    "# train_data = pd.concat([X_train_scaled, y_train], axis=1)\n",
    "# valid_data = pd.concat([X_valid_scaled, y_valid], axis=1)\n",
    "# test_data = pd.concat([X_test_scaled, y_test], axis=1)\n",
    "\n",
    "# Output lengths of each dataset to verify correctness\n",
    "# print(f\"Train data shape: {train_data.shape}\")\n",
    "# print(f\"Validation data shape: {valid_data.shape}\")\n",
    "# print(f\"Test data shape: {test_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomize the time sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence length (5 hours = 300 instances for 1-minute resolution)\n",
    "seq_length = 60\n",
    "batch_size = 32*40\n",
    "\n",
    "# Create time series datasets\n",
    "tf.random.set_seed(42)  # Ensures reproducibility\n",
    "\n",
    "# Training dataset\n",
    "train_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    data=X_train_scaled.iloc[:-seq_length].to_numpy(),  # Exclude the last 'seq_length' rows for input\n",
    "    targets=y_train.iloc[seq_length:].to_numpy(),  # Shift target by 'seq_length'\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Validation dataset\n",
    "valid_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    data=X_valid_scaled.iloc[:-seq_length].to_numpy(),\n",
    "    targets=y_valid.iloc[seq_length:].to_numpy(),\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – defines a utility function we'll reuse several time\n",
    "\n",
    "def fit_and_evaluate(model, train_set, valid_set, learning_rate, epochs=500):\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=20, restore_best_weights=True, verbose=1)\n",
    "\n",
    "    # opt = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    opt=tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])\n",
    "    history = model.fit(train_set, validation_data=valid_set, epochs=epochs,\n",
    "                        callbacks=[early_stopping_cb])\n",
    "    valid_loss, valid_mae = model.evaluate(valid_set)\n",
    "    return valid_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivar LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ata/miniconda3/envs/ml-2/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(64, activation=\"tanh\", return_sequences=True, input_shape=[None, 54]),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.LSTM(64, activation=\"tanh\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(64, activation=\"tanh\", return_sequences=True, input_shape=[None, 54],\n",
    "                         dropout=0.2, recurrent_dropout=0.2),  # Use both dropout types\n",
    "    tf.keras.layers.LSTM(64, activation=\"tanh\", dropout=0.2, recurrent_dropout=0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 372ms/step - loss: 0.0326 - mae: 0.1870 - val_loss: 0.0252 - val_mae: 0.1538\n",
      "Epoch 2/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 359ms/step - loss: 0.0187 - mae: 0.1344 - val_loss: 0.0248 - val_mae: 0.1536\n",
      "Epoch 3/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 362ms/step - loss: 0.0183 - mae: 0.1318 - val_loss: 0.0246 - val_mae: 0.1529\n",
      "Epoch 4/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 361ms/step - loss: 0.0179 - mae: 0.1308 - val_loss: 0.0243 - val_mae: 0.1515\n",
      "Epoch 5/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 369ms/step - loss: 0.0177 - mae: 0.1302 - val_loss: 0.0244 - val_mae: 0.1518\n",
      "Epoch 6/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 392ms/step - loss: 0.0177 - mae: 0.1299 - val_loss: 0.0243 - val_mae: 0.1516\n",
      "Epoch 7/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 382ms/step - loss: 0.0175 - mae: 0.1290 - val_loss: 0.0243 - val_mae: 0.1515\n",
      "Epoch 8/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 374ms/step - loss: 0.0175 - mae: 0.1291 - val_loss: 0.0244 - val_mae: 0.1518\n",
      "Epoch 9/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 368ms/step - loss: 0.0173 - mae: 0.1285 - val_loss: 0.0243 - val_mae: 0.1515\n",
      "Epoch 10/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 270ms/step - loss: 0.0172 - mae: 0.1284 - val_loss: 0.0243 - val_mae: 0.1519\n",
      "Epoch 11/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - loss: 0.0172 - mae: 0.1283 - val_loss: 0.0244 - val_mae: 0.1517\n",
      "Epoch 12/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - loss: 0.0171 - mae: 0.1282 - val_loss: 0.0247 - val_mae: 0.1523\n",
      "Epoch 13/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - loss: 0.0170 - mae: 0.1274 - val_loss: 0.0245 - val_mae: 0.1522\n",
      "Epoch 14/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - loss: 0.0170 - mae: 0.1280 - val_loss: 0.0245 - val_mae: 0.1520\n",
      "Epoch 15/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - loss: 0.0167 - mae: 0.1267 - val_loss: 0.0246 - val_mae: 0.1518\n",
      "Epoch 16/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - loss: 0.0168 - mae: 0.1270 - val_loss: 0.0247 - val_mae: 0.1532\n",
      "Epoch 17/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - loss: 0.0166 - mae: 0.1269 - val_loss: 0.0248 - val_mae: 0.1529\n",
      "Epoch 18/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - loss: 0.0165 - mae: 0.1262 - val_loss: 0.0248 - val_mae: 0.1524\n",
      "Epoch 19/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - loss: 0.0166 - mae: 0.1267 - val_loss: 0.0249 - val_mae: 0.1530\n",
      "Epoch 20/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - loss: 0.0163 - mae: 0.1261 - val_loss: 0.0247 - val_mae: 0.1523\n",
      "Epoch 21/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - loss: 0.0162 - mae: 0.1257 - val_loss: 0.0248 - val_mae: 0.1524\n",
      "Epoch 22/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - loss: 0.0161 - mae: 0.1260 - val_loss: 0.0251 - val_mae: 0.1539\n",
      "Epoch 23/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - loss: 0.0161 - mae: 0.1255 - val_loss: 0.0248 - val_mae: 0.1525\n",
      "Epoch 24/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - loss: 0.0158 - mae: 0.1250 - val_loss: 0.0255 - val_mae: 0.1541\n",
      "Epoch 25/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - loss: 0.0158 - mae: 0.1251 - val_loss: 0.0254 - val_mae: 0.1537\n",
      "Epoch 26/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - loss: 0.0158 - mae: 0.1250 - val_loss: 0.0253 - val_mae: 0.1534\n",
      "Epoch 27/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - loss: 0.0154 - mae: 0.1237 - val_loss: 0.0251 - val_mae: 0.1533\n",
      "Epoch 28/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - loss: 0.0153 - mae: 0.1234 - val_loss: 0.0260 - val_mae: 0.1563\n",
      "Epoch 29/500\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - loss: 0.0154 - mae: 0.1242 - val_loss: 0.0258 - val_mae: 0.1553\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0240 - mae: 0.1473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15147694945335388"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_and_evaluate(model, train_ds, valid_ds, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trtained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lstm_ema_10candles_1min.joblib']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "joblib.dump(model, 'lstm_ema_10candles_1min.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load previously trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model\n",
    "model = joblib.load('lstm_ema_10candles_1min.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " y_test Absolute Mean: 0.1259\n",
      " y_test Standard Deviation: 0.1829\n",
      " y_test Minimum Value: -1.2396\n",
      " y_test Maximum Value: 1.4439\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each target column in y_test\n",
    "print(f\" y_test Absolute Mean: {y_test.abs().mean():.4f}\")\n",
    "print(f\" y_test Standard Deviation: {y_test.std():.4f}\")\n",
    "print(f\" y_test Minimum Value: {y_test.min():.4f}\")\n",
    "print(f\" y_test Maximum Value: {y_test.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_BALANCE=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_test_copy: 27084\n",
      "Length of y_test_copy: 27084\n",
      "Length of test_data: 27084\n",
      "seq_length: 60, nn: 10\n",
      "\u001b[1m845/845\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate sequences for LSTM input\n",
    "# seq_length = 60  # Replace with the sequence length used during training\n",
    "X_test_copy = X_test_scaled.copy()\n",
    "y_test_copy = y_test.copy()\n",
    "X_test_list = []\n",
    "y_test_list = []\n",
    "nn = 10\n",
    "\n",
    "print(f\"Length of X_test_copy: {len(X_test_copy)}\")\n",
    "print(f\"Length of y_test_copy: {len(y_test_copy)}\")\n",
    "print(f\"Length of test_data: {len(test_data)}\")\n",
    "print(f\"seq_length: {seq_length}, nn: {nn}\")\n",
    "\n",
    "\n",
    "for i in range(seq_length, len(test_data)-nn):\n",
    "    X_test_list.append(X_test_copy.iloc[i-seq_length:i])  # Create sequence\n",
    "    y_test_list.append(y_test_copy.iloc[i])\n",
    "    # y_test.append( (test_data.iloc[i + nn]['close'] - test_data.iloc[i]['close']) / test_data.iloc[i]['close'] * 100)  # Price change nn candles ahead\n",
    "\n",
    "X_test_list = np.array(X_test_list)\n",
    "y_test_list = np.array(y_test_list)\n",
    "\n",
    "# Unscale predictions\n",
    "predictions = model.predict(X_test_list)  # Predictions are in scaled space\n",
    "predictions = predictions.flatten()\n",
    "\n",
    "# Prepend 'nn' NaNs to align predictions with actual changes\n",
    "predictions = np.concatenate((predictions, np.full(nn, np.nan)))\n",
    "# predictions = -1*predictions \n",
    "\n",
    "\n",
    "# Combine predictions and actual values\n",
    "results_df = X_test[seq_length:].copy()\n",
    "results_df['Predicted Change'] = predictions  # Model output: predicted change in price\n",
    "results_df['Actual Change'] = y_test   # Actual change in price (target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df['Actual Future Price'] = results_df['close']  # Actual future close price\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(12, 7))\n",
    "# results_df['Predicted Price'].plot()\n",
    "# results_df['close'].plot()\n",
    "results_df['Predicted Change'].plot(alpha=0.5)\n",
    "results_df['Actual Change'].plot(alpha=0.5)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_trades(signals, prices, initial_balance=1000):\n",
    "    \"\"\"\n",
    "    Simulates trades based on signals and actual price changes.\n",
    "\n",
    "    Args:\n",
    "        actual_changes (list or pd.Series): Actual percentage changes (not predicted).\n",
    "        signals (list): List of trading signals (\"Buy\", \"Sell\", \"Hold\").\n",
    "        prices (list or pd.Series): Actual price values for the asset.\n",
    "        initial_balance (float): Starting balance of the trading account.\n",
    "\n",
    "    Returns:\n",
    "        float: Final balance or cumulative profit.\n",
    "    \"\"\"\n",
    "    balance = INITIAL_BALANCE\n",
    "    position = 0  # Tracks the number of stocks held\n",
    "    entry_price = None  # Store the price when a \"Buy\" was executed\n",
    "\n",
    "    for i, signal in enumerate(signals):\n",
    "        if signal == 1 and balance > 0:\n",
    "            # Execute a buy\n",
    "            entry_price = prices.iloc[i]  # Use .iloc for positional indexing\n",
    "            position = balance / entry_price  # Buy with all available balance\n",
    "            balance = 0  # All balance used to buy\n",
    "        elif signal == -1 and position > 0:\n",
    "            # Execute a sell\n",
    "            exit_price = prices.iloc[i]  # Use .iloc for positional indexing\n",
    "            balance = position * exit_price  # Convert position to cash\n",
    "            position = 0  # Clear position\n",
    "            entry_price = None  # Reset entry price after selling\n",
    "\n",
    "    # If there's a remaining position at the end, calculate its value\n",
    "    if position > 0 and entry_price is not None:\n",
    "        balance += position * prices.iloc[-1]  # Use .iloc for positional indexing\n",
    "\n",
    "    return balance - INITIAL_BALANCE  # Return cumulative profit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Change: -0.8875565528869629\n",
      "Max Change: 0.824345588684082\n"
     ]
    }
   ],
   "source": [
    "predict_ch_min = results_df[\"Predicted Change\"].min()\n",
    "predict_ch_max = results_df[\"Predicted Change\"].max()\n",
    "print(f'Min Change: {predict_ch_min}')\n",
    "print(f'Max Change: {predict_ch_max}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Buy Threshold: 0.3751, Best Sell Threshold: -0.2125565528869623\n",
      "Best Performance: 22.113288469810755\n"
     ]
    }
   ],
   "source": [
    "# Define buy and sell thresholds (e.g., absolute differences in predicted vs. actual price)\n",
    "sell_thresholds = np.arange(predict_ch_min, -0.0001, 0.005)  # Thresholds for when to \"Sell\"; Sell when price is predicted to go down\n",
    "buy_thresholds = np.arange(0.0001, predict_ch_max, 0.005)   # Thresholds for when to \"Buy\"; buy when price is predicted to go up\n",
    "\n",
    "best_buy_threshold = None\n",
    "best_sell_threshold = None\n",
    "best_performance = -np.inf\n",
    "\n",
    "ii = 0\n",
    "jj = 0\n",
    "performance = np.zeros((len(buy_thresholds), len(sell_thresholds)))\n",
    "# -1 = Sell\n",
    "# 0 = Hold\n",
    "# 1 = Buy\n",
    "for buy_th in buy_thresholds:\n",
    "    for sell_th in sell_thresholds:\n",
    "        # Generate signals\n",
    "        trading_signals = [\n",
    "            -1 if pred < sell_th else 1 if pred > buy_th else 0\n",
    "            for pred in results_df['Predicted Change']\n",
    "        ]\n",
    "\n",
    "        # Simulate trades and calculate performance\n",
    "        performance[ii, jj] = simulate_trades(\n",
    "            signals=trading_signals,\n",
    "            prices=results_df['close'],  # Use the computed predicted prices\n",
    "            initial_balance=INITIAL_BALANCE\n",
    "        )\n",
    "        # Update best thresholds if current performance is better\n",
    "        if performance[ii, jj] > best_performance:\n",
    "            best_performance = performance[ii, jj]\n",
    "            best_buy_threshold = buy_th\n",
    "            best_sell_threshold = sell_th\n",
    "        jj += 1\n",
    "    ii += 1\n",
    "    jj = 0\n",
    "print(f\"Best Buy Threshold: {best_buy_threshold}, Best Sell Threshold: {best_sell_threshold}\")\n",
    "print(f\"Best Performance: {best_performance}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beck Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Balance: $1022.11\n",
      "Net Profit: $22.11\n"
     ]
    }
   ],
   "source": [
    "# Define buy & sell thrsholds\n",
    "buy_threshold = best_buy_threshold\n",
    "sell_threshold = best_sell_threshold\n",
    "# Generate signals with reversed logic\n",
    "trading_signals = [\n",
    "    -1 if pred < sell_threshold else 1 if pred > buy_threshold else 0\n",
    "    for pred in results_df['Predicted Change']\n",
    "]\n",
    "\n",
    "balance = INITIAL_BALANCE\n",
    "position = 0  # No stock initially\n",
    "trading_log = []  # To store completed trades\n",
    "\n",
    "\n",
    "\n",
    "results_df['Signal'] = trading_signals\n",
    "\n",
    "# Add 'open' and 'close' prices from the original DataFrame to results DataFrame\n",
    "# results_df['open'] = df.loc[results_df.index, 'open']\n",
    "# results_df['close'] = df.loc[results_df.index, 'close']\n",
    "\n",
    "results_df.dropna(inplace=True)\n",
    "\n",
    "# Variables to track ongoing trades\n",
    "buy_price = None\n",
    "buy_date = None\n",
    "buy_volume = None\n",
    "\n",
    "# Iterate over results_df for backtesting\n",
    "for index, row in results_df.iterrows():\n",
    "    signal = row['Signal']\n",
    "    price = row['close']  # Use 'open' price for Buy\n",
    "\n",
    "    if signal == 1 and balance > 0:\n",
    "        # Record Buy details\n",
    "        buy_price = price\n",
    "        buy_date = index\n",
    "        buy_volume = balance / price\n",
    "        position = buy_volume  # Update position\n",
    "        balance = 0  # All money is invested\n",
    "\n",
    "    elif signal == -1 and position > 0:\n",
    "        # Calculate profit/loss for the completed trade\n",
    "        sell_price = price  # Use 'close' price for Sell\n",
    "        profit_loss = (sell_price - buy_price) * buy_volume\n",
    "        balance = sell_price * buy_volume  # Update balance after selling\n",
    "        position = 0  # No stock left\n",
    "\n",
    "        # Record the completed trade in the log\n",
    "        trading_log.append({\n",
    "            \"Buy Date\": buy_date,\n",
    "            \"Buy Price\": buy_price,\n",
    "            \"Buy Volume\": buy_volume,\n",
    "            \"Sell Date\": index,\n",
    "            \"Sell Price\": sell_price,\n",
    "            \"Profit/Loss\": profit_loss\n",
    "        })\n",
    "\n",
    "        # Reset Buy details\n",
    "        buy_price = None\n",
    "        buy_date = None\n",
    "        buy_volume = None\n",
    "\n",
    "# Final portfolio value\n",
    "if position > 0:\n",
    "    final_price = results_df.iloc[-1]['Predicted Price']\n",
    "    final_profit_loss = (final_price - buy_price) * buy_volume\n",
    "    balance = final_price * buy_volume  # Update balance with remaining shares\n",
    "    trading_log.append({\n",
    "        \"Buy Date\": buy_date,\n",
    "        \"Buy Price\": buy_price,\n",
    "        \"Buy Volume\": buy_volume,\n",
    "        \"Sell Date\": results_df.index[-1],\n",
    "        \"Sell Price\": final_price,\n",
    "        \"Profit/Loss\": final_profit_loss\n",
    "    })\n",
    "\n",
    "# Convert trading log to a DataFrame for better analysis\n",
    "trading_log_df = pd.DataFrame(trading_log)\n",
    "\n",
    "# Print the final results\n",
    "print(f\"Final Balance: ${balance:.2f}\")\n",
    "print(f\"Net Profit: ${balance - INITIAL_BALANCE:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predicted prices\n",
    "plt.clf()\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(results_df.index, results_df['Predicted Change'], label='Predicted Change', color='blue', alpha=0.7)\n",
    "plt.plot(results_df.index, y_test/100, label='Actual Change', color='red', alpha=0.7)\n",
    "\n",
    "\n",
    "# Use trading_log_df for Buy and Sell points\n",
    "buy_signals = trading_log_df.dropna(subset=['Buy Date'])\n",
    "sell_signals = trading_log_df.dropna(subset=['Sell Date'])\n",
    "\n",
    "# Map Buy/Sell signals to values from results_df['close']\n",
    "buy_close_prices = [results_df.loc[row['Buy Date'], 'Predicted Change'] for _, row in buy_signals.iterrows()]\n",
    "sell_close_prices = [results_df.loc[row['Sell Date'], 'Predicted Change'] for _, row in sell_signals.iterrows()]\n",
    "\n",
    "# Plot Buy signals as green squares at actual 'close' prices\n",
    "plt.scatter(\n",
    "    buy_signals['Buy Date'],\n",
    "    buy_close_prices,\n",
    "    label='Buy Signal',\n",
    "    color='green',\n",
    "    marker='s',\n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "# Plot Sell signals as red circles at actual 'close' prices\n",
    "plt.scatter(\n",
    "    sell_signals['Sell Date'],\n",
    "    sell_close_prices,\n",
    "    label='Sell Signal',\n",
    "    color='red',\n",
    "    marker='o',\n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "# Add labels, title, legend, and grid\n",
    "plt.title(\"Trading Signals Over Predicted Prices (Using Actual Close Prices)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model_10candles_1min.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "joblib.dump(best_model, 'best_model_10candles_1min.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
