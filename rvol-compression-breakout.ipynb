{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35317593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the class from the Python file (module)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# from dotenv import load_dotenv\n",
    "# from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from BinanceClient import BinanceClient\n",
    "import numpy as np\n",
    "from typing import Final\n",
    "import joblib\n",
    "from BatchFeatures import BatchFeatures\n",
    "from datetime import datetime, timedelta\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eafd5c2",
   "metadata": {},
   "source": [
    "## Load pair df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ca49b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "def interval_slug(s: str) -> str:\n",
    "    return s.strip().replace(\" \", \"\").replace(\"/\", \"\").lower()\n",
    "\n",
    "def make_db_name(pair: str, interval: str, weeks: int) -> str:\n",
    "    return f\"{pair}_{interval_slug(interval)}_{weeks}weeks.db\"\n",
    "\n",
    "def load_or_fetch_pair_df(pair: str, interval: str, weeks: int) -> tuple[str, \"pd.DataFrame\"]:\n",
    "    db_name = make_db_name(pair, interval, weeks)\n",
    "    db_path = \"./db/\" + db_name\n",
    "\n",
    "    print(f\"[{pair}] DB: {db_path}\")\n",
    "\n",
    "    binance_client = BinanceClient(db_path)\n",
    "    binance_client.set_interval(interval)\n",
    "\n",
    "    df = None\n",
    "\n",
    "    if os.path.exists(db_path):\n",
    "        df = binance_client.fetch_data_from_db(pair)\n",
    "        if df is not None and not df.empty:\n",
    "            print(f\"[{pair}] Loaded {len(df):,} rows from DB.\")\n",
    "        else:\n",
    "            df = None\n",
    "\n",
    "    if df is None:\n",
    "        print(f\"[{pair}] No usable DB data found -> fetching from Binance...\")\n",
    "\n",
    "        api_secret = os.getenv(\"BINANCE_SECRET_KEY\")\n",
    "        api_key = os.getenv(\"BINANCE_API_KEY\")\n",
    "        binance_client.make(api_key, api_secret)\n",
    "\n",
    "        server_time = binance_client.get_server_time()\n",
    "        end_dt = datetime.fromtimestamp(server_time[\"serverTime\"] / 1000, tz=timezone.utc)\n",
    "        start_dt = end_dt - timedelta(weeks=weeks)\n",
    "\n",
    "        start_ms = int(start_dt.timestamp() * 1000)\n",
    "        end_ms = int(end_dt.timestamp() * 1000)\n",
    "\n",
    "        data = binance_client.fetch_data(pair, start_ms, end_ms)\n",
    "        if data is None or data.empty:\n",
    "            raise RuntimeError(f\"[{pair}] No data returned from Binance for the requested range.\")\n",
    "\n",
    "        binance_client.store_data_to_db(pair, data)\n",
    "\n",
    "        df = binance_client.fetch_data_from_db(pair)\n",
    "        if df is None or df.empty:\n",
    "            raise RuntimeError(f\"[{pair}] Data fetched/stored but DB load returned empty.\")\n",
    "\n",
    "        print(f\"[{pair}] Fetched + stored + loaded {len(df):,} rows.\")\n",
    "\n",
    "    df = df.sort_index()\n",
    "    return db_path, df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b4bf11",
   "metadata": {},
   "source": [
    "## Load COINS, then align timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ae31635-347b-4493-b505-85498e0b58ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def detect_volume_events(\n",
    "    df: pd.DataFrame,\n",
    "    symbol: str,\n",
    "    vol_win: int = 144,          # 12 hours on 5m\n",
    "    impulse_k: int = 12,         # 60 min impulse\n",
    "    rvol_thresh: float = 6.0,    # strict\n",
    "    impulse_thresh: float = 0.04,# +4% over impulse_k\n",
    "    lookahead: int = 24,         # 2 hours forward path\n",
    "    cooldown: int = 12,          # avoid logging same burst repeatedly (60 min)\n",
    "):\n",
    "    \"\"\"\n",
    "    Logs candidate 'flow shock' events:\n",
    "      - RVOL spike relative to rolling median\n",
    "      - Positive impulse over last impulse_k bars\n",
    "    Then measures forward path stats over lookahead bars.\n",
    "    \"\"\"\n",
    "    d = df.copy().sort_index()\n",
    "    d = d[[\"open\",\"high\",\"low\",\"close\",\"volume\"]].dropna()\n",
    "\n",
    "    vol_med = d[\"volume\"].rolling(vol_win).median()\n",
    "    rvol = d[\"volume\"] / vol_med\n",
    "    impulse = d[\"close\"] / d[\"close\"].shift(impulse_k) - 1.0\n",
    "\n",
    "    out = []\n",
    "    i = 0\n",
    "    n = len(d)\n",
    "\n",
    "    while i < n - lookahead:\n",
    "        if (rvol.iloc[i] >= rvol_thresh) and (impulse.iloc[i] >= impulse_thresh):\n",
    "            px0 = float(d[\"close\"].iloc[i])\n",
    "            ts0 = d.index[i]\n",
    "\n",
    "            future = d[\"close\"].iloc[i+1:i+1+lookahead]\n",
    "            fmax = float(future.max())\n",
    "            fmin = float(future.min())\n",
    "            max_fwd_return = fmax / px0 - 1.0\n",
    "            max_drawdown = fmin / px0 - 1.0\n",
    "\n",
    "            # retrace from the peak within the lookahead window\n",
    "            # find peak time then worst after that peak\n",
    "            peak_idx = future.values.argmax()\n",
    "            peak_px = float(future.iloc[peak_idx])\n",
    "            after_peak = future.iloc[peak_idx:]  # includes peak bar\n",
    "            trough_after_peak = float(after_peak.min())\n",
    "            max_retrace = trough_after_peak / peak_px - 1.0  # negative means retrace\n",
    "\n",
    "            # time to max retrace (bars after event)\n",
    "            trough_idx = after_peak.values.argmin()\n",
    "            time_to_max_retrace_bars = int(peak_idx + trough_idx + 1)\n",
    "\n",
    "            out.append({\n",
    "                \"symbol\": symbol,\n",
    "                \"event_ts\": ts0,\n",
    "                \"close_event\": px0,\n",
    "                \"rvol\": float(rvol.iloc[i]),\n",
    "                \"impulse\": float(impulse.iloc[i]),\n",
    "                \"max_fwd_return\": max_fwd_return,\n",
    "                \"max_drawdown\": max_drawdown,\n",
    "                \"max_retrace\": max_retrace,\n",
    "                \"time_to_max_retrace_bars\": time_to_max_retrace_bars,\n",
    "            })\n",
    "\n",
    "            i += cooldown  # skip ahead so we don't log every bar of the same burst\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return pd.DataFrame(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6963fc3-8a04-4230-ba38-a92c9803b0af",
   "metadata": {},
   "source": [
    "## Get all Binance coin pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebb5e124-1a4e-46e7-ab7e-d1e16949b323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "BINANCE_REST = \"https://api.binance.com\"\n",
    "\n",
    "def get_spot_usdt_symbols():\n",
    "    \"\"\"All Spot symbols that trade against USDT and are currently TRADING.\"\"\"\n",
    "    info = requests.get(f\"{BINANCE_REST}/api/v3/exchangeInfo\", timeout=20).json()\n",
    "    syms = []\n",
    "    for s in info[\"symbols\"]:\n",
    "        if s.get(\"status\") != \"TRADING\":\n",
    "            continue\n",
    "        if s.get(\"isSpotTradingAllowed\") is not True:\n",
    "            continue\n",
    "        if s.get(\"quoteAsset\") != \"USDT\":\n",
    "            continue\n",
    "\n",
    "        sym = s[\"symbol\"]\n",
    "\n",
    "        # Exclude leveraged tokens & some common non-spot-like tickers\n",
    "        bad_substrings = [\"UPUSDT\", \"DOWNUSDT\", \"BULLUSDT\", \"BEARUSDT\", \"3LUSDT\", \"3SUSDT\", \"5LUSDT\", \"5SUSDT\"]\n",
    "        if any(sym.endswith(x) for x in bad_substrings):\n",
    "            continue\n",
    "\n",
    "        syms.append(sym)\n",
    "    return sorted(set(syms))\n",
    "\n",
    "def rank_symbols_by_quote_volume(symbols):\n",
    "    \"\"\"Return DataFrame of symbols with 24h quoteVolume (USDT) sorted desc.\"\"\"\n",
    "    tickers = requests.get(f\"{BINANCE_REST}/api/v3/ticker/24hr\", timeout=20).json()\n",
    "    # Build a map for fast lookup\n",
    "    wanted = set(symbols)\n",
    "\n",
    "    rows = []\n",
    "    for t in tickers:\n",
    "        sym = t.get(\"symbol\")\n",
    "        if sym not in wanted:\n",
    "            continue\n",
    "        # quoteVolume is in quoteAsset units, here USDT\n",
    "        qv = float(t.get(\"quoteVolume\", 0.0))\n",
    "        rows.append({\n",
    "            \"symbol\": sym,\n",
    "            \"quoteVolumeUSDT_24h\": qv,\n",
    "            \"lastPrice\": float(t.get(\"lastPrice\", 0.0)),\n",
    "            \"priceChangePercent\": float(t.get(\"priceChangePercent\", 0.0)),\n",
    "            \"count\": int(t.get(\"count\", 0)),  # trade count 24h\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.sort_values(\"quoteVolumeUSDT_24h\", ascending=False).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def get_top_usdt_pairs(n=100, min_quote_vol_usdt=None):\n",
    "    \"\"\"Top-N by 24h quote volume; optionally filter by minimum quote volume.\"\"\"\n",
    "    syms = get_spot_usdt_symbols()\n",
    "    ranked = rank_symbols_by_quote_volume(syms)\n",
    "\n",
    "    if min_quote_vol_usdt is not None:\n",
    "        ranked = ranked[ranked[\"quoteVolumeUSDT_24h\"] >= float(min_quote_vol_usdt)].copy()\n",
    "\n",
    "    top = ranked.head(n).copy()\n",
    "    return top, ranked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a39df23b-a2f4-413e-b913-d138d3712d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top100, ranked_all = get_top_usdt_pairs(n=100)\n",
    "pairs = top100[\"symbol\"].tolist()\n",
    "\n",
    "len(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51bee877-e504-4a5c-94a7-68298b36bea4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[USDCUSDT] DB: ./db/USDCUSDT_5m_52weeks.db\n",
      "[USDCUSDT] Loaded 104,832 rows from DB.\n",
      "[ETHUSDT] DB: ./db/ETHUSDT_5m_52weeks.db\n",
      "[ETHUSDT] Loaded 104,832 rows from DB.\n",
      "[BTCUSDT] DB: ./db/BTCUSDT_5m_52weeks.db\n",
      "[BTCUSDT] Loaded 104,832 rows from DB.\n",
      "[USD1USDT] DB: ./db/USD1USDT_5m_52weeks.db\n",
      "[USD1USDT] Loaded 71,475 rows from DB.\n",
      "[SOLUSDT] DB: ./db/SOLUSDT_5m_52weeks.db\n",
      "[SOLUSDT] Loaded 104,832 rows from DB.\n",
      "[XRPUSDT] DB: ./db/XRPUSDT_5m_52weeks.db\n",
      "[XRPUSDT] Loaded 104,832 rows from DB.\n",
      "[FOGOUSDT] DB: ./db/FOGOUSDT_5m_52weeks.db\n",
      "[FOGOUSDT] Loaded 2,907 rows from DB.\n",
      "[FDUSDUSDT] DB: ./db/FDUSDUSDT_5m_52weeks.db\n",
      "[FDUSDUSDT] Loaded 104,832 rows from DB.\n",
      "[PAXGUSDT] DB: ./db/PAXGUSDT_5m_52weeks.db\n",
      "[PAXGUSDT] Loaded 104,832 rows from DB.\n",
      "[ZKPUSDT] DB: ./db/ZKPUSDT_5m_52weeks.db\n",
      "[ZKPUSDT] Loaded 5,212 rows from DB.\n",
      "[BNBUSDT] DB: ./db/BNBUSDT_5m_52weeks.db\n",
      "[BNBUSDT] Loaded 104,832 rows from DB.\n",
      "[AXSUSDT] DB: ./db/AXSUSDT_5m_52weeks.db\n",
      "[AXSUSDT] Loaded 104,832 rows from DB.\n",
      "[ZECUSDT] DB: ./db/ZECUSDT_5m_52weeks.db\n",
      "[ZECUSDT] Loaded 104,832 rows from DB.\n",
      "[DOGEUSDT] DB: ./db/DOGEUSDT_5m_52weeks.db\n",
      "[DOGEUSDT] Loaded 104,832 rows from DB.\n",
      "[SUIUSDT] DB: ./db/SUIUSDT_5m_52weeks.db\n",
      "[SUIUSDT] Loaded 104,832 rows from DB.\n",
      "[TRXUSDT] DB: ./db/TRXUSDT_5m_52weeks.db\n",
      "[TRXUSDT] Loaded 104,832 rows from DB.\n",
      "[PEPEUSDT] DB: ./db/PEPEUSDT_5m_52weeks.db\n",
      "[PEPEUSDT] Loaded 104,832 rows from DB.\n",
      "[WLFIUSDT] DB: ./db/WLFIUSDT_5m_52weeks.db\n",
      "[WLFIUSDT] Loaded 42,252 rows from DB.\n",
      "[PUMPUSDT] DB: ./db/PUMPUSDT_5m_52weeks.db\n",
      "[PUMPUSDT] Loaded 39,215 rows from DB.\n",
      "[ADAUSDT] DB: ./db/ADAUSDT_5m_52weeks.db\n",
      "[ADAUSDT] Loaded 104,832 rows from DB.\n",
      "[LTCUSDT] DB: ./db/LTCUSDT_5m_52weeks.db\n",
      "[LTCUSDT] Loaded 104,832 rows from DB.\n",
      "[ASTERUSDT] DB: ./db/ASTERUSDT_5m_52weeks.db\n",
      "[ASTERUSDT] Loaded 32,185 rows from DB.\n",
      "[DASHUSDT] DB: ./db/DASHUSDT_5m_52weeks.db\n",
      "[DASHUSDT] Loaded 104,832 rows from DB.\n",
      "[AVAXUSDT] DB: ./db/AVAXUSDT_5m_52weeks.db\n",
      "[AVAXUSDT] Loaded 104,832 rows from DB.\n",
      "[SENTUSDT] DB: ./db/SENTUSDT_5m_52weeks.db\n",
      "[SENTUSDT] Loaded 904 rows from DB.\n",
      "[LINKUSDT] DB: ./db/LINKUSDT_5m_52weeks.db\n",
      "[LINKUSDT] Loaded 104,832 rows from DB.\n",
      "[RESOLVUSDT] DB: ./db/RESOLVUSDT_5m_52weeks.db\n",
      "[RESOLVUSDT] Loaded 65,908 rows from DB.\n",
      "[ZROUSDT] DB: ./db/ZROUSDT_5m_52weeks.db\n",
      "[ZROUSDT] Loaded 104,832 rows from DB.\n",
      "[ENSOUSDT] DB: ./db/ENSOUSDT_5m_52weeks.db\n",
      "[ENSOUSDT] Loaded 29,751 rows from DB.\n",
      "[EURUSDT] DB: ./db/EURUSDT_5m_52weeks.db\n",
      "[EURUSDT] Loaded 104,832 rows from DB.\n",
      "[AUCTIONUSDT] DB: ./db/AUCTIONUSDT_5m_52weeks.db\n",
      "[AUCTIONUSDT] Loaded 104,832 rows from DB.\n",
      "[LINEAUSDT] DB: ./db/LINEAUSDT_5m_52weeks.db\n",
      "[LINEAUSDT] Loaded 39,633 rows from DB.\n",
      "[TAOUSDT] DB: ./db/TAOUSDT_5m_52weeks.db\n",
      "[TAOUSDT] Loaded 104,832 rows from DB.\n",
      "[UNIUSDT] DB: ./db/UNIUSDT_5m_52weeks.db\n",
      "[UNIUSDT] Loaded 104,832 rows from DB.\n",
      "[ENAUSDT] DB: ./db/ENAUSDT_5m_52weeks.db\n",
      "[ENAUSDT] Loaded 104,832 rows from DB.\n",
      "[BCHUSDT] DB: ./db/BCHUSDT_5m_52weeks.db\n",
      "[BCHUSDT] Loaded 104,832 rows from DB.\n",
      "[HMSTRUSDT] DB: ./db/HMSTRUSDT_5m_52weeks.db\n",
      "[HMSTRUSDT] No usable DB data found -> fetching from Binance...\n",
      "Fetching data from Binance API...\n",
      "[HMSTRUSDT] Fetched + stored + loaded 104,832 rows.\n",
      "[USDEUSDT] DB: ./db/USDEUSDT_5m_52weeks.db\n",
      "[USDEUSDT] Loaded 39,963 rows from DB.\n",
      "[NOMUSDT] DB: ./db/NOMUSDT_5m_52weeks.db\n",
      "[NOMUSDT] Loaded 33,508 rows from DB.\n",
      "[ZKCUSDT] DB: ./db/ZKCUSDT_5m_52weeks.db\n",
      "[ZKCUSDT] Loaded 38,044 rows from DB.\n",
      "[HBARUSDT] DB: ./db/HBARUSDT_5m_52weeks.db\n",
      "[HBARUSDT] Loaded 104,832 rows from DB.\n",
      "[PENGUUSDT] DB: ./db/PENGUUSDT_5m_52weeks.db\n",
      "[PENGUUSDT] Loaded 104,832 rows from DB.\n",
      "[NEARUSDT] DB: ./db/NEARUSDT_5m_52weeks.db\n",
      "[NEARUSDT] Loaded 104,832 rows from DB.\n",
      "[XUSDUSDT] DB: ./db/XUSDUSDT_5m_52weeks.db\n",
      "[XUSDUSDT] Loaded 90,132 rows from DB.\n",
      "[ROSEUSDT] DB: ./db/ROSEUSDT_5m_52weeks.db\n",
      "[ROSEUSDT] Loaded 104,832 rows from DB.\n",
      "[币安人生USDT] DB: ./db/币安人生USDT_5m_52weeks.db\n",
      "[币安人生USDT] Loaded 5,377 rows from DB.\n",
      "[VIRTUALUSDT] DB: ./db/VIRTUALUSDT_5m_52weeks.db\n",
      "[VIRTUALUSDT] Loaded 83,432 rows from DB.\n",
      "[CHZUSDT] DB: ./db/CHZUSDT_5m_52weeks.db\n",
      "[CHZUSDT] Loaded 104,832 rows from DB.\n",
      "[SOMIUSDT] DB: ./db/SOMIUSDT_5m_52weeks.db\n",
      "[SOMIUSDT] Loaded 41,782 rows from DB.\n",
      "[WBTCUSDT] DB: ./db/WBTCUSDT_5m_52weeks.db\n",
      "[WBTCUSDT] Loaded 104,832 rows from DB.\n",
      "[DUSKUSDT] DB: ./db/DUSKUSDT_5m_52weeks.db\n",
      "[DUSKUSDT] Loaded 104,832 rows from DB.\n",
      "[ARBUSDT] DB: ./db/ARBUSDT_5m_52weeks.db\n",
      "[ARBUSDT] Loaded 104,832 rows from DB.\n",
      "[APTUSDT] DB: ./db/APTUSDT_5m_52weeks.db\n",
      "[APTUSDT] Loaded 104,832 rows from DB.\n",
      "[XPLUSDT] DB: ./db/XPLUSDT_5m_52weeks.db\n",
      "[XPLUSDT] Loaded 35,344 rows from DB.\n",
      "[AAVEUSDT] DB: ./db/AAVEUSDT_5m_52weeks.db\n",
      "[AAVEUSDT] Loaded 104,832 rows from DB.\n",
      "[FILUSDT] DB: ./db/FILUSDT_5m_52weeks.db\n",
      "[FILUSDT] Loaded 104,832 rows from DB.\n",
      "[DODOUSDT] DB: ./db/DODOUSDT_5m_52weeks.db\n",
      "[DODOUSDT] Loaded 104,832 rows from DB.\n",
      "[ICPUSDT] DB: ./db/ICPUSDT_5m_52weeks.db\n",
      "[ICPUSDT] Loaded 104,832 rows from DB.\n",
      "[AXLUSDT] DB: ./db/AXLUSDT_5m_52weeks.db\n",
      "[AXLUSDT] Loaded 104,832 rows from DB.\n",
      "[DOTUSDT] DB: ./db/DOTUSDT_5m_52weeks.db\n",
      "[DOTUSDT] Loaded 104,832 rows from DB.\n",
      "[WIFUSDT] DB: ./db/WIFUSDT_5m_52weeks.db\n",
      "[WIFUSDT] Loaded 104,832 rows from DB.\n",
      "[SANDUSDT] DB: ./db/SANDUSDT_5m_52weeks.db\n",
      "[SANDUSDT] Loaded 104,832 rows from DB.\n",
      "[JTOUSDT] DB: ./db/JTOUSDT_5m_52weeks.db\n",
      "[JTOUSDT] Loaded 104,832 rows from DB.\n",
      "[RENDERUSDT] DB: ./db/RENDERUSDT_5m_52weeks.db\n",
      "[RENDERUSDT] Loaded 104,832 rows from DB.\n",
      "[ZENUSDT] DB: ./db/ZENUSDT_5m_52weeks.db\n",
      "[ZENUSDT] Loaded 104,832 rows from DB.\n",
      "[ALGOUSDT] DB: ./db/ALGOUSDT_5m_52weeks.db\n",
      "[ALGOUSDT] No usable DB data found -> fetching from Binance...\n",
      "Fetching data from Binance API...\n",
      "[ALGOUSDT] Fetched + stored + loaded 104,832 rows.\n",
      "[BFUSDUSDT] DB: ./db/BFUSDUSDT_5m_52weeks.db\n",
      "[BFUSDUSDT] Loaded 47,718 rows from DB.\n",
      "[WLDUSDT] DB: ./db/WLDUSDT_5m_52weeks.db\n",
      "[WLDUSDT] Loaded 104,832 rows from DB.\n",
      "[POLUSDT] DB: ./db/POLUSDT_5m_52weeks.db\n",
      "[POLUSDT] Loaded 104,832 rows from DB.\n",
      "[LPTUSDT] DB: ./db/LPTUSDT_5m_52weeks.db\n",
      "[LPTUSDT] Loaded 104,832 rows from DB.\n",
      "[KAIAUSDT] DB: ./db/KAIAUSDT_5m_52weeks.db\n",
      "[KAIAUSDT] Loaded 104,832 rows from DB.\n",
      "[XLMUSDT] DB: ./db/XLMUSDT_5m_52weeks.db\n",
      "[XLMUSDT] Loaded 104,832 rows from DB.\n",
      "[BONKUSDT] DB: ./db/BONKUSDT_5m_52weeks.db\n",
      "[BONKUSDT] Loaded 104,832 rows from DB.\n",
      "[FETUSDT] DB: ./db/FETUSDT_5m_52weeks.db\n",
      "[FETUSDT] Loaded 104,832 rows from DB.\n",
      "[2ZUSDT] DB: ./db/2ZUSDT_5m_52weeks.db\n",
      "[2ZUSDT] Loaded 33,383 rows from DB.\n",
      "[SHIBUSDT] DB: ./db/SHIBUSDT_5m_52weeks.db\n",
      "[SHIBUSDT] Loaded 104,832 rows from DB.\n",
      "[RVNUSDT] DB: ./db/RVNUSDT_5m_52weeks.db\n",
      "[RVNUSDT] No usable DB data found -> fetching from Binance...\n",
      "Error fetching data from Binance: HTTPSConnectionPool(host='api.binance.com', port=443): Read timed out.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[RVNUSDT] No data returned from Binance for the requested range.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m dfs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sym \u001b[38;5;129;01min\u001b[39;00m pairs:\n\u001b[0;32m----> 8\u001b[0m     db_path, df \u001b[38;5;241m=\u001b[39m \u001b[43mload_or_fetch_pair_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43msym\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweeks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     paths[sym] \u001b[38;5;241m=\u001b[39m db_path\n\u001b[1;32m     10\u001b[0m     dfs[sym] \u001b[38;5;241m=\u001b[39m df\n",
      "Cell \u001b[0;32mIn[6], line 44\u001b[0m, in \u001b[0;36mload_or_fetch_pair_df\u001b[0;34m(pair, interval, weeks)\u001b[0m\n\u001b[1;32m     42\u001b[0m data \u001b[38;5;241m=\u001b[39m binance_client\u001b[38;5;241m.\u001b[39mfetch_data(pair, start_ms, end_ms)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpair\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] No data returned from Binance for the requested range.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m binance_client\u001b[38;5;241m.\u001b[39mstore_data_to_db(pair, data)\n\u001b[1;32m     48\u001b[0m df \u001b[38;5;241m=\u001b[39m binance_client\u001b[38;5;241m.\u001b[39mfetch_data_from_db(pair)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [RVNUSDT] No data returned from Binance for the requested range."
     ]
    }
   ],
   "source": [
    "interval = \"5m\"\n",
    "weeks = 52\n",
    "\n",
    "paths = {}\n",
    "dfs = {}\n",
    "\n",
    "for sym in pairs:\n",
    "    db_path, df = load_or_fetch_pair_df(sym, interval, weeks)\n",
    "    paths[sym] = db_path\n",
    "    dfs[sym] = df\n",
    "    dfs[sym] = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924c6504-33ce-400e-9a64-1755e81db007",
   "metadata": {},
   "source": [
    "## Detect Comporession state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10154eca-6f14-4289-a5a9-bcbbe19bd944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def detect_compression_state(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    atr_short: int = 20,          # ~100 min on 5m\n",
    "    atr_long: int = 100,          # ~8 hours on 5m\n",
    "    vol_win: int = 144,           # volume median window (12 hours)\n",
    "    vol_ratio_thresh: float = 0.6,\n",
    "    rvol_thresh: float = 0.6,\n",
    "    min_duration: int = 12        # bars of sustained compression (60 min)\n",
    "):\n",
    "    \"\"\"\n",
    "    Detects pre-shock compression state.\n",
    "\n",
    "    Returns df with added columns:\n",
    "      - atr\n",
    "      - atr_med\n",
    "      - vol_compression\n",
    "      - rvol\n",
    "      - volu_compression\n",
    "      - compression_raw\n",
    "      - compression_duration\n",
    "      - is_compressed\n",
    "    \"\"\"\n",
    "\n",
    "    d = df.copy().sort_index()\n",
    "    d = d[[\"open\",\"high\",\"low\",\"close\",\"volume\"]].dropna()\n",
    "\n",
    "    # -----------------------\n",
    "    # 1) Volatility (ATR)\n",
    "    # -----------------------\n",
    "    high = d[\"high\"]\n",
    "    low  = d[\"low\"]\n",
    "    close = d[\"close\"]\n",
    "\n",
    "    tr = pd.concat([\n",
    "        high - low,\n",
    "        (high - close.shift()).abs(),\n",
    "        (low - close.shift()).abs()\n",
    "    ], axis=1).max(axis=1)\n",
    "\n",
    "    d[\"atr\"] = tr.rolling(atr_short).mean()\n",
    "    d[\"atr_med\"] = d[\"atr\"].rolling(atr_long).median()\n",
    "\n",
    "    d[\"vol_compression\"] = d[\"atr\"] / d[\"atr_med\"]\n",
    "    d[\"is_vol_compressed\"] = d[\"vol_compression\"] <= vol_ratio_thresh\n",
    "\n",
    "    # -----------------------\n",
    "    # 2) Volume compression\n",
    "    # -----------------------\n",
    "    vol_med = d[\"volume\"].rolling(vol_win).median()\n",
    "    d[\"rvol\"] = d[\"volume\"] / vol_med\n",
    "    d[\"is_volume_compressed\"] = d[\"rvol\"] <= rvol_thresh\n",
    "\n",
    "    # -----------------------\n",
    "    # 3) Raw compression flag\n",
    "    # -----------------------\n",
    "    d[\"compression_raw\"] = (\n",
    "        d[\"is_vol_compressed\"] &\n",
    "        d[\"is_volume_compressed\"]\n",
    "    )\n",
    "\n",
    "    # -----------------------\n",
    "    # 4) Duration counter\n",
    "    # -----------------------\n",
    "    duration = np.zeros(len(d), dtype=int)\n",
    "\n",
    "    for i in range(1, len(d)):\n",
    "        if d[\"compression_raw\"].iloc[i]:\n",
    "            duration[i] = duration[i-1] + 1\n",
    "        else:\n",
    "            duration[i] = 0\n",
    "\n",
    "    d[\"compression_duration\"] = duration\n",
    "\n",
    "    # -----------------------\n",
    "    # 5) Final state\n",
    "    # -----------------------\n",
    "    d[\"is_compressed\"] = d[\"compression_duration\"] >= min_duration\n",
    "\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c252a734-b5fb-4551-b6ac-8cb04e97daab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vol_compression</th>\n",
       "      <th>rvol</th>\n",
       "      <th>compression_duration</th>\n",
       "      <th>is_compressed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2026-01-24 12:50:00</th>\n",
       "      <td>0.868259</td>\n",
       "      <td>1.387158</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 12:55:00</th>\n",
       "      <td>0.837331</td>\n",
       "      <td>1.140229</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:00:00</th>\n",
       "      <td>0.797691</td>\n",
       "      <td>0.936581</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:05:00</th>\n",
       "      <td>0.779997</td>\n",
       "      <td>0.651361</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:10:00</th>\n",
       "      <td>0.775064</td>\n",
       "      <td>0.883699</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:15:00</th>\n",
       "      <td>0.786500</td>\n",
       "      <td>2.852841</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:20:00</th>\n",
       "      <td>0.698898</td>\n",
       "      <td>1.816785</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:25:00</th>\n",
       "      <td>0.675804</td>\n",
       "      <td>0.651221</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:30:00</th>\n",
       "      <td>0.657340</td>\n",
       "      <td>0.881418</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:35:00</th>\n",
       "      <td>0.694816</td>\n",
       "      <td>0.812190</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:40:00</th>\n",
       "      <td>0.640644</td>\n",
       "      <td>0.313170</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:45:00</th>\n",
       "      <td>0.582687</td>\n",
       "      <td>0.327921</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:50:00</th>\n",
       "      <td>0.545234</td>\n",
       "      <td>0.371703</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 13:55:00</th>\n",
       "      <td>0.916004</td>\n",
       "      <td>5.158043</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:00:00</th>\n",
       "      <td>1.439484</td>\n",
       "      <td>12.129071</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:05:00</th>\n",
       "      <td>1.814154</td>\n",
       "      <td>3.734550</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:10:00</th>\n",
       "      <td>1.900884</td>\n",
       "      <td>3.335517</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:15:00</th>\n",
       "      <td>1.900022</td>\n",
       "      <td>1.663950</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:20:00</th>\n",
       "      <td>1.900465</td>\n",
       "      <td>0.887099</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:25:00</th>\n",
       "      <td>1.923170</td>\n",
       "      <td>1.418124</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:30:00</th>\n",
       "      <td>2.016597</td>\n",
       "      <td>0.886594</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:35:00</th>\n",
       "      <td>2.056416</td>\n",
       "      <td>1.348959</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:40:00</th>\n",
       "      <td>2.088773</td>\n",
       "      <td>2.653494</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:45:00</th>\n",
       "      <td>2.185846</td>\n",
       "      <td>2.761525</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:50:00</th>\n",
       "      <td>2.207220</td>\n",
       "      <td>1.929704</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 14:55:00</th>\n",
       "      <td>2.195277</td>\n",
       "      <td>1.422006</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 15:00:00</th>\n",
       "      <td>2.279987</td>\n",
       "      <td>3.426879</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 15:05:00</th>\n",
       "      <td>2.369031</td>\n",
       "      <td>4.032178</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 15:10:00</th>\n",
       "      <td>2.435445</td>\n",
       "      <td>7.094364</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-24 15:15:00</th>\n",
       "      <td>2.511463</td>\n",
       "      <td>3.552484</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     vol_compression       rvol  compression_duration  \\\n",
       "timestamp                                                               \n",
       "2026-01-24 12:50:00         0.868259   1.387158                     0   \n",
       "2026-01-24 12:55:00         0.837331   1.140229                     0   \n",
       "2026-01-24 13:00:00         0.797691   0.936581                     0   \n",
       "2026-01-24 13:05:00         0.779997   0.651361                     0   \n",
       "2026-01-24 13:10:00         0.775064   0.883699                     0   \n",
       "2026-01-24 13:15:00         0.786500   2.852841                     0   \n",
       "2026-01-24 13:20:00         0.698898   1.816785                     0   \n",
       "2026-01-24 13:25:00         0.675804   0.651221                     0   \n",
       "2026-01-24 13:30:00         0.657340   0.881418                     0   \n",
       "2026-01-24 13:35:00         0.694816   0.812190                     0   \n",
       "2026-01-24 13:40:00         0.640644   0.313170                     0   \n",
       "2026-01-24 13:45:00         0.582687   0.327921                     1   \n",
       "2026-01-24 13:50:00         0.545234   0.371703                     2   \n",
       "2026-01-24 13:55:00         0.916004   5.158043                     0   \n",
       "2026-01-24 14:00:00         1.439484  12.129071                     0   \n",
       "2026-01-24 14:05:00         1.814154   3.734550                     0   \n",
       "2026-01-24 14:10:00         1.900884   3.335517                     0   \n",
       "2026-01-24 14:15:00         1.900022   1.663950                     0   \n",
       "2026-01-24 14:20:00         1.900465   0.887099                     0   \n",
       "2026-01-24 14:25:00         1.923170   1.418124                     0   \n",
       "2026-01-24 14:30:00         2.016597   0.886594                     0   \n",
       "2026-01-24 14:35:00         2.056416   1.348959                     0   \n",
       "2026-01-24 14:40:00         2.088773   2.653494                     0   \n",
       "2026-01-24 14:45:00         2.185846   2.761525                     0   \n",
       "2026-01-24 14:50:00         2.207220   1.929704                     0   \n",
       "2026-01-24 14:55:00         2.195277   1.422006                     0   \n",
       "2026-01-24 15:00:00         2.279987   3.426879                     0   \n",
       "2026-01-24 15:05:00         2.369031   4.032178                     0   \n",
       "2026-01-24 15:10:00         2.435445   7.094364                     0   \n",
       "2026-01-24 15:15:00         2.511463   3.552484                     0   \n",
       "\n",
       "                     is_compressed  \n",
       "timestamp                           \n",
       "2026-01-24 12:50:00          False  \n",
       "2026-01-24 12:55:00          False  \n",
       "2026-01-24 13:00:00          False  \n",
       "2026-01-24 13:05:00          False  \n",
       "2026-01-24 13:10:00          False  \n",
       "2026-01-24 13:15:00          False  \n",
       "2026-01-24 13:20:00          False  \n",
       "2026-01-24 13:25:00          False  \n",
       "2026-01-24 13:30:00          False  \n",
       "2026-01-24 13:35:00          False  \n",
       "2026-01-24 13:40:00          False  \n",
       "2026-01-24 13:45:00          False  \n",
       "2026-01-24 13:50:00          False  \n",
       "2026-01-24 13:55:00          False  \n",
       "2026-01-24 14:00:00          False  \n",
       "2026-01-24 14:05:00          False  \n",
       "2026-01-24 14:10:00          False  \n",
       "2026-01-24 14:15:00          False  \n",
       "2026-01-24 14:20:00          False  \n",
       "2026-01-24 14:25:00          False  \n",
       "2026-01-24 14:30:00          False  \n",
       "2026-01-24 14:35:00          False  \n",
       "2026-01-24 14:40:00          False  \n",
       "2026-01-24 14:45:00          False  \n",
       "2026-01-24 14:50:00          False  \n",
       "2026-01-24 14:55:00          False  \n",
       "2026-01-24 15:00:00          False  \n",
       "2026-01-24 15:05:00          False  \n",
       "2026-01-24 15:10:00          False  \n",
       "2026-01-24 15:15:00          False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dfs[\"BTCUSDT\"]\n",
    "df_c = detect_compression_state(df)\n",
    "\n",
    "df_c[[\"vol_compression\",\"rvol\",\"compression_duration\",\"is_compressed\"]].tail(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "973e7c80-ac75-4944-9da3-55846269a8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0025660103785103785)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c[\"is_compressed\"].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (binbot)",
   "language": "python",
   "name": "binbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
