{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ata/miniconda3/envs/ml-2/bin/python\n",
      "/home/ata/miniconda3/envs/ml-2/bin/jupyter\n"
     ]
    }
   ],
   "source": [
    "# Verify that we are using the correct Python (/home/ata/miniconda3/envs/ml/bin/)\n",
    "!which python\n",
    "!which jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 10:20:05.433076: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-08 10:20:05.435207: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-08 10:20:05.441934: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736313605.454310 1178438 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736313605.457738 1178438 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-08 10:20:05.469986: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from packaging import version\n",
    "import tensorflow as tf\n",
    "\n",
    "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the class from the Python file (module)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# from dotenv import load_dotenv\n",
    "# from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import seaborn as sns\n",
    "from BinanceClient import BinanceClient\n",
    "import numpy as np\n",
    "from typing import Final\n",
    "import joblib\n",
    "from BatchFeatures import BatchFeatures\n",
    "from datetime import datetime, timedelta\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch pair data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Binance client with your API credentials\n",
    "# dotenv_path = Path('.env-secret')\n",
    "# load_dotenv(dotenv_path=dotenv_path)\n",
    "api_secret = os.getenv(\"BINANCE_SECRET_KEY\")\n",
    "api_key = os.getenv(\"BINANCE_API_KEY\")\n",
    "\n",
    "# Create Binance client & initialize it\n",
    "pair = \"BTCUSDT\"\n",
    "time_delta = 12\n",
    "db_name = pair + \"_1min_\" + str(time_delta) + \"weeks.db\"\n",
    "db_name = \"BTCUSDT_1min_dry_run.db\"             # For dry run testing\n",
    "binance_client = BinanceClient(db_name)\n",
    "binance_client.set_interval(\"1m\")\n",
    "batch_feature = BatchFeatures()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fecth Data from Binance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from Binance API...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create connection to fetch data\n",
    "binance_client.make(api_key, api_secret)\n",
    "\n",
    "# Get current server time\n",
    "server_time = binance_client.get_server_time()\n",
    "\n",
    "# Compute start and end time for the last x hours\n",
    "server_time_dt = datetime.fromtimestamp(server_time['serverTime'] / 1000, tz=datetime.timezone.utc if hasattr(datetime, 'timezone') else None)\n",
    "end_date = server_time_dt\n",
    "# start_date = server_time_dt - timedelta(hours=10)\n",
    "start_date = server_time_dt - timedelta(weeks=time_delta)\n",
    "start_date_str = int(start_date.timestamp() * 1000)  # Convert to milliseconds\n",
    "end_date_str = int(end_date.timestamp() * 1000)      # Convert to milliseconds\n",
    "\n",
    "# Fetch data\n",
    "data = binance_client.fetch_data(pair, start_date_str, end_date_str)\n",
    "binance_client.store_data_to_db(pair, data)\n",
    "\n",
    "# Check if data is fetched\n",
    "if not data.empty:\n",
    "    df = data\n",
    "else:\n",
    "    print(\"No data found!!!.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch data from db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch data from db\n",
    "df = binance_client.fetch_data_from_db(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering (mind the order since some features are depended on others)\n",
    "bf = BatchFeatures()\n",
    "bf.calculate_sma(df)\n",
    "bf.calculate_ema(df)\n",
    "bf.calculate_rsi(df)\n",
    "bf.calculate_macd(df)\n",
    "bf.calculate_bollinger_bands(df)\n",
    "bf.calculate_atr(df)\n",
    "bf.calculate_volume_features(df)\n",
    "bf.calculate_roc(df)\n",
    "bf.calculate_lagged_features(df)\n",
    "bf.calculate_candle_features(df)\n",
    "bf.calculate_stochastic_oscillator(df)\n",
    "bf.calculate_williams_r(df)\n",
    "bf.calculate_moving_average_crossover(df)\n",
    "bf.calculate_historical_volatility(df)\n",
    "bf.calculate_on_balance_volume(df)\n",
    "bf.calculate_money_flow_index(df)\n",
    "bf.calculate_croc(df)\n",
    "\n",
    "# drop NaNs\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the percentage price change over the next 'n' candles\n",
    "nn = 10\n",
    "# df['target'] = (df['close'].shift(nn) - df['close'])\n",
    "# df['target'] = (df['close'].shift(nn) - df['close']) / df['close'] * 100\n",
    "df['target'] = (df['close'].shift(nn) - df['close']) / df['close'] * 100\n",
    "# df['target'] = (df['ema_5'].shift(nn) - df['ema_5']) / df['ema_5'] * 100\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test/Train Splot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the df into three parts, train, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lstm_scaler.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "# Use only the last 3 hours of data for training, validation, and testing\n",
    "df_recent = df.copy().iloc[-1920*4:]  # Adjust slice as needed\n",
    "\n",
    "# Calculate split indices\n",
    "n = len(df_recent)\n",
    "train_end = int(train_ratio * n)\n",
    "val_end = train_end + int(val_ratio * n)\n",
    "\n",
    "# Perform the splits\n",
    "train_data = df_recent.iloc[:train_end]\n",
    "val_data = df_recent.iloc[train_end:val_end]\n",
    "test_data = df_recent.iloc[val_end:]\n",
    "\n",
    "# Separate features (X_*) and targets (y_*)\n",
    "X_train = train_data.drop(columns=['target'])\n",
    "y_train = train_data['target']\n",
    "\n",
    "X_valid = val_data.drop(columns=['target'])\n",
    "y_valid = val_data['target']\n",
    "\n",
    "X_test = test_data.drop(columns=['target'])\n",
    "y_test = test_data['target']\n",
    "\n",
    "# Initialize the scaler and scale only the X_* components\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training features and transform\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "\n",
    "# Transform validation and test features\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_valid_scaled = pd.DataFrame(X_valid_scaled, columns=X_valid.columns, index=X_valid.index)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# Save the scaler for later use\n",
    "joblib.dump(scaler, 'lstm_scaler.pkl')\n",
    "\n",
    "# Combine scaled features (X_*) and unscaled targets (y_*) back into final datasets\n",
    "# train_data = pd.concat([X_train_scaled, y_train], axis=1)\n",
    "# valid_data = pd.concat([X_valid_scaled, y_valid], axis=1)\n",
    "# test_data = pd.concat([X_test_scaled, y_test], axis=1)\n",
    "\n",
    "# Output lengths of each dataset to verify correctness\n",
    "# print(f\"Train data shape: {train_data.shape}\")\n",
    "# print(f\"Validation data shape: {valid_data.shape}\")\n",
    "# print(f\"Test data shape: {test_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomize the time sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 10:22:27.765265: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Sequence length (5 hours = 300 instances for 1-minute resolution)\n",
    "seq_length = 60\n",
    "batch_size = 32*4\n",
    "\n",
    "# Create time series datasets\n",
    "tf.random.set_seed(42)  # Ensures reproducibility\n",
    "\n",
    "# Training dataset\n",
    "train_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    data=X_train_scaled.iloc[:-seq_length].to_numpy(),  # Exclude the last 'seq_length' rows for input\n",
    "    targets=y_train.iloc[seq_length:].to_numpy(),  # Shift target by 'seq_length'\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Validation dataset\n",
    "valid_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    data=X_valid_scaled.iloc[:-seq_length].to_numpy(),\n",
    "    targets=y_valid.iloc[seq_length:].to_numpy(),\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – defines a utility function we'll reuse several time\n",
    "\n",
    "def fit_and_evaluate(model, train_set, valid_set, learning_rate, epochs=500):\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_mae\", patience=50, restore_best_weights=True)\n",
    "    # opt = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    opt=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])\n",
    "    history = model.fit(train_set, validation_data=valid_set, epochs=epochs,\n",
    "                        callbacks=[early_stopping_cb])\n",
    "    valid_loss, valid_mae = model.evaluate(valid_set)\n",
    "    return valid_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple RNN Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(64, activation=\"tanh\", return_sequences=True, input_shape=[None, 52]),\n",
    "    tf.keras.layers.LSTM(64, activation=\"tanh\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ata/miniconda3/envs/ml-2/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(64, activation=\"relu\", return_sequences=True, input_shape=[None, 51]),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.LSTM(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - loss: 0.0728 - mae: 0.2148 - val_loss: 0.0022 - val_mae: 0.0504\n",
      "Epoch 2/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0088 - mae: 0.0983 - val_loss: 0.0017 - val_mae: 0.0451\n",
      "Epoch 3/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0063 - mae: 0.0834 - val_loss: 0.0015 - val_mae: 0.0412\n",
      "Epoch 4/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0056 - mae: 0.0781 - val_loss: 0.0016 - val_mae: 0.0430\n",
      "Epoch 5/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0056 - mae: 0.0776 - val_loss: 0.0014 - val_mae: 0.0396\n",
      "Epoch 6/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0049 - mae: 0.0731 - val_loss: 0.0014 - val_mae: 0.0392\n",
      "Epoch 7/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0048 - mae: 0.0725 - val_loss: 0.0013 - val_mae: 0.0388\n",
      "Epoch 8/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0047 - mae: 0.0714 - val_loss: 0.0014 - val_mae: 0.0394\n",
      "Epoch 9/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0044 - mae: 0.0703 - val_loss: 0.0013 - val_mae: 0.0384\n",
      "Epoch 10/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0043 - mae: 0.0686 - val_loss: 0.0014 - val_mae: 0.0393\n",
      "Epoch 11/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0046 - mae: 0.0706 - val_loss: 0.0013 - val_mae: 0.0381\n",
      "Epoch 12/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0048 - mae: 0.0716 - val_loss: 0.0014 - val_mae: 0.0396\n",
      "Epoch 13/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0041 - mae: 0.0674 - val_loss: 0.0012 - val_mae: 0.0374\n",
      "Epoch 14/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0043 - mae: 0.0670 - val_loss: 0.0013 - val_mae: 0.0378\n",
      "Epoch 15/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0040 - mae: 0.0670 - val_loss: 0.0013 - val_mae: 0.0387\n",
      "Epoch 16/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0040 - mae: 0.0669 - val_loss: 0.0012 - val_mae: 0.0373\n",
      "Epoch 17/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0039 - mae: 0.0655 - val_loss: 0.0013 - val_mae: 0.0386\n",
      "Epoch 18/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0039 - mae: 0.0659 - val_loss: 0.0013 - val_mae: 0.0375\n",
      "Epoch 19/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0039 - mae: 0.0660 - val_loss: 0.0012 - val_mae: 0.0368\n",
      "Epoch 20/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0038 - mae: 0.0640 - val_loss: 0.0013 - val_mae: 0.0378\n",
      "Epoch 21/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0038 - mae: 0.0645 - val_loss: 0.0012 - val_mae: 0.0373\n",
      "Epoch 22/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0038 - mae: 0.0647 - val_loss: 0.0013 - val_mae: 0.0382\n",
      "Epoch 23/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0038 - mae: 0.0649 - val_loss: 0.0012 - val_mae: 0.0365\n",
      "Epoch 24/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0037 - mae: 0.0627 - val_loss: 0.0012 - val_mae: 0.0373\n",
      "Epoch 25/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0037 - mae: 0.0638 - val_loss: 0.0012 - val_mae: 0.0367\n",
      "Epoch 26/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0036 - mae: 0.0630 - val_loss: 0.0012 - val_mae: 0.0375\n",
      "Epoch 27/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0038 - mae: 0.0648 - val_loss: 0.0015 - val_mae: 0.0418\n",
      "Epoch 28/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0036 - mae: 0.0637 - val_loss: 0.0013 - val_mae: 0.0383\n",
      "Epoch 29/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0037 - mae: 0.0631 - val_loss: 0.0012 - val_mae: 0.0374\n",
      "Epoch 30/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0036 - mae: 0.0628 - val_loss: 0.0013 - val_mae: 0.0390\n",
      "Epoch 31/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0035 - mae: 0.0632 - val_loss: 0.0012 - val_mae: 0.0368\n",
      "Epoch 32/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0035 - mae: 0.0617 - val_loss: 0.0012 - val_mae: 0.0365\n",
      "Epoch 33/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0037 - mae: 0.0639 - val_loss: 0.0013 - val_mae: 0.0379\n",
      "Epoch 34/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0035 - mae: 0.0626 - val_loss: 0.0012 - val_mae: 0.0378\n",
      "Epoch 35/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0035 - mae: 0.0619 - val_loss: 0.0013 - val_mae: 0.0378\n",
      "Epoch 36/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0034 - mae: 0.0616 - val_loss: 0.0013 - val_mae: 0.0378\n",
      "Epoch 37/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0037 - mae: 0.0639 - val_loss: 0.0012 - val_mae: 0.0366\n",
      "Epoch 38/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0035 - mae: 0.0619 - val_loss: 0.0013 - val_mae: 0.0391\n",
      "Epoch 39/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0034 - mae: 0.0621 - val_loss: 0.0012 - val_mae: 0.0368\n",
      "Epoch 40/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0013 - val_mae: 0.0378\n",
      "Epoch 41/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0035 - mae: 0.0619 - val_loss: 0.0013 - val_mae: 0.0386\n",
      "Epoch 42/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0011 - val_mae: 0.0360\n",
      "Epoch 43/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0012 - val_mae: 0.0367\n",
      "Epoch 44/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0032 - mae: 0.0601 - val_loss: 0.0013 - val_mae: 0.0384\n",
      "Epoch 45/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0012 - val_mae: 0.0371\n",
      "Epoch 46/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0033 - mae: 0.0605 - val_loss: 0.0012 - val_mae: 0.0366\n",
      "Epoch 47/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0032 - mae: 0.0605 - val_loss: 0.0012 - val_mae: 0.0372\n",
      "Epoch 48/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0033 - mae: 0.0603 - val_loss: 0.0015 - val_mae: 0.0415\n",
      "Epoch 49/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0035 - mae: 0.0622 - val_loss: 0.0012 - val_mae: 0.0368\n",
      "Epoch 50/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0011 - val_mae: 0.0357\n",
      "Epoch 51/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0012 - val_mae: 0.0368\n",
      "Epoch 52/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0014 - val_mae: 0.0392\n",
      "Epoch 53/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0011 - val_mae: 0.0362\n",
      "Epoch 54/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0031 - mae: 0.0593 - val_loss: 0.0011 - val_mae: 0.0355\n",
      "Epoch 55/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0012 - val_mae: 0.0368\n",
      "Epoch 56/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0031 - mae: 0.0598 - val_loss: 0.0011 - val_mae: 0.0360\n",
      "Epoch 57/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0030 - mae: 0.0584 - val_loss: 0.0012 - val_mae: 0.0370\n",
      "Epoch 58/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0031 - mae: 0.0585 - val_loss: 0.0013 - val_mae: 0.0377\n",
      "Epoch 59/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0031 - mae: 0.0591 - val_loss: 0.0012 - val_mae: 0.0369\n",
      "Epoch 60/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0030 - mae: 0.0574 - val_loss: 0.0013 - val_mae: 0.0392\n",
      "Epoch 61/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0030 - mae: 0.0585 - val_loss: 0.0012 - val_mae: 0.0372\n",
      "Epoch 62/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0030 - mae: 0.0576 - val_loss: 0.0013 - val_mae: 0.0384\n",
      "Epoch 63/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0035 - mae: 0.0623 - val_loss: 0.0013 - val_mae: 0.0378\n",
      "Epoch 64/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0012 - val_mae: 0.0366\n",
      "Epoch 65/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0032 - mae: 0.0590 - val_loss: 0.0012 - val_mae: 0.0367\n",
      "Epoch 66/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0031 - mae: 0.0571 - val_loss: 0.0012 - val_mae: 0.0374\n",
      "Epoch 67/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0030 - mae: 0.0577 - val_loss: 0.0011 - val_mae: 0.0360\n",
      "Epoch 68/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0011 - val_mae: 0.0363\n",
      "Epoch 69/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0030 - mae: 0.0572 - val_loss: 0.0011 - val_mae: 0.0350\n",
      "Epoch 70/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0011 - val_mae: 0.0351\n",
      "Epoch 71/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0030 - mae: 0.0584 - val_loss: 0.0011 - val_mae: 0.0356\n",
      "Epoch 72/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0012 - val_mae: 0.0364\n",
      "Epoch 73/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0029 - mae: 0.0566 - val_loss: 0.0011 - val_mae: 0.0360\n",
      "Epoch 74/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0030 - mae: 0.0579 - val_loss: 0.0012 - val_mae: 0.0355\n",
      "Epoch 75/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0030 - mae: 0.0575 - val_loss: 0.0012 - val_mae: 0.0364\n",
      "Epoch 76/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0028 - mae: 0.0564 - val_loss: 0.0011 - val_mae: 0.0354\n",
      "Epoch 77/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0039 - mae: 0.0593 - val_loss: 0.0012 - val_mae: 0.0375\n",
      "Epoch 78/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0030 - mae: 0.0575 - val_loss: 0.0012 - val_mae: 0.0361\n",
      "Epoch 79/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0029 - mae: 0.0566 - val_loss: 0.0010 - val_mae: 0.0339\n",
      "Epoch 80/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0028 - mae: 0.0560 - val_loss: 0.0011 - val_mae: 0.0357\n",
      "Epoch 81/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0031 - mae: 0.0579 - val_loss: 0.0011 - val_mae: 0.0347\n",
      "Epoch 82/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0030 - mae: 0.0580 - val_loss: 0.0011 - val_mae: 0.0355\n",
      "Epoch 83/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0027 - mae: 0.0549 - val_loss: 0.0012 - val_mae: 0.0366\n",
      "Epoch 84/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0028 - mae: 0.0553 - val_loss: 0.0011 - val_mae: 0.0360\n",
      "Epoch 85/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0028 - mae: 0.0559 - val_loss: 0.0011 - val_mae: 0.0353\n",
      "Epoch 86/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0028 - mae: 0.0554 - val_loss: 0.0012 - val_mae: 0.0373\n",
      "Epoch 87/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0027 - mae: 0.0551 - val_loss: 0.0010 - val_mae: 0.0342\n",
      "Epoch 88/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0028 - mae: 0.0561 - val_loss: 0.0013 - val_mae: 0.0379\n",
      "Epoch 89/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0028 - mae: 0.0554 - val_loss: 0.0012 - val_mae: 0.0365\n",
      "Epoch 90/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0026 - mae: 0.0546 - val_loss: 0.0011 - val_mae: 0.0349\n",
      "Epoch 91/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0028 - mae: 0.0548 - val_loss: 0.0011 - val_mae: 0.0351\n",
      "Epoch 92/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0026 - mae: 0.0540 - val_loss: 0.0011 - val_mae: 0.0346\n",
      "Epoch 93/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0027 - mae: 0.0554 - val_loss: 0.0010 - val_mae: 0.0338\n",
      "Epoch 94/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0011 - val_mae: 0.0352\n",
      "Epoch 95/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0028 - mae: 0.0555 - val_loss: 0.0012 - val_mae: 0.0361\n",
      "Epoch 96/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0029 - mae: 0.0558 - val_loss: 0.0010 - val_mae: 0.0338\n",
      "Epoch 97/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0028 - mae: 0.0560 - val_loss: 0.0011 - val_mae: 0.0348\n",
      "Epoch 98/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0028 - mae: 0.0551 - val_loss: 0.0011 - val_mae: 0.0343\n",
      "Epoch 99/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0029 - mae: 0.0563 - val_loss: 0.0011 - val_mae: 0.0361\n",
      "Epoch 100/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0026 - mae: 0.0539 - val_loss: 0.0012 - val_mae: 0.0370\n",
      "Epoch 101/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0029 - mae: 0.0574 - val_loss: 0.0010 - val_mae: 0.0344\n",
      "Epoch 102/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0029 - mae: 0.0563 - val_loss: 0.0011 - val_mae: 0.0359\n",
      "Epoch 103/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0026 - mae: 0.0536 - val_loss: 0.0011 - val_mae: 0.0360\n",
      "Epoch 104/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0024 - mae: 0.0523 - val_loss: 0.0011 - val_mae: 0.0361\n",
      "Epoch 105/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0026 - mae: 0.0541 - val_loss: 0.0011 - val_mae: 0.0352\n",
      "Epoch 106/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0025 - mae: 0.0527 - val_loss: 0.0011 - val_mae: 0.0345\n",
      "Epoch 107/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0028 - mae: 0.0552 - val_loss: 0.0011 - val_mae: 0.0343\n",
      "Epoch 108/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0027 - mae: 0.0543 - val_loss: 0.0010 - val_mae: 0.0336\n",
      "Epoch 109/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0027 - mae: 0.0543 - val_loss: 0.0011 - val_mae: 0.0346\n",
      "Epoch 110/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0028 - mae: 0.0543 - val_loss: 0.0011 - val_mae: 0.0353\n",
      "Epoch 111/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0026 - mae: 0.0533 - val_loss: 0.0011 - val_mae: 0.0342\n",
      "Epoch 112/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0025 - mae: 0.0535 - val_loss: 0.0012 - val_mae: 0.0354\n",
      "Epoch 113/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0025 - mae: 0.0525 - val_loss: 0.0011 - val_mae: 0.0343\n",
      "Epoch 114/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0026 - mae: 0.0541 - val_loss: 0.0011 - val_mae: 0.0349\n",
      "Epoch 115/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0025 - mae: 0.0533 - val_loss: 0.0012 - val_mae: 0.0366\n",
      "Epoch 116/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0026 - mae: 0.0540 - val_loss: 0.0011 - val_mae: 0.0348\n",
      "Epoch 117/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0025 - mae: 0.0532 - val_loss: 0.0011 - val_mae: 0.0345\n",
      "Epoch 118/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0026 - mae: 0.0535 - val_loss: 0.0011 - val_mae: 0.0356\n",
      "Epoch 119/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0025 - mae: 0.0523 - val_loss: 0.0012 - val_mae: 0.0358\n",
      "Epoch 120/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0026 - mae: 0.0528 - val_loss: 0.0012 - val_mae: 0.0360\n",
      "Epoch 121/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0027 - mae: 0.0555 - val_loss: 0.0011 - val_mae: 0.0349\n",
      "Epoch 122/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0025 - mae: 0.0527 - val_loss: 0.0011 - val_mae: 0.0353\n",
      "Epoch 123/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.0026 - mae: 0.0541 - val_loss: 0.0011 - val_mae: 0.0342\n",
      "Epoch 124/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0025 - mae: 0.0525 - val_loss: 0.0011 - val_mae: 0.0352\n",
      "Epoch 125/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0025 - mae: 0.0528 - val_loss: 0.0010 - val_mae: 0.0335\n",
      "Epoch 126/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0025 - mae: 0.0535 - val_loss: 0.0012 - val_mae: 0.0355\n",
      "Epoch 127/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0025 - mae: 0.0530 - val_loss: 0.0010 - val_mae: 0.0339\n",
      "Epoch 128/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0024 - mae: 0.0522 - val_loss: 0.0011 - val_mae: 0.0353\n",
      "Epoch 129/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0024 - mae: 0.0522 - val_loss: 0.0011 - val_mae: 0.0344\n",
      "Epoch 130/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0025 - mae: 0.0530 - val_loss: 0.0010 - val_mae: 0.0337\n",
      "Epoch 131/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0025 - mae: 0.0526 - val_loss: 0.0010 - val_mae: 0.0334\n",
      "Epoch 132/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0025 - mae: 0.0529 - val_loss: 0.0011 - val_mae: 0.0344\n",
      "Epoch 133/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.0025 - mae: 0.0521 - val_loss: 9.7806e-04 - val_mae: 0.0327\n",
      "Epoch 134/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0024 - mae: 0.0522 - val_loss: 0.0011 - val_mae: 0.0346\n",
      "Epoch 135/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0024 - mae: 0.0518 - val_loss: 9.8003e-04 - val_mae: 0.0326\n",
      "Epoch 136/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0025 - mae: 0.0531 - val_loss: 0.0012 - val_mae: 0.0370\n",
      "Epoch 137/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0024 - mae: 0.0521 - val_loss: 0.0011 - val_mae: 0.0346\n",
      "Epoch 138/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0025 - mae: 0.0532 - val_loss: 0.0011 - val_mae: 0.0352\n",
      "Epoch 139/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.0026 - mae: 0.0545 - val_loss: 0.0011 - val_mae: 0.0344\n",
      "Epoch 140/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0024 - mae: 0.0515 - val_loss: 0.0011 - val_mae: 0.0341\n",
      "Epoch 141/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0023 - mae: 0.0509 - val_loss: 0.0011 - val_mae: 0.0341\n",
      "Epoch 142/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0026 - mae: 0.0532 - val_loss: 0.0012 - val_mae: 0.0359\n",
      "Epoch 143/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0024 - mae: 0.0512 - val_loss: 0.0011 - val_mae: 0.0345\n",
      "Epoch 144/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0023 - mae: 0.0515 - val_loss: 0.0011 - val_mae: 0.0341\n",
      "Epoch 145/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0023 - mae: 0.0505 - val_loss: 0.0011 - val_mae: 0.0343\n",
      "Epoch 146/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0026 - mae: 0.0536 - val_loss: 0.0010 - val_mae: 0.0338\n",
      "Epoch 147/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0024 - mae: 0.0520 - val_loss: 0.0012 - val_mae: 0.0361\n",
      "Epoch 148/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0025 - mae: 0.0532 - val_loss: 0.0011 - val_mae: 0.0349\n",
      "Epoch 149/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0024 - mae: 0.0511 - val_loss: 0.0010 - val_mae: 0.0339\n",
      "Epoch 150/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0024 - mae: 0.0513 - val_loss: 0.0011 - val_mae: 0.0346\n",
      "Epoch 151/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0024 - mae: 0.0513 - val_loss: 9.8894e-04 - val_mae: 0.0329\n",
      "Epoch 152/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0024 - mae: 0.0519 - val_loss: 0.0012 - val_mae: 0.0362\n",
      "Epoch 153/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0023 - mae: 0.0503 - val_loss: 0.0012 - val_mae: 0.0355\n",
      "Epoch 154/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0024 - mae: 0.0514 - val_loss: 0.0010 - val_mae: 0.0338\n",
      "Epoch 155/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0023 - mae: 0.0499 - val_loss: 0.0011 - val_mae: 0.0340\n",
      "Epoch 156/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0026 - mae: 0.0533 - val_loss: 0.0010 - val_mae: 0.0333\n",
      "Epoch 157/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0024 - mae: 0.0516 - val_loss: 0.0012 - val_mae: 0.0356\n",
      "Epoch 158/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0023 - mae: 0.0508 - val_loss: 0.0011 - val_mae: 0.0351\n",
      "Epoch 159/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0024 - mae: 0.0518 - val_loss: 0.0010 - val_mae: 0.0330\n",
      "Epoch 160/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0023 - mae: 0.0510 - val_loss: 0.0011 - val_mae: 0.0345\n",
      "Epoch 161/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0023 - mae: 0.0508 - val_loss: 0.0012 - val_mae: 0.0361\n",
      "Epoch 162/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.0023 - mae: 0.0512 - val_loss: 0.0010 - val_mae: 0.0332\n",
      "Epoch 163/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0023 - mae: 0.0510 - val_loss: 0.0010 - val_mae: 0.0336\n",
      "Epoch 164/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0022 - mae: 0.0499 - val_loss: 0.0010 - val_mae: 0.0336\n",
      "Epoch 165/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0023 - mae: 0.0503 - val_loss: 0.0011 - val_mae: 0.0348\n",
      "Epoch 166/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0022 - mae: 0.0495 - val_loss: 0.0010 - val_mae: 0.0341\n",
      "Epoch 167/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0022 - mae: 0.0497 - val_loss: 0.0010 - val_mae: 0.0343\n",
      "Epoch 168/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0023 - mae: 0.0509 - val_loss: 0.0010 - val_mae: 0.0333\n",
      "Epoch 169/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0022 - mae: 0.0500 - val_loss: 0.0012 - val_mae: 0.0362\n",
      "Epoch 170/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0023 - mae: 0.0505 - val_loss: 0.0010 - val_mae: 0.0333\n",
      "Epoch 171/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0021 - mae: 0.0483 - val_loss: 0.0011 - val_mae: 0.0339\n",
      "Epoch 172/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0023 - mae: 0.0503 - val_loss: 0.0011 - val_mae: 0.0345\n",
      "Epoch 173/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0022 - mae: 0.0498 - val_loss: 0.0011 - val_mae: 0.0350\n",
      "Epoch 174/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0021 - mae: 0.0491 - val_loss: 0.0011 - val_mae: 0.0343\n",
      "Epoch 175/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0022 - mae: 0.0494 - val_loss: 0.0011 - val_mae: 0.0346\n",
      "Epoch 176/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0021 - mae: 0.0487 - val_loss: 9.8910e-04 - val_mae: 0.0330\n",
      "Epoch 177/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0022 - mae: 0.0494 - val_loss: 0.0012 - val_mae: 0.0356\n",
      "Epoch 178/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0023 - mae: 0.0509 - val_loss: 0.0011 - val_mae: 0.0348\n",
      "Epoch 179/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0022 - mae: 0.0486 - val_loss: 0.0011 - val_mae: 0.0340\n",
      "Epoch 180/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0021 - mae: 0.0491 - val_loss: 0.0011 - val_mae: 0.0341\n",
      "Epoch 181/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0028 - mae: 0.0519 - val_loss: 0.0011 - val_mae: 0.0344\n",
      "Epoch 182/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0027 - mae: 0.0521 - val_loss: 0.0011 - val_mae: 0.0351\n",
      "Epoch 183/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0024 - mae: 0.0508 - val_loss: 0.0012 - val_mae: 0.0361\n",
      "Epoch 184/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0022 - mae: 0.0492 - val_loss: 0.0011 - val_mae: 0.0342\n",
      "Epoch 185/500\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0020 - mae: 0.0485 - val_loss: 0.0011 - val_mae: 0.0341\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0014 - mae: 0.0396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.032598864287137985"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_and_evaluate(model, train_ds, valid_ds, learning_rate=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trtained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lstm_10candles_1min.joblib']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "joblib.dump(model, 'lstm_10candles_1min.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load previously trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model\n",
    "model = joblib.load('lstm_5candles_1min.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target abs mean: 0.23579404234325918\n",
      "Target std deviation: 0.3025890970668356\n",
      "Target min: -1.306111988423618\n",
      "Target max: 0.7365753207666758\n"
     ]
    }
   ],
   "source": [
    "print(f\"Target abs mean: {y_test.abs().mean()}\")\n",
    "print(f\"Target std deviation: {y_test.std()}\")\n",
    "print(f\"Target min: {y_test.min()}\")\n",
    "print(f\"Target max: {y_test.max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (128, 60, 51)\n",
      "Target shape: (128,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 07:23:22.890062: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input shape:\", x.shape)  # Should be (batch_size, time_steps, features)\n",
    "    print(\"Target shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_BALANCE=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate sequences for LSTM input\n",
    "# seq_length = 60  # Replace with the sequence length used during training\n",
    "X_test_copy = X_test_scaled.copy()\n",
    "y_test_copy = y_test.copy()\n",
    "X_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for i in range(seq_length, len(test_data)-nn):\n",
    "    X_test_list.append(X_test_copy.iloc[i-seq_length:i])  # Create sequence\n",
    "    y_test_list.append(y_test_copy.iloc[i])\n",
    "    # y_test.append( (test_data.iloc[i + nn]['close'] - test_data.iloc[i]['close']) / test_data.iloc[i]['close'] * 100)  # Price change nn candles ahead\n",
    "\n",
    "X_test_list = np.array(X_test_list)\n",
    "y_test_list = np.array(y_test_list)\n",
    "\n",
    "# Unscale predictions\n",
    "predictions = model.predict(X_test_list)  # Predictions are in scaled space\n",
    "predictions = predictions.flatten()\n",
    "\n",
    "# predictions = scaler.inverse_transform(\n",
    "#     np.hstack([np.zeros((predictions_scaled.shape[0], test_data_scaled.shape[1]-1)), predictions_scaled])\n",
    "# )[:, -1]  # Unscale the 'close' column only\n",
    "\n",
    "# Prepend 'nn' NaNs to align predictions with actual changes\n",
    "predictions = np.concatenate((1*predictions, np.full(nn, np.nan)))\n",
    "# predictions = -1*predictions \n",
    "\n",
    "\n",
    "# Combine predictions and actual values\n",
    "results_df = X_test[seq_length:].copy()\n",
    "results_df['Predicted Change'] = predictions  # Model output: predicted change in price\n",
    "results_df['Actual Change'] = y_test   # Actual change in price (target)\n",
    "\n",
    "# Calculate predicted price\n",
    "results_df['Predicted Price'] = results_df['close'] * (1 + results_df['Predicted Change']/100)\n",
    "\n",
    "# Optionally include actual future prices for comparison\n",
    "# results_df['Actual Price'] = results_df['close'] * (1 + results_df['Actual Change'])  # Actual future close price\n",
    "\n",
    "# results_df.dropna(inplace=True)  # Remove NaNs caused by shifting\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df['Actual Future Price'] = results_df['close']  # Actual future close price\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(12, 7))\n",
    "# results_df['Predicted Price'].plot()\n",
    "# results_df['close'].plot()\n",
    "results_df['Predicted Change'].plot()\n",
    "results_df['Actual Change'].plot()\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Change: -0.5142806172370911\n",
      "Max Change: 0.9654271602630615\n"
     ]
    }
   ],
   "source": [
    "predict_ch_min = results_df[\"Predicted Change\"].min()\n",
    "predict_ch_max = results_df[\"Predicted Change\"].max()\n",
    "print(f'Min Change: {predict_ch_min}')\n",
    "print(f'Max Change: {predict_ch_max}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_trades(signals, prices, initial_balance=1000):\n",
    "    \"\"\"\n",
    "    Simulates trades based on signals and actual price changes.\n",
    "\n",
    "    Args:\n",
    "        actual_changes (list or pd.Series): Actual percentage changes (not predicted).\n",
    "        signals (list): List of trading signals (\"Buy\", \"Sell\", \"Hold\").\n",
    "        prices (list or pd.Series): Actual price values for the asset.\n",
    "        initial_balance (float): Starting balance of the trading account.\n",
    "\n",
    "    Returns:\n",
    "        float: Final balance or cumulative profit.\n",
    "    \"\"\"\n",
    "    balance = INITIAL_BALANCE\n",
    "    position = 0  # Tracks the number of stocks held\n",
    "    entry_price = None  # Store the price when a \"Buy\" was executed\n",
    "\n",
    "    for i, signal in enumerate(signals):\n",
    "        if signal == 1 and balance > 0:\n",
    "            # Execute a buy\n",
    "            entry_price = prices.iloc[i]  # Use .iloc for positional indexing\n",
    "            position = balance / entry_price  # Buy with all available balance\n",
    "            balance = 0  # All balance used to buy\n",
    "        elif signal == -1 and position > 0:\n",
    "            # Execute a sell\n",
    "            exit_price = prices.iloc[i]  # Use .iloc for positional indexing\n",
    "            balance = position * exit_price  # Convert position to cash\n",
    "            position = 0  # Clear position\n",
    "            entry_price = None  # Reset entry price after selling\n",
    "\n",
    "    # If there's a remaining position at the end, calculate its value\n",
    "    if position > 0 and entry_price is not None:\n",
    "        balance += position * prices.iloc[-1]  # Use .iloc for positional indexing\n",
    "\n",
    "    return balance - INITIAL_BALANCE  # Return cumulative profit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "results_df[\"Predicted Change\"].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Buy Threshold: 0.3051, Best Sell Threshold: -0.054280617237090656\n",
      "Best Performance: 11.989245237638102\n"
     ]
    }
   ],
   "source": [
    "# Define buy and sell thresholds (e.g., absolute differences in predicted vs. actual price)\n",
    "sell_thresholds = np.arange(predict_ch_min, -0.0001, 0.005)  # Thresholds for when to \"Sell\"; Sell when price is predicted to go down\n",
    "buy_thresholds = np.arange(0.0001, predict_ch_max, 0.005)   # Thresholds for when to \"Buy\"; buy when price is predicted to go up\n",
    "\n",
    "best_buy_threshold = None\n",
    "best_sell_threshold = None\n",
    "best_performance = -np.inf\n",
    "\n",
    "ii = 0\n",
    "jj = 0\n",
    "performance = np.zeros((len(buy_thresholds), len(sell_thresholds)))\n",
    "# -1 = Sell\n",
    "# 0 = Hold\n",
    "# 1 = Buy\n",
    "for buy_th in buy_thresholds:\n",
    "    for sell_th in sell_thresholds:\n",
    "        # Generate signals\n",
    "        trading_signals = [\n",
    "            -1 if pred < sell_th else 1 if pred > buy_th else 0\n",
    "            for pred in results_df['Predicted Change']\n",
    "        ]\n",
    "\n",
    "        # Simulate trades and calculate performance\n",
    "        performance[ii, jj] = simulate_trades(\n",
    "            signals=trading_signals,\n",
    "            prices=results_df['close'],  # Use the computed predicted prices\n",
    "            initial_balance=INITIAL_BALANCE\n",
    "        )\n",
    "        # Update best thresholds if current performance is better\n",
    "        if performance[ii, jj] > best_performance:\n",
    "            best_performance = performance[ii, jj]\n",
    "            best_buy_threshold = buy_th\n",
    "            best_sell_threshold = sell_th\n",
    "        jj += 1\n",
    "    ii += 1\n",
    "    jj = 0\n",
    "print(f\"Best Buy Threshold: {best_buy_threshold}, Best Sell Threshold: {best_sell_threshold}\")\n",
    "print(f\"Best Performance: {best_performance}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beck Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Balance: $1016.15\n",
      "Net Profit: $16.15\n"
     ]
    }
   ],
   "source": [
    "# Define buy & sell thrsholds\n",
    "buy_threshold = best_buy_threshold\n",
    "sell_threshold = best_sell_threshold\n",
    "# Generate signals with reversed logic\n",
    "trading_signals = [\n",
    "    -1 if pred < sell_threshold else 1 if pred > buy_threshold else 0\n",
    "    for pred in results_df['Predicted Change']\n",
    "]\n",
    "\n",
    "balance = INITIAL_BALANCE\n",
    "position = 0  # No stock initially\n",
    "trading_log = []  # To store completed trades\n",
    "\n",
    "\n",
    "\n",
    "results_df['Signal'] = trading_signals\n",
    "\n",
    "# Add 'open' and 'close' prices from the original DataFrame to results DataFrame\n",
    "# results_df['open'] = df.loc[results_df.index, 'open']\n",
    "# results_df['close'] = df.loc[results_df.index, 'close']\n",
    "\n",
    "results_df.dropna(inplace=True)\n",
    "\n",
    "# Variables to track ongoing trades\n",
    "buy_price = None\n",
    "buy_date = None\n",
    "buy_volume = None\n",
    "\n",
    "# Iterate over results_df for backtesting\n",
    "for index, row in results_df.iterrows():\n",
    "    signal = row['Signal']\n",
    "    price = row['close']  # Use 'open' price for Buy\n",
    "\n",
    "    if signal == 1 and balance > 0:\n",
    "        # Record Buy details\n",
    "        buy_price = price\n",
    "        buy_date = index\n",
    "        buy_volume = balance / price\n",
    "        position = buy_volume  # Update position\n",
    "        balance = 0  # All money is invested\n",
    "\n",
    "    elif signal == -1 and position > 0:\n",
    "        # Calculate profit/loss for the completed trade\n",
    "        sell_price = price  # Use 'close' price for Sell\n",
    "        profit_loss = (sell_price - buy_price) * buy_volume\n",
    "        balance = sell_price * buy_volume  # Update balance after selling\n",
    "        position = 0  # No stock left\n",
    "\n",
    "        # Record the completed trade in the log\n",
    "        trading_log.append({\n",
    "            \"Buy Date\": buy_date,\n",
    "            \"Buy Price\": buy_price,\n",
    "            \"Buy Volume\": buy_volume,\n",
    "            \"Sell Date\": index,\n",
    "            \"Sell Price\": sell_price,\n",
    "            \"Profit/Loss\": profit_loss\n",
    "        })\n",
    "\n",
    "        # Reset Buy details\n",
    "        buy_price = None\n",
    "        buy_date = None\n",
    "        buy_volume = None\n",
    "\n",
    "# Final portfolio value\n",
    "if position > 0:\n",
    "    final_price = results_df.iloc[-1]['Predicted Price']\n",
    "    final_profit_loss = (final_price - buy_price) * buy_volume\n",
    "    balance = final_price * buy_volume  # Update balance with remaining shares\n",
    "    trading_log.append({\n",
    "        \"Buy Date\": buy_date,\n",
    "        \"Buy Price\": buy_price,\n",
    "        \"Buy Volume\": buy_volume,\n",
    "        \"Sell Date\": results_df.index[-1],\n",
    "        \"Sell Price\": final_price,\n",
    "        \"Profit/Loss\": final_profit_loss\n",
    "    })\n",
    "\n",
    "# Convert trading log to a DataFrame for better analysis\n",
    "trading_log_df = pd.DataFrame(trading_log)\n",
    "\n",
    "# Print the final results\n",
    "print(f\"Final Balance: ${balance:.2f}\")\n",
    "print(f\"Net Profit: ${balance - INITIAL_BALANCE:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predicted prices\n",
    "plt.clf()\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(results_df.index, results_df['Predicted Change'], label='Predicted Change', color='blue', alpha=0.7)\n",
    "plt.plot(results_df.index, y_test/100, label='Actual Change', color='red', alpha=0.7)\n",
    "\n",
    "\n",
    "# Use trading_log_df for Buy and Sell points\n",
    "buy_signals = trading_log_df.dropna(subset=['Buy Date'])\n",
    "sell_signals = trading_log_df.dropna(subset=['Sell Date'])\n",
    "\n",
    "# Map Buy/Sell signals to values from results_df['close']\n",
    "buy_close_prices = [results_df.loc[row['Buy Date'], 'Predicted Change'] for _, row in buy_signals.iterrows()]\n",
    "sell_close_prices = [results_df.loc[row['Sell Date'], 'Predicted Change'] for _, row in sell_signals.iterrows()]\n",
    "\n",
    "# Plot Buy signals as green squares at actual 'close' prices\n",
    "plt.scatter(\n",
    "    buy_signals['Buy Date'],\n",
    "    buy_close_prices,\n",
    "    label='Buy Signal',\n",
    "    color='green',\n",
    "    marker='s',\n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "# Plot Sell signals as red circles at actual 'close' prices\n",
    "plt.scatter(\n",
    "    sell_signals['Sell Date'],\n",
    "    sell_close_prices,\n",
    "    label='Sell Signal',\n",
    "    color='red',\n",
    "    marker='o',\n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "# Add labels, title, legend, and grid\n",
    "plt.title(\"Trading Signals Over Predicted Prices (Using Actual Close Prices)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model_10candles_1min.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "joblib.dump(best_model, 'best_model_10candles_1min.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
